<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon shortcut" type="image/png" href="https://blog.ubie.tech/logo.png"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&amp;display=swap"/><title>mizutani | Ubie Engineers&#x27; Blogs</title><meta property="og:title" content="mizutani"/><meta property="og:url" content="https://blog.ubie.tech/members/mizutani"/><meta name="twitter:card" content="summary_large_image"/><meta property="og:site" content="Ubie Engineers&#x27; Blogs"/><meta property="og:image" content="https://blog.ubie.tech/og.png"/><link rel="canonical" href="https://blog.ubie.tech/members/mizutani"/><link rel="preload" href="/_next/static/css/022fee67b0af59aa852d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/022fee67b0af59aa852d.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.8d61253ae98ee51657b8.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-e552cec615d644762a9b.js" as="script"/><link rel="preload" href="/_next/static/chunks/81b50c7ab23905e464b4340eb234bd6ea389d26b.6f016a54640da22ace83.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/members/%5Bid%5D-0a2d3cf0d329b39cefc0.js" as="script"/></head><body><div id="__next"><header class="site-header"><div class="content-wrapper"><div class="site-header__inner"><a class="site-header__logo-link" href="/"><img src="/logo.png" alt="Ubie Engineers&#x27; Blogs" class="site-header__logo-img"/><span class="site-header__logo-text">Ubie<br/>Engineers&#x27; Blogs</span></a><div class="site-header__links"><a href="https://ubie.life/" class="site-header__link" target="_blank">Company</a><a href="https://recruit.ubie.life/jd_dev" class="site-header__link" target="_blank">Recruit</a></div></div></div></header><section class="member"><div class="content-wrapper"><header class="member-header"><figure class="member-header__avatar"><img src="/avatars/mizutani.jpg" alt="mizutani" width="200" height="200" class="member-header__avatar-img"/></figure><h1 class="member-header__nickname">mizutani</h1><p class="member-header__real-name">Masayoshi Mizutani</p><p class="member-header__bio">セキュリティやってます</p><div class="member-header__links"><a href="https://twitter.com/m_mizutani" class="member-header__link"><img src="/icons/twitter.svg" alt="Twitterのユーザー@m_mizutani" width="22" height="22"/></a><a href="https://github.com/m-mizutani" class="member-header__link"><img src="/icons/github.svg" alt="GitHubのユーザー@m-mizutani" width="22" height="22"/></a><a href="https://github.com/m-mizutani" class="member-header__link"><img src="/icons/link.svg" alt="ウェブサイトのリンク" width="22" height="22"/></a></div></header><div class="member-posts-container"><div class="post-list"><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2022-03-12T04:45:21.000Z" class="post-link__date">8 days ago</time></div></a><a href="https://zenn.dev/mizutani/articles/d861b63086fa95" class="post-link__main-link"><h2 class="post-link__title">あまねくGitHubイベントのSlack通知をOPA/Regoで制御する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-31T07:57:15.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/books/d2f1440cfbba94" class="post-link__main-link"><h2 class="post-link__title">OPA/Rego入門</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-31T04:06:56.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2021/12/31/130656" class="post-link__main-link"><h2 class="post-link__title">2021年 → 2022年</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-24T15:00:16.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/0a74f409faa07d" class="post-link__main-link"><h2 class="post-link__title">まとめ：情報セキュリティのDX</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-24T03:17:19.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/1755527e782183" class="post-link__main-link"><h2 class="post-link__title">OPA/Regoの応用（SOAR: Security Orchestration, Automation and Response）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-23T02:28:46.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/27e5915a362697" class="post-link__main-link"><h2 class="post-link__title">OPA/Regoの応用（脆弱性管理）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-22T03:21:57.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/647dcd83039503" class="post-link__main-link"><h2 class="post-link__title">OPAの拡張（カスタム関数）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-20T23:30:30.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/1311288523dad2" class="post-link__main-link"><h2 class="post-link__title">GitHub Actionsから得られた結果をOPAサーバに問い合わせる</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-19T22:21:10.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/e0ab95bfd4da4d" class="post-link__main-link"><h2 class="post-link__title">Regoのコーディング規約をRegoで検査する</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-19T01:14:21.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/a8f8aac0ae6fb9" class="post-link__main-link"><h2 class="post-link__title">GitHub Action で Trivy + OPA/Rego による脆弱性管理</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-18T01:20:06.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/f305204605a7cf" class="post-link__main-link"><h2 class="post-link__title">OPAサーバをGCP Cloud Runで利用するリポジトリ構成や設定</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-17T14:55:59.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/759d47f17ebd2e" class="post-link__main-link"><h2 class="post-link__title">OPAをAWS Lambdaへデプロイ</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-16T00:12:50.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/ca51a5e5da72f4" class="post-link__main-link"><h2 class="post-link__title">Go言語によるRego runtimeの組み込み</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-14T23:26:39.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/0b401a4be783e8" class="post-link__main-link"><h2 class="post-link__title">OPAのデプロイアーキテクチャ例</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-14T01:33:02.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/89ce7831c245ef" class="post-link__main-link"><h2 class="post-link__title">Regoのデバッグ (trace/print)</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-13T13:54:02.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/24a74292150fff" class="post-link__main-link"><h2 class="post-link__title">Regoの記述例2 (クラウドサービスの監視)</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-12T05:13:51.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/a8ce41c66a2fcc" class="post-link__main-link"><h2 class="post-link__title">Regoの記述例1 (OPAサーバの認可とテスト)</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-11T10:31:53.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/f00d3ca12e4102" class="post-link__main-link"><h2 class="post-link__title">OPAコマンドの利用</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-10T00:58:35.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/07525213a6c3ff" class="post-link__main-link"><h2 class="post-link__title">Regoチートシート</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-09T00:48:13.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/85c9992f601068" class="post-link__main-link"><h2 class="post-link__title">Regoのテスト</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-12-07T22:47:00.000Z" class="post-link__date">3 months ago</time></div></a><a href="https://zenn.dev/mizutani/articles/075920f4a0529e" class="post-link__main-link"><h2 class="post-link__title">Regoの基礎（Safety）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=zenn.dev" width="14" height="14" class="post-link__site-favicon"/>zenn.dev</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-11-04T00:29:40.000Z" class="post-link__date">5 months ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2021/11/04/092940" class="post-link__main-link"><h2 class="post-link__title">Ubieで一緒にセキュリティをエンジニアリングしていってくれる方を募集中です</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-09-06T00:42:15.000Z" class="post-link__date">6 months ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2021/09/06/094215" class="post-link__main-link"><h2 class="post-link__title">2021年8月の夏休み</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-08-01T04:13:16.000Z" class="post-link__date">8 months ago</time></div></a><a href="https://mztn.hatenablog.com/entry/cookpad-to-ubie" class="post-link__main-link"><h2 class="post-link__title">転職します（Cookpad → Ubie）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2021-03-08T12:42:25.000Z" class="post-link__date">a year ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2021/03/08/214225" class="post-link__main-link"><h2 class="post-link__title">シン・エヴァンゲリオン感想（ネタバレあり）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2020-05-04T10:00:28.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2020/05/04/190028" class="post-link__main-link"><h2 class="post-link__title">CLIの環境変数をいい感じに管理するツールを作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2020-01-03T06:54:02.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://mztn.hatenablog.com/entry/badman" class="post-link__main-link"><h2 class="post-link__title">IPアドレスやドメイン名のブラックリストを取得・管理するGo言語のライブラリを作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2019-12-23T22:30:00.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2019/12/24/073000" class="post-link__main-link"><h2 class="post-link__title">AWSにおけるお手軽セキュリティ監視運用のはじめかた 2019（Cookpad Tech Bookより）</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2019-12-22T22:03:58.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2019/12/23/070358" class="post-link__main-link"><h2 class="post-link__title">セキュリティアラートの自動対応の種類についてまとめた</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2019-11-04T06:04:14.000Z" class="post-link__date">2 years ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2019/11/04/150414" class="post-link__main-link"><h2 class="post-link__title">Amazon S3上のログのスキーマを管理していい感じに使うGo言語用ツールを作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2019-02-11T09:29:03.000Z" class="post-link__date">3 years ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2019/02/11/182903" class="post-link__main-link"><h2 class="post-link__title">クラウドネイティブなハニーポットをAWS上に作ってみた話</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article><article class="post-link"><a class="post-link__author" href="/members/mizutani/"><img src="/avatars/mizutani.jpg" class="post-link__author-img" width="35" height="35"/><div class="post-link__author-name"><div class="post-link__author-name">mizutani</div><time dateTime="2018-05-23T23:15:17.000Z" class="post-link__date">4 years ago</time></div></a><a href="https://mztn.hatenablog.com/entry/2018/05/24/081517" class="post-link__main-link"><h2 class="post-link__title">テキスト出力されたログファイルから元のログフォーマットを分析するツールを作った</h2><div class="post-link__site"><img src="https://www.google.com/s2/favicons?domain=mztn.hatenablog.com" width="14" height="14" class="post-link__site-favicon"/>mztn.hatenablog.com</div></a></article></div><div class="post-list-load"><button class="post-list-load__button">LOAD MORE</button></div></div></div></section><footer class="site-footer"><div class="content-wrapper"><p>© <!-- -->Ubie Discovery</p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"member":{"id":"mizutani","nickname":"mizutani","realName":"Masayoshi Mizutani","bio":"セキュリティやってます","avatarSrc":"/avatars/mizutani.jpg","sources":["https://mztn.hatenablog.com/rss","https://zenn.dev/mizutani/feed"],"twitterUsername":"m_mizutani","githubUsername":"m-mizutani","websiteUrl":"https://github.com/m-mizutani"},"postItems":[{"title":"あまねくGitHubイベントのSlack通知をOPA/Regoで制御する","contentSnippet":"TL;DRGitHubは公式の通知機能やコメント内容に応じた通知ツールがすでにあるが、より多くの通知ユースケースがありそうOPA/Regoを使うと通知ルールと実装をうまく分離できる全てのGitHubイベントの通知ができるツールをPoCとして実装してみたhttps://github.com/m-mizutani/ghnotify GitHub通知の活用GitHub上での出来事を通知する方法は、公式のEmail通知やSlack連携だけでなく、様々なツールがこれを実現しています。特に（以前お世話になっていた）tokiteはIssueやPull Request(PR)内の文...","link":"https://zenn.dev/mizutani/articles/d861b63086fa95","isoDate":"2022-03-12T04:45:21.000Z","dateMiliSeconds":1647060321000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPA/Rego入門","contentSnippet":"情報セキュリティの分野で注目されている汎用的なポリシーエンジンOPAと、OPAで利用するポリシー記述言語Regoについて解説します","link":"https://zenn.dev/mizutani/books/d2f1440cfbba94","isoDate":"2021-12-31T07:57:15.000Z","dateMiliSeconds":1640937435000,"authorName":"mizutani","authorId":"mizutani"},{"title":"2021年 → 2022年","contentSnippet":"大晦日ということで2021年のちょっとした振り返りと、2022年のゆるやかな展望のようなものをしたためておきます。仕事2021年今年の前半はクックパッドにてセキュリティ関連の仕事をやっていました。強く印象に残っている仕事がオフィスの移転とISMSの継続審査でした。継続審査はオフィスの移転などに伴って対応が後手後手になり、結構苦しみながら準備をすることになりましたが、なんとか完遂できました。関係者各位、ありがとうございました。そして7月末をもってクックパッドを退職し、ヘルステックのスタートアップであるUbieへ転職しました。ちゃんと働き始めたのは9月からなのでまだ4ヶ月程度なのですが、日々の密度が高すぎてもう1年位働いているような気がしています。ヤバい。mztn.hatenablog.com仕事内容は引き続きセキュリティ関連なのですが、Ubieは社内のリスク対応を専門にとりくむコーポレートセキュリティのメンバーがおり、自分はプロダクト関連のセキュリティに集中して様々な施策をしています。今取り組んでいるのは以下のようなトピックです。インシデント対応体制の構築プロダクトの脆弱性診断3rd partyパッケージの脆弱性管理OPAによるポリシーコード化の取り組みプロダクトセキュリティは自分以外にも（専任ではないいのですが）エンジニアがおり、スクラム形式でタスクを回しています。複数のメンバーで同じ領域に集中して取り組むのはなかなか楽しく、いろいろチャレンジングな取り組みもできています。2022年今年やってきた取り組みも一定形になってきたかなと思う一方で、成熟度はまだまだかなと思っています。特にポリシーのコード化は社内に広く展開し、活用していきたいと考えています。。プロダクトセキュリティ関連だけでなく、コーポレートセキュリティに関するポリシーもここに乗っけていきたいと目論んでおり、OPAというかRegoの布教を進めている日々です。また新しいトピックとして「攻めのセキュリティ」をやっていきたいと考えています。ここでいう「攻め」は「その取り組みによって安全性だけでなく利便性や事業速度の向上にもつながるもの」です。例えば異なるプロダクトで共通するようなセキュリティの機能を事業チームとは別に開発・運用できるようにしておくことで、事業チームがサービスの本質的な機能に集中することができるようになります*1。今まで外向けに使われるプロダクトでの開発経験は豊富ではないため身が引き締まる思いではありますが、チャレンジしていきたいなという機運です。個人活動OSSたまに自分が困ったりしたときには他所のリポジトリにPR投げたりしますが、基本的には自分の作りたいものを作りたいように作る、というスタンスでやってます。今年はGo言語を中心にしたユーティリティをいろいろやっていました。goerr: pkg.go.dev/errors のようにスタックトレースをつけつつ、文脈を表す変数を引き回せるエラー関数golambda: AWS LambdaでGoをいい感じにするやつ。PowertoolsのGo版のつもりzlog: 秘匿値をいろんな方法で隠せるGoのロガーzenv: 環境変数を読み込んだりMac Keychainに隠して管理したりするツール。これはGo関係ないあとデカ目のやつとしてはOctovyというTrivyをベースにした脆弱性管理のツールを作ったというか、作っています。これはもともと前職向けに作っていたやつなんですが、環境がAWS → GCPになったおかげでほぼフルスクラッチで書き換えることになりました*2。github.com登壇とかブログとか転職が挟まった＆ご時世的な状況もあり、ほとんど登壇はなかったです。唯一、自社でホストしたTech Talkイベント（発表資料）で脆弱性管理の話をさせてもらいました。ブログは自分の作ったものを説明したりするときにふらっと書く程度だったんですが、12月はOPA/Regoの一人アドベントカレンダーというのをやりました。我ながら頭がおかしいですね。adventar.org前々から準備していればよかったんですが、これやるか決めたのがそもそも11月中旬で、しかもその時点では「OPAってたしかk8sの設定チェックするツールだっけ？」みたいな状態でスタートしたので、25日分の記事を書くのはなかなかにハードモードでした。もう二度とやらんぞ。私生活転職という大きな節目はあったものの、基本的には前職・現職ともにほとんど在宅勤務のスタイルだったので、基本自宅に引きこもりという生活スタイルでした。たまたまこのご時世に突入する直前の2019年末にマンションを購入していたのですが、ちょっと広めの1LDKを選択していたのが僥倖でした。スペースの余裕は心の余裕。自宅環境の大きな変化はスタンディングデスクを購入したことで、最近おそらく8割以上の仕事時間は立ちながら作業しています。今も立ちながらこの記事を書いています。これで足腰が鍛えられているのかどうかよくわかりませんが、最初の頃は2、3時間くらいで疲れていたのが5、6時間立ちっぱなしでも大して疲れなくなったので一定効果がありそうです。まとめというわけで2021年も各位大変お世話になりました。2022年も引き続きどうぞよろしくおねがいします。*1:このあたりの話に興味がある方はぜひこちらをご参照ください https://mztn.hatenablog.com/entry/2021/11/04/092940*2:Lambda＋DynamoDBだったのをCloud Run+PostgreSQLにしたので、ほとんど異世界転生だった","link":"https://mztn.hatenablog.com/entry/2021/12/31/130656","isoDate":"2021-12-31T04:06:56.000Z","dateMiliSeconds":1640923616000,"authorName":"mizutani","authorId":"mizutani"},{"title":"まとめ：情報セキュリティのDX","contentSnippet":"メリークリスマス！ この記事はOPA/Regoアドベントカレンダーの最終日、25日目です。というわけでこのアドベントカレンダーもついに最終回を迎えました。今回は最後ということもあり、個別の技術の話ではなくメタな視点から改めてOPA/Regoについて振り返りつつ、Policy as Codeの発展の話などをしたいと思います。 OPA/Regoが活用できる領域このアドベントカレンダーを始めるにあたって過去に執筆されたOPA/Regoの記事や発表、連携しているツールなどを調べましたが、 クラウドリソースのmiss configurationやポリシー違反を防ぐ という目的の内容が多く見ら...","link":"https://zenn.dev/mizutani/articles/0a74f409faa07d","isoDate":"2021-12-24T15:00:16.000Z","dateMiliSeconds":1640358016000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPA/Regoの応用（SOAR: Security Orchestration, Automation and Response）","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの24日目です。本日は前回に引き続き、OPA/Regoによる応用がテーマです。今回はセキュリティ監視・対応の運用を自動化する Security Orchestration, Automation and Response (SOAR) にOPA/Regoを組み込む可能性について議論します。こちらも実装を形にしつつはあるのですがまだ不十分なこともあり、今回は構想について紹介するにとどめたいと思います。 SOARとは単語としてはGartnerが2017年くらいから言い始めた単語で、セキュリティ監視によって得られたアラートを自動的に評価・対...","link":"https://zenn.dev/mizutani/articles/1755527e782183","isoDate":"2021-12-24T03:17:19.000Z","dateMiliSeconds":1640315839000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPA/Regoの応用（脆弱性管理）","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの23日目です。今回、次回ではOPA/Regoを使った応用事例について（構想段階のものも含めて）紹介したいと思います。本日は組織内で開発しているプロダクトの脆弱性管理についてになります。今回のトピックは筆者がUbie Tech Talk 〜Ubieを支えるプロダクト基盤と分析環境〜（アーカイブ）で講演させてもらった内容をベースに、発表時には時間の都合上割愛させてもらった技術の詳細について深堀りしたいと思います。発表資料やアーカイブは以下で閲覧できますので、興味のある方は併せてご覧ください。https://www.youtube.com/w...","link":"https://zenn.dev/mizutani/articles/27e5915a362697","isoDate":"2021-12-23T02:28:46.000Z","dateMiliSeconds":1640226526000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPAの拡張（カスタム関数）","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの22日目です。OPA上で動くRegoは非常に柔軟で、自由な表現ができます。さらにOPA自身もいろいろと拡張ができる仕様となっています。詳しくは公式ドキュメントにて説明がありますが、今回は拡張機能の要の一つであるカスタム関数（Custom Built-in Functions）について紹介したいと思います。 カスタム関数とは一言でいうと Goで実装した関数をRego内で利用できるようにする 機能です。Regoの仕様を拡張し、ランタイム内で使える関数を増やすという目的で利用します。具体的には 1) 自分の実装に組み込んだランタイムとして...","link":"https://zenn.dev/mizutani/articles/647dcd83039503","isoDate":"2021-12-22T03:21:57.000Z","dateMiliSeconds":1640143317000,"authorName":"mizutani","authorId":"mizutani"},{"title":"GitHub Actionsから得られた結果をOPAサーバに問い合わせる","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの21日目です。GitHub Action で Trivy + OPA/Rego による脆弱性管理という記事では、Trivyの出力結果をOPAで検査してCIのPass/Failを判定するという事例を紹介しました。この例では判定用のポリシーを同じリポジトリで管理し、opa のコンテナイメージを使ってローカルで判定する、というアプローチを取っています。この方法は開発環境での再現も容易で、検査対象と一緒に確認しながらポリシーを記述できるというメリットがあります。一方で、リポジトリ数が増えるとポリシーの管理が煩雑になってきてしまいます。特に1つの...","link":"https://zenn.dev/mizutani/articles/1311288523dad2","isoDate":"2021-12-20T23:30:30.000Z","dateMiliSeconds":1640043030000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Regoのコーディング規約をRegoで検査する","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの20日目です。本アドベントカレンダーのOPAコマンドの利用 でも紹介しましたが、 opa コマンドは様々な機能を有しており、その中にコードのチェックに関するサブコマンドも含まれています。check はポリシーやデータに言語としての論理的な不整合がないかを事前チェックし、fmt は改行やインデントなどのフォーマットを修正してくれます。しかし、それ以外のコーディングに関する規約のチェックをするような機能は現状 opa コマンド自身には無いようです。OPAのルールを複数人で管理するとなると、（主に筆者の経験から）例えば以下のような項目を強制し...","link":"https://zenn.dev/mizutani/articles/e0ab95bfd4da4d","isoDate":"2021-12-19T22:21:10.000Z","dateMiliSeconds":1639952470000,"authorName":"mizutani","authorId":"mizutani"},{"title":"GitHub Action で Trivy + OPA/Rego による脆弱性管理","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの19日目です。今回は GitHub Actions で Trivy を用いてOSSパッケージの脆弱性検査をした際に、カスタムポリシーによってCIを落とすような仕組みについて紹介[1]します。もともとコンテナイメージの脆弱性スキャナとして開発されていたTrivyですが、最近はファイルシステムにあるパッケージシステムの脆弱性をスキャンする機能も実装されています。この機能を利用したGitHub Actionsも提供されており、自分が開発してるリポジトリで利用している外部パッケージにどのような脆弱性が含まれているかを簡単に調べることができるよう...","link":"https://zenn.dev/mizutani/articles/a8f8aac0ae6fb9","isoDate":"2021-12-19T01:14:21.000Z","dateMiliSeconds":1639876461000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPAサーバをGCP Cloud Runで利用するリポジトリ構成や設定","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの18日目です。今回はOPAサーバをGoogle CloudのCloud Run上にデプロイするような設定、リポジトリ管理、CIの事例について紹介したいと思います。OPAのデプロイアーキテクチャ例 でコンテナイメージを用いてECSへデプロイするパターンを紹介しましたが、構成としてはECSをCloud Runに置き換えただけと考えていただければと思います。また、ポリシーについてはバージョン管理の容易さや、ポリシーとサーバを疎結合にしないようにするという観点からコンテナイメージにポリシーを埋め込むというアプローチになります。 構成まず、今...","link":"https://zenn.dev/mizutani/articles/f305204605a7cf","isoDate":"2021-12-18T01:20:06.000Z","dateMiliSeconds":1639790406000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPAをAWS Lambdaへデプロイ","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの17日目です。今回はOPAの機能をAWS Lambdaで実装する方法について紹介します。 AWS Lambda におけるOPA利用の戦略AWS LambdaはFargateやGCP Cloud Runとは異なり、純粋に「関数」としての機能を提供しています。関数の呼び出しも各言語のSDKを経由する必要があり、既存のバイナリをそのまま利用するのは困難です。つまり GCP Cloud Run 、あるいは AWS ECS・Fargateのようにコンテナイメージやバイナリをそのまま使うことはできません。そのため、次の2つのどちらかの方針を検討...","link":"https://zenn.dev/mizutani/articles/759d47f17ebd2e","isoDate":"2021-12-17T14:55:59.000Z","dateMiliSeconds":1639752959000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Go言語によるRego runtimeの組み込み","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの16日目です。今回はGo言語からRegoのruntimeを呼び出し、ポリシーの評価結果を求める手順について解説します。 セットアップまずはGoの開発環境をセットアップしてください。この記事では以下の環境で検証しています。go: 1.17.2 darwin/arm64opa: v0.34.2Go開発環境のセットアップについては以下のページなどをご参照ください。https://go.dev/doc/install準備ができたら以下の通りモジュールの準備をします（下記の解説では regotest を作業用ディレクトリ...","link":"https://zenn.dev/mizutani/articles/ca51a5e5da72f4","isoDate":"2021-12-16T00:12:50.000Z","dateMiliSeconds":1639613570000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPAのデプロイアーキテクチャ例","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの15日目です。OPAは様々な利用形態がありますが、複数のサービスなどから1つのポリシー群を参照したいなどのケースでは実行用の環境をクラウドなどへデプロイする場合があります。今回はOPAをクラウド環境などで実際に利用する際、どのようなデプロイのパターンがあるかについて解説したいと思います。今回は特定のプロダクトに依存せず、汎用的なアーキテクチャを考えています。筆者の経験からAWSをベースに紹介したいと思います。 パターン1) ポリシーを実行用のアセットに同梱するポリシーデータを実行用のアセット（実行のためのランタイムやコード、バイ...","link":"https://zenn.dev/mizutani/articles/0b401a4be783e8","isoDate":"2021-12-14T23:26:39.000Z","dateMiliSeconds":1639524399000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Regoのデバッグ (trace/print)","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの14日目です。Regoは宣言型の記述言語であり、近年メジャーな手続き型言語と考え方がいささか異なります。そのためどのように動作するかを慎重に確認しながらポリシーを書くという状況が多くなりがちです。筆者もまだRegoを書き始めて日が浅いのですが、今回の記事ではデバッグに使える機能である trace と print について紹介したいと思います。 traceもともとRegoでは組み込みの trace 関数をつかって、どのように評価がされたのかを検証するというデバッグ方法がありました。具体的な使用例を以下に示します。package de...","link":"https://zenn.dev/mizutani/articles/89ce7831c245ef","isoDate":"2021-12-14T01:33:02.000Z","dateMiliSeconds":1639445582000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Regoの記述例2 (クラウドサービスの監視)","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの13日目です。前回に引き続き、記述例編です。今回はクラウドサービス（AWS・GCP）のリソースやアラートの監視に使ってみた、というユースケースに基づいて記述例を紹介したいと思います。OPAはConftestやGatekeeperが有名なためInfrastructure as Codeによるデプロイを止める用途という印象が強いですが、監視のためのルールを管理するポリシーエンジンとしても活用できます。今回はAWSでいくつか例を挙げてみようと思います。AWSはAWS Configによってリソースの変更を追跡できるため、これとOPAを組み合わ...","link":"https://zenn.dev/mizutani/articles/24a74292150fff","isoDate":"2021-12-13T13:54:02.000Z","dateMiliSeconds":1639403642000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Regoの記述例1 (OPAサーバの認可とテスト)","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの12日目です。今回は具体的なユースケースに基づいてRegoの記述例を紹介したいと思います。公式でも既存のインテグレーション事例がいくつか紹介されており、Kubernetes を題材に使用例も解説されています。 APIサーバへのアクセスを制限するポリシーopa コマンドはCLIでポリシーを評価するだけでなく、サーバの機能も提供されています。そのサーバに対するアクセス制御もRegoで記述できるようになっています。詳しい仕様については公式ドキュメントに解説を譲り、今回は具体的な記述について説明していきたいと思います。今回用意したポリシー...","link":"https://zenn.dev/mizutani/articles/a8ce41c66a2fcc","isoDate":"2021-12-12T05:13:51.000Z","dateMiliSeconds":1639286031000,"authorName":"mizutani","authorId":"mizutani"},{"title":"OPAコマンドの利用","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの11日目です。今回は opa コマンドについてです。opaコマンドはいろいろな機能をサブコマンドで備えていますが、よく使うと思われる部分に絞って紹介したいと思います。コマンドのインストールについては公式ドキュメントを参照してください。macOSであれば homebrew からのインストールも可能です。 runOPAの実行環境を作るためのコマンドです。大きく分けて 1) CLIでインタラクティブにクエリを打ち込めるシェルを立ち上げる、2) サーバとして起動してHTTPによって操作する2つのモードがあります。 インタラクティブモー...","link":"https://zenn.dev/mizutani/articles/f00d3ca12e4102","isoDate":"2021-12-11T10:31:53.000Z","dateMiliSeconds":1639218713000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Regoチートシート","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの10日目です。今回の記事ではRegoによるルール表現のパターンをひたすら列挙していきます。 デバッグ 値のチェックr := input.userprint(r) トレースexplainオプションを有効化すると表示される。trace(sprintf(\"x = %d\", [x])) 文字列操作 整形\"blue 5\" == sprintf(\"%s %d\", [\"blue\", 5]) 文字列の結合・分割\"red, yellow, blue\" == concat(\", \", [\"red\", \"yellow\", \"...","link":"https://zenn.dev/mizutani/articles/07525213a6c3ff","isoDate":"2021-12-10T00:58:35.000Z","dateMiliSeconds":1639097915000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Regoのテスト","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの9日目です。Policy as Codeとはの記事でも述べたとおり、ポリシーをコードで記述する大きなメリットの1つがテスト可能になることです。シンプルで少ないポリシーだけを運用しているうちはいいですが、ポリシーが複雑化・巨大化することによって記述した内容が意図したとおりに動作するか、あるいは新たに追加・修正したことで既存のポリシーに影響を及ぼしていないかを確認するコストが肥大化していきます。OPAはポリシーをテストする機能を提供しており、容易にテストの記述や実施ができるようになっています。この記事ではテスト機能の基本的な部分をかいつまん...","link":"https://zenn.dev/mizutani/articles/85c9992f601068","isoDate":"2021-12-09T00:48:13.000Z","dateMiliSeconds":1639010893000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Regoの基礎（Safety）","contentSnippet":"この記事はOPA/Regoアドベントカレンダーの8日目です。今回はRegoでポリシーを記述する際にはまりがちな \"Safety\" の概念について解説します（公式ドキュメント）。 rego_unsafe_var_error: var x is unsafeRegoでポリシーの記述し始めるとおそらく1度は遭遇するであろうエラーです。例えば以下のようなポリシーがこのエラーになります。example.regopackage examplep := {    \"blue\": 1,    \"red\": 0,    \"yellow\": 2,}result[x] {   ...","link":"https://zenn.dev/mizutani/articles/075920f4a0529e","isoDate":"2021-12-07T22:47:00.000Z","dateMiliSeconds":1638917220000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Ubieで一緒にセキュリティをエンジニアリングしていってくれる方を募集中です","contentSnippet":"TL; DRセキュリティエンジニア（プロダクトおよびコーポレート）絶賛募集中ですセキュリティだけを専門でやられていた方だけでなく、サービス開発が中心だったけどセキュリティも少しやっていたみたいな方も大歓迎ですヘルステックのスタートアップであるUbieで働き始めておよそ2ヶ月ほどたちました。入社する前からなんとなくは知っていましたが、メンバーの熱量の高さや能力の高さに圧倒され続けています。事業についても患者さん向けのユビ―AI受診相談や医師向けのユビーAI問診が中心ではあるものの、その枠に留まらない新しいチャレンジを多角的に取り組んでおり、とても刺激的な日々を過ごしています。自分はセキュリティエンジニアとして入社させてもらい、まだ大きな進捗はないもののUbieで提供するプロダクトやそのプラットフォームのセキュリティを向上させる取り組みをさせてもらっています。転職した理由として、事業ドメインや成長フェーズの異なる会社に移り、自分の技術や知識、そして考え方が通用するかというのを試したいというものがありました。入社前からいろいろと社内の話はいくらか聞いていましたが、実際に働いてみることで徐々に自分の中で取り組むべき具体的な課題がはっきりしてくるようになりました。同時に、1つ1つがとても重い話で一緒に取り組んでくれる仲間がもっと必要であるということも分かってきました。そこで、Ubieがこれから取り組みたい課題について言語化してみつつ、どういった方を探しているかについてまとめてみました。興味を持っていただいた方がいたら、ぜひお話させてもらえると嬉しいです。UbieにおけるセキュリティのチャレンジDevSecOpsバズワードのため定義がはっきりしないDevSecOpsですが、自分の中では以下のように定義しています。プロダクト開発の各段階で必要なセキュリティの要件を満たしていけるプロダクト開発で継続的に脆弱性が入り込んでいないかのチェックをするどのサービス事業会社もそうだとは思いますが、Ubieでは特にプロダクトの機能拡張や新しいプロダクトの開発がものすごいスピードで進んでいます。「今度こういう機能を実装する予定なんですよ」 → 「もうできました」みたいな爆速事案をしばしば目撃します。それゆえにプロダクトの変化が激しく、セキュリティ上問題になるような仕組みになっていないか、扱うデータが適切か、脆弱性などが入り込んでいないかなどを常に気にし続けなければなりません。セキュリティを専門に理解している人が張り付くという方法もあるかもしれませんが、スケールしないというのが難点です。これを解決するアプローチとして仕組み化と自動化を積極的にやっていきたいと考えています。この問題は単にCIにセキュリティチェックを組み込めばいいというわけではなく、どうすれば開発するメンバーの負荷にならないようにセキュリティを向上させられるかを模索していかなければなりません。そのためどちらかといえばプロダクト開発の経験があり、かつセキュリティに対して興味がある、というような方と一緒にチャレンジできると面白そうだなと考えています。全社共通・横断のプロダクト向けセキュリティ機能の実装前述したとおり、UbieではユビーAI受診相談およびユビーAI問診という2つのプロダクトを主軸としていますが、それらの拡張だけでなく新しいプロダクトの開発も積極的に取り組んでいます。これら全てのプロダクトは医療に関係するものであり、各々でセキュリティの機能（認証認可、プライバシー保護、監査、リスク分析など）が必要があります。プロダクトが少ないうちは個別に実装するほうが柔軟に動けるなどのメリットがありますが、プロダクトが多くなってくると実装水準のばらつきや全社的なコントロール、状況把握が難しくなるという課題があります。そこでプロダクトが成長・拡大しようとしているこのタイミングで、全社共通のセキュリティ関連機能を実装したいと考えています。これによって、各プロダクトが必要なセキュリティの水準を満たしつつ、サービス開発者が開発のスピードを上げられるという恩恵も得られるようになると期待されます。具体的な事例として、認証認可基盤の構築があります。開発するプロダクトが増えることで、認証認可の仕組みをどのように整えていくかという問題と向き合わなければいけません。現代の認証認可の仕組みは単純なID・パスワードの組み合わせを保持すればいいというだけでなく、多要素認証や様々なデバイスからの利用、そしてサービス間の連携を考える必要があります。Ubieが新しいプロダクトや機能を展開していくとなるとその間の認可をどのように制御すればいいかも考える必要があります。この機能もプロダクトごとに開発すると実装水準にばらつきが出てしまう他、将来的に会社横断で統合するとなると時間が立つほど移行の苦しみが大きくなってきます。今まさにプロダクトが広がっていこうとしている中でこのような仕組みをゼロから設計・実装できるというのは絶妙なチャンスだと考えていますが、自分はこういった仕組みを知識として知っているだけで、実際に大規模な基盤を実装・運用した経験がありません。そういった知識・経験・実装力をもった方にぜひ力を貸していただきたいと考えています。社内の統合的なセキュリティの向上Ubieは現在急速にメンバーを増やしつつあり、そのため社内システムや働く環境のセキュリティについても急速に整えていく必要があります。創業したばかりのベンチャーだとよくあることかもしれませんが、Ubieは事業を加速させるために社内のメンバーが自ら各種クラウドサービスを積極的に導入・活用するという文化が根づいています。現状、管理体制として2020年にはISMSを取得し、3省2ガイドラインの準拠を進めるなど、社内体制やシステム側の安全管理を急速に整えてきています。しかし今後世界市場に拡大するためにも、今ある文化を活かしつつ、安全かつスムーズに各種サービスが使えるようなサービス統制や環境整備をさらに進化させる必要があります。また、各社内システムなどで一定のセキュリティを保つような設定をしているものの、統合した守りの体制を構築していく必要があります。例えば各システムの状況をセキュリティ観点で監視・調査したり、アラートの調査や対応をしたり、セキュリティ関連のエンドポイント製品の導入や運用をしたり…というようなものがあります。これらをバラバラに使うのではなく、それぞれを連携させて機能できるようなグランドデザインをしながら実装・運用をしていく、という試みが必要です。このような体制を整えていくにあたり、人手を増やすことでスケールさせることも時には必要ですが、近代的なシステムやツールの力を使い、人だけに依存しないような構造を考えていく、というところにエンジニアリングとしてのチャレンジがあるのではないかと思います。そういった取り組みに興味がある人と是非一緒に取り組んでいきたいと考えています。どういった方に来てもらいたいか「セキュリティエンジニア」という募集をすると「ずっと情報セキュリティを専門にやってきた方のみを対象にしている」と思われがちですが決してそんなことはありません。特にセキュリティベンダー以外のユーザ向け企業などにおいて、セキュリティの分野というのは業務や開発といった営みに強く関係するものであり、時としてそちらについての知見が必要とされる場合もあります。もちろん一定のセキュリティに関する知識やエンジニアリングに関する技量は必要となりますが、セキュリティ以外のことについてもいろいろ取り組まれていたり、メインは開発だけど実態としてプロダクトのセキュリティ関連のケアをしてきた、というような人にもぜひ興味を持っていただけると嬉しいです。meetyのカジュアル面談募集のリンクも以下にありますので、興味を持っていただけた方はぜひお声がけください。お待ちしています！meety.netその他関連リンクrecruit.ubie.liferecruit.ubie.life","link":"https://mztn.hatenablog.com/entry/2021/11/04/092940","isoDate":"2021-11-04T00:29:40.000Z","dateMiliSeconds":1635985780000,"authorName":"mizutani","authorId":"mizutani"},{"title":"2021年8月の夏休み","contentSnippet":"先日ブログに書いたとおり7月末を最終出社として退職し、8月は有給消化期間にした。学生時代以来の長期夏休みを獲得したし、8月上旬にはfully vaccinatedになっていたのでうまくいけば8月下旬にふらっと旅行するぐらい大丈夫なんじゃないかな、とかちょっと期待していたらデルタ株によってご覧の有様である。そんなわけで折角の機会にも関わらず1ヶ月間は自宅の半径2kmから出ることなく過ごす羽目になってしまい、何もなさすぎて自分でも何をしていたのか忘れてしまいそうなのでブログをしたためておく。読書転職先の推薦図書をいくつか読んだ。Measure What MattersOKR (Objectives and Key Results) の仕組みや効果についてひたすら書かれている本。OKRというものに触れたのが初めてだったので最初はよくある目標設定とどう違うのかというのがピンときていなかった。今回、自分が読んでなるほどなと思った点は以下の3つだった。「やるべき重要な取り組み」の優先順位は組織でも個人でもすぐにブレる。なので方向性を揃えたり修正したりするためにOKRが使える。全社的にOKRというシンプルなプロトコルを使うことで目標管理のコミュニケーションがやりやすくなる。特に全社で定めたOKRが下位のOKRとつながることで、会社としての取り組みに整合性がうまれたりメンバー間の協力がしやすくなる。OKRは「組織にとって価値あることに集中」するための仕組みで、成果をトラックする＆必要に応じて柔軟に変更するという運用をやって初めて効果が発揮される。個人の成績と紐付けてはいけない。なぜなら「組織にとって価値あること」ではなく「OKRを達成すること」が重視されるようになり、間違っていたり環境変化によって効果的ではなくなってしまったOKRでもそれを達成させようとする力学が働くからHow Google WorksおなじみのGoogleが内部でどういう思想でどういう運用をしているかについて書かれた本。全体的に話がちょっと古い（2000年代ぐらいの話が中心）なのと、結果論なのではと思う話が多いきらいはあるものの、 \"Googleっぽさ\" をいくらか理解できたかなと思う。この本で書かれているような内容も現在においてはすでにいろいろな会社・組織に取り入れられるようになったなと感じており、読んだ率直な感想としてすごい斬新だとは思わなかった。ただ、もともとの根幹の話に触れておくのは大切だし、良い機会だったと思う。1兆ドルコーチシリコンバレーのbig tech企業を中心にコーチングの才を発揮していたビル・キャンベル氏の逸話集。氏の類まれな能力や人格による話なので全てをそのまま実践するのは難しく、体系だてた話でもないのでスッと理解するのも難しい。とはいえ自分に足りない人間力的なところで学ぶべきてきなところや、これからチャレンジしていくべきポイントという意味では学びがあったかなと思う。開発個人開発で手を付けたもの。AlertChainSecurity Orchestration, Automation and Response (SOAR) の小さい実装。前職にいたときはAWSのフルサーバレスアーキテクチャでDeepAlertというSOARを実装していたが、次の職場ではGCPなので可搬性ゼロで無事終了していた。ということでコンテナベースで動くものを作ろう思い立ったのだが、この機に最初から設計し直すかとなってフルスクラッチしているのがこのAlertChain。github.com基本的にはセキュリティアラートを受け取って、1) アラートに対して事前に定めたワークフローを自動的に実行する、2) 追加のワークフローを管理画面から実行できる、という2つだけの機能が主軸。事前に定めたワークフローでは、アラートにでてきたIPアドレスをOSINTしたり、条件に従ってリスク判定したり、どこかに通知したりというようなユースケースを想定している。一方、追加のワークフローというのはもうちょっとアグレッシブ＆人間の判断を挟んだほうが良さそうなもので、例えばinstanceをtermianteしたり、ユーザ権限をsuspendさせたり、みたいなのを想定している。下図は対象IPアドレスをBANさせるという追加ワークフローの例。前作との違いを少しふれると、以下の3点。前作は各ワークフローがばらばらになっていてテストがしにくかったのを悔い改め、AlertChainでは全ワークフローを一気通貫でテストできるようにした1プロセスだけで動くようにして運用やデバッグをやりやすくしたAlertChain自体がちゃんとアラートの情報を保持するようにし、管理画面から確認できるようにした正直、まだ荒削りというレベルにすら達していないが次の職場に導入していきたいと画策していて、運用していく中でブラッシュアップしていきたいと考えている。もうちょっと整ってきたタイミングで解説記事などを改めて書きたい。zenv開発などで手元のPCで環境変数を扱う時、envchainを活用しているが、秘匿値以外の環境変数もいい感じに扱えるツールがあると便利だなといろいろ思案した結果、結局envchain + dotenvのようなツールができたというのがこれ。なので既存ツールを組み合わせでどうとでもなる範疇の実装ではあり、人様に強く進めたいというほどのものではない。ただ、 .env ファイルに通常の環境変数だけでなく秘匿値の指定（秘匿値は実際にはkeychain内に保存してある）をしたり、読み込んだ環境変数を元にコマンドライン引数を書き換えたりができるようになっているので、個人的には便利。github.com利用イメージとしてはこんな感じ$ zenv secret write @aws-account AWS_SECRET_ACCESS_KEY Value: # コピペなどで入力$ zenv list @aws-account AWS_SECRET_ACCESS_KEY=**************************************** (hidden) # 読み込んだ環境変数を表示。秘匿値は伏せ字にする$ zenv @aws-account aws s3 ls(snip) # S3のリスト表示$ echo \"AWS_REGION=ap-northeast-1\" \u003e .env$ zenv list @aws-accountAWS_SECRET_ACCESS_KEY=**************************************** (hidden)AWS_REGION=ap-northeast-1 # .envファイルからも読み込み生活ダイエット特に意気込んでやっていたわけではないんだけど成果はでていたので、したためておく。運動＋なんちゃって糖質制限的なやつを6月末からやっていて、だいたい3kgぐらい減量した。運動は実は去年からずっとエアロバイク30分程度というのを中心にほぼ毎日やっていたのだが、いまいち減量するにはいたならかった。そこでなんとなく食事量（特に糖質）を減らしてみたところ、徐々に体重が落ち始めたので惰性で続けてみて今に至る。食事はbase breadとnoshを活用しており、自分ではオートミールをベースにした炒飯とかカレーとかを調理したりしている。あと鶏むね肉やローストビーフをバッチで継続的に低温調理している。糖質はだいたい1日あたり平均して120gぐらいなはず。あとFitbitに食事管理機能があるのだが、定型の食事（それこそbase breadとかnosh）を摂る場合は計測しやすく便利。記入漏れとかもあるからあまり正確ではないが、概ね1日あたり500〜600kcalほどは消費カロリー量が上回っているらしい。豚肉キャベツ卵納豆とオートミールでチャーをハンしたやつ pic.twitter.com/GC6gE8LRdI— mizutani (@m_mizutani) 2021年8月8日  最近はまっているやつ・鶏胸肉を60度4時間くらいでアノーバする・薄切りにする\u0026冷やしてる場合はレンチン・刻んだネギを盛る・ごま油ちょい＋塩ちょい＋白だしとお湯を1:1ぐらいを混ぜてぶっかける普通に美味くてスルッと食べれるし小腹が空いた時に便利 pic.twitter.com/hIMGtVzOZk— mizutani (@m_mizutani) 2021年9月4日  長らく米を食べていないので「たまにはがっつりカツ丼とか食べたい！」と思うことはままあるものの、今のところそこまで辛い気持ちにはなっていないので、無理なく継続してシュッとしていきたい。ゲームMONSTER HUNTER RISEエアロバイクのお供。毎日30分くらい野良で狩りに行っている。エアロバイクをやっていることを程よく忘れられるくらいの集中力が必要。他のゲームも試してみたが、あんまり没頭できないゲームだと「漕いでいて辛い」という気持ちが続いてしまうのだが、モンハンはいい感じに没頭できる。あと1サイクルが10〜15分くらいなので、2〜3回やっていると運動時間が終わるというのも良い。トータルのプレイ時間はそんなに長くないのでHR200ちょいぐらい。ただ最近さすがにちょっと飽きは感じ始めているので、代替になりそうなゲーム無いかなとは思い始めている。Factorio無人の星に不時着してしまったエンジニアが資源を集めて建物や工場を作り、武装や物流システムを発展させていくゲーム。一応、生産物の一つである「ロケット」を作るとクリアとはされているのだが、マップが無限に広がっておりクリア後も工場を発展させることができる。このゲーム、去年末くらいにめちゃくちゃハマって300時間くらいプレイし、自分なりの物流システムの最適解に至るまでやりこんだ。ところが、あまりに工場をでかくしすぎて処理負荷が大きくなりゲームがまともに動かなくなってしまったので、それ以降あまりプレイしなくなっていた。で、特に何かあったわけではないんだけど、ふともう一度ゼロから始めるかとなり、異世界転生よろしく2周目の知識を活かして、丁寧かつゆるゆるとしたプレイをしている。支配地域を広げすぎてわけわからなくなってしまった図。中心部が工場で、資源採掘ポイントと固定砲台が置かれている軍事拠点が鉄道網で各地に散らばっている月姫もう永遠に発売されないんじゃないかと思っていたけど、本当に発売されたよ！ ありがとうTYPE-MOON！！とりあえずの感想として結構演出も凝っているし（「魔法使いの夜」に近い）フルボイスなのでオートモードでプレイしていると実質アニメを見ているのに近く非常に快適。そのため自分の進行はとても遅くまだ序盤も序盤。ただ原作未プレイ勢ではあるものの、結末とか世界設定とかはだいたい知っているのでゆるゆる一月ぐらいかけて楽しんでいくつもり。","link":"https://mztn.hatenablog.com/entry/2021/09/06/094215","isoDate":"2021-09-06T00:42:15.000Z","dateMiliSeconds":1630888935000,"authorName":"mizutani","authorId":"mizutani"},{"title":"転職します（Cookpad → Ubie）","contentSnippet":"https://github.com/m-mizutani/m-mizutani/commit/067a421f3e3e8405cba870bb461446c545128a2e2021年7月30日を最終出社日として現職のCookpadを退職し、9月からUbieという医療系のスタートアップに入社します。Cookpadでのこれまで2017年11月に入社したので、在籍期間は4年弱でした。この間、組織変更に伴う部署異動はありましたが、ずっと情報セキュリティに関わる業務をやってきました。システムのセキュリティ対策主な業務は「インフラや社内システム、開発サービスに対するセキュリティの機能をエンジニアリングによって向上させること」でした。製品やサービスをそのまま導入することもありますが、自分たちの必要に応じて既存ツールを拡張したり、全く新しいシステムを自作することもありました。例えば以下が代表的なやつです。低コストでセキュリティログの横断検索ができる仕組みセキュリティアラートに自動対応する仕組みコンテナ脆弱性を検査して結果を管理する仕組みセキュリティに関する社内の問題を見つけ出してエンジニアリングによってそれを解決していく、という仕事内容は自分の志向とマッチしており仕事はとても楽しかったです。さらに仕事で取り組んだ結果を発表する機会も各所から多くいただき、これについてもありがたかったです。USに飛んで英語で撮影するぞという話を突然もらって、七転八倒しながら達成したのも良い思い出です。ただ調子に乗っていろいろやりすぎてしまった感があり、退職に伴って大量のシステムを引き継ぐことになってしまった点については少し申し訳ないなと感じている次第です。社内リスク対応いわゆる社内の情報セキュリティ委員会というやつもやっており、社内で新たに起きる情報セキュリティのリスクをコントロールするということもやっていました。自分もこの業務に携わるまであまり意識したことがなかったんですが、会社の活動というのは目まぐるしく変化し、それに伴って様々なリスクが発生します。そういったリスクに対応するため、どんな情報システムを使ったらいいのか、どのように使ったらいいのか、どんなデータを扱っていいのか、という相談をうけたり判断をしたりということもやっていました。これは単純に社内ルールに準拠するだけでなく、法律や規制などについても配慮し、とりあつかう情報の重要度などから実際のリスクを考え、現実的な落とし所を考える必要があり、最初のうちはかなりハードな業務でした。自分もそもそも法律などについては素人だったり、（セキュリティの人にありがちですが）過度に安全側に倒して現実的でない方法になってしまうなど四苦八苦していました。しかし同僚の助けも借りつつ最終的にはある程度の部分をこなせるようになった気がしており、自分としてはなかなか良い経験値になったのではと思います。その他会社生活全般組織のカルチャーや雰囲気も自分にとってはかなりマッチしていたと思います。前職が大手SI企業だったこともあり、そのギャップの衝撃から入社直後にわりとはしゃいでいる記事を書いたりしていました。さすがに今はもうこの記事のテンションはありませんが、ここで良かったと感じたことは特に変わっていません。今回の転職直前にオフィスが恵比寿からみなとみらいへ移転するという一大イベントがありましたが、これについても今回の転職とはあまり関係ありません。個人的にみなとみらいはいろいろ思い出深い土地で気持ちがあったし、WeWorkの無限にビールが飲めるサービスとか楽しみにしていたのですが、情勢によって結局ほとんど恩恵に預かれませんでした。悲しい。めちゃくちゃいい天気@みなとみらい pic.twitter.com/UmRlo4tWT1— mizutani (@m_mizutani) 2021年7月27日  転職のきっかけということで現職に対して特に厳しいことがあったというわけではないのですが、自分の能力の幅を広げるという観点でこの度転職をすることにしました。セキュリティエンジニアのキャリアパスというのもいろいろあると思うのですが、自分は「システムのセキュリティ対策」というのがやはり最も興味の強い範囲で、これを継続していった場合にどのようにキャリアを重ねていけばいいのかという点についてはこれまでずっと模索してきました。社内リスク対応の方はパスとして例えばCISOになるというような話があったりすると思いますが、どちらかというと現場でエンジニアリングしていたいので、役職を上げるのとはまた違うかなと考えています。というようなことを長らくもやもやと考えていたのですが、あるきっかけで「違う事業ドメインにチャレンジしてみることで幅を広げるのがいいのでは」と思いつきました。同じWeb系であっても他社のセキュリティ担当の方と話させてもらうと、やはり会社の事業ごとにリスクであったり守るべき資産の捉え方というのが大きく違うな、というのは以前から感じていました。そのため現職でうまくいっている事例を話しても「うちとは（環境や背景が）違いますね」という反応になることがあり、自分のやっていることが他の会社や事業ドメインでどのくらい通用するのか？というのが未知なままでした。そこは確かにやってみないとわからないので「だったら環境を変えてチャレンジすることでより多くの場所で通用することを増やしていこう」と考えるようになりました。Ubieでのこれからというわけで冒頭で書いたとおり、Ubieという医療系のスタートアップに転職することにしました。現状では医療機関向け、および患者さん向けのサポートをして患者さんを適切な医療へつないでいく、といったサービスを提供しています。（私もまだ事業の細かいところを知っているわけではないので、詳しくはこちらの資料を見ていただくか、あるいは興味のある方はぜひお声がけください）ubie.appUbieに決めた理由実は今回の転職では他の会社の選考は受けておらずUbie一本だった*1ため、他社との比較はしていません。普通に考えて転職するときは複数社を受けてオファーを並べて検討するものと思うのですが、1社目で転職しようと考えた決定的な理由は以下の2つでした。事業ドメインが今までと大きく違うセキュリティをエンジニアリングしていくことへの理解1については転職のきっかけの話の通り、事業ドメインがなるべく違うところが望ましいというのがありました。特にセキュリティに対しての厳しさでいうと自分の中では医療と金融が最も難しい分野であり、その片方である医療の分野というのは自分の思惑にとてもマッチしていました。また、事業についても「今あるアナログなビジネスをちゃんとデジタル化していく」という分野は個人的にとても面白く、熱い領域であると考えています。（流行り言葉を使うといわゆる \"DX\" になるんだと思います）Ubieの事業が医療機関に関わってくることで自分たちのサービスだけでなく、医療機関でのセキュリティというのも同時に携わっていく必要があり、それについてもチャレンジングで興味深いと考えています。自分の中でさらに決定打になったのは2の「セキュリティをエンジニアリングしてくことへの理解」が大きかったです。これはCookpadへ入社する際の転職活動で感じたことでもあるのですが、いわゆるセキュリティの問題に対して製品やサービスの導入するだけでなく、ちゃんと自分たちでエンジニアリングをして問題を解決しようというマインドを持った組織というのは日本だとまだかなり少ない印象です*2。Ubieのメンバーとカジュアル面談をした際に彼らもその課題感をもっており、しかしまだそこにアプローチするメンバーがいないという話を聞いたときに、ここで働いてみたいなとう気持ちが強くなったことを覚えています。この他にもマネジメント的な上下関係がない組織構造（ホラクラシー）や評価のない制度、会社の雰囲気など惹かれた部分はいろいろあります。ただまだ直接働いたわけではなく「良さそう」という印象でしかないので、詳しくはいずれ別の機会にという感じです。やっていきたいことというわけでUbieへの転職後も引き続きセキュリティエンジニアをやっていく予定です。今回は医療という領域になるため、リスクに対する考え方や対応がよりシビアになっていくのではないかと考えています。利用してもらう人のために十分な安全性を担保していかなければならないのですが、じゃあどこまでやったら「十分か」ということを常に見極めていく必要があります。そうしたことを突き詰めていく課程で、最適なセキュリティとはなんなのか？、そもそも最適というものがあるのか？ ということを考えていきたいと思っています。また自分の密かな目標として、サービス運用をソフトウェアエンジニアリングの方法でアプローチするSRE（Site Reliability Engineering）にあやかり、Security Reliability Engineering*3の方法論を探求していきたい、というものがあります。Site Reliability EngineeringはもともとGoogle社内で運用にまつわる作業や問題をソフトウェア開発の考え方・発想・手法で解決する方法論を体系化して世に出したのが発端という認識です*4。この着想はセキュリティに関する運用にも適用でき、ソフトウェアエンジニアリングの応用で解決できる問題というのは多くあるのではないかと自分は考えています。ただSREとは領域や前提がいろいろ違うためそのまま持ってくることはできず、セキュリティ分野ならどうかということを改めて検討しなければなりません。自分が新しい領域でチャレンジすることでSecurityのReliability Engineeringの方法論を体系化していく足がかりになればと考えており、引き続きやっていきたいと思います。ということで各位、引き続きどうぞよろしくお願いいたします。*1:厳密に言うとUbieに最初に声をかけてもらったので、Ubieの選考がだめだったら他を考えようとしていました*2:逆に海外のbig tech companyはこのマインドがかなり強い印象で、例えばAWSの事例紹介などでユーザ企業がAWSのサービスを組み合わせてセキュリティの問題を解決しているという話は多くあります*3:略語がSREともろかぶりなので、この名付けはどうかと思うんですが*4:なんですが門外漢なので違ったらこっそり教えて下さい","link":"https://mztn.hatenablog.com/entry/cookpad-to-ubie","isoDate":"2021-08-01T04:13:16.000Z","dateMiliSeconds":1627791196000,"authorName":"mizutani","authorId":"mizutani"},{"title":"シン・エヴァンゲリオン感想（ネタバレあり）","contentSnippet":"3月8日の11:00〜の回でシン・エヴァンゲリオンを観劇してきました。基本的ただの雑感のなぐり書きですが、旧劇の「閉塞の拡大」をBGMに聴きながら今のお気持ちをしたためておきます。思春期から拗らせた者の末路なので、その前提でご笑覧ください。ネタバレしかないので、ご注意ください全体通して「まとまった…な…？」みたいな感じ。アニメーションとしてはめちゃくちゃ動くしすごかったけど、エンターテイメントとしては序や破の方が好きだし、旧劇劇場版のようにバチバチに尖ったところもなかったなという感じ。とはいえこれまでの物語を締めようとしているというのがしっかり見えて「あーこれで終わりなんだな」というのを実感させられた。四半世紀に渡る因縁に対してスパッと決着ついたのかと言われるとちょっとわからないけど、とりあえずこの作品を世に出してくれてありがとうという気持ちです。その他雑感序盤〜ヴンダー出撃小出しにされるコンテンツ見るの嫌い派なので先行映像は一切観なかった、ので冒頭の戦闘シーンは登場する敵含めてちょっと意表をつかれて良かった村の生活で人間性を獲得していく綾波に対し、どんどん人間性を失っていくシンジがちょっと哀れシンジ、旧劇ではわりと「そんなことでうじうじしているんじゃない」みたいな感じがあったけど今回の件はまあそりゃ落ち込むよね…、という納得がめちゃくちゃあったとはいえ旧劇劇場版みたいに最後までこのテンションだったらどうするんや…と思っていたけど、ちゃんと復活してくれてよかったアスカにけちょんけちょんに言われてたけど、自分で世界滅ぼしかけて目前で友人殺されてという状況からちゃんと立ち直るの、むしろ強靭メンタルすぎでは？アスカとケンスケがいい仲になっていたのは最初「まじで！？」ってなったけど、個人的にはなんかわりとすんなり受け止められた。一方、一緒に見に行った友人は許せていなそうであった。古のオタクは難しいのだプラグスーツの電源がなくなる描写、そのまま爆発でもするんじゃないかとヒヤヒヤした異空間での戦闘〜シンジ覚醒誘導弾、「完全に無人在来線爆弾じゃねーか」と思わずツッコミ「ヤマト作戦」とかその他あれこれで、ああ庵野監督は本当に宇宙戦艦ヤマト好きなんだなぁと実感ミサトさんとシンジのコミュニケーションが落ち着いたものでなんか良かったマイナス宇宙〜終劇親子プロレス（初号機vs13号機）は、仮想世界での戦いという演出はすごいわかるんだけど、なんかギャグっぽく感じてしまいうーむという印象「特撮っぽい描写」を演出するために色んな要素をチープにしていたと思うんだけど、あそここそ全力全開最高作画をやってほしかった異空間とかスケールのデカさからなんかグレンラガンを想起した旧劇のお家芸、精神世界描写もでてきたり、旧劇のラストに通じるアスカのシーンも会ったりして「あー、ほんとうに過去の因縁を終わらせようとしてくれたんだな」というのを感じたしかしこれ新劇だけ観てた人にはわりと「？」になったりするんじゃないかな本当は旧劇もこうありたかったということなんじゃないかなー？旧劇だとゲンドウについてあまり語られなかったけど、今回の深堀りで普通にまるでダメなオヤジだったことがわかりちょっとニッコリしたわれながらちょろいけど髪下ろしたミサトさんいいよね、、となりました最後のシンジの相手がマリだったのは、嫌ではないんだけど個人的には納得いかずそもそも君たち本作でやっとちゃんとした面識持ったというぐらいの仲じゃん…。個人的にはあのポジションはレイだった。アスカはケンスケとよろしくやっているのでヨシこれはなんか過去作に気づいてない伏線とかあるのかもしれないので考察班を待ちます最後が実写だったのは、監督からの「現実に帰ってこい」的なメッセージを感じましたね旧劇時代に比べ、監督が結婚して拗れが解消したという説はわりと信憑性があると思う","link":"https://mztn.hatenablog.com/entry/2021/03/08/214225","isoDate":"2021-03-08T12:42:25.000Z","dateMiliSeconds":1615207345000,"authorName":"mizutani","authorId":"mizutani"},{"title":"CLIの環境変数をいい感じに管理するツールを作った","contentSnippet":"表題のとおりですが altenv というツールを作りました。 Alter environment の略です。github.comモチベーション業務上、大小様々なツールやらシステムやら（これとかこれとか）を開発をすることが多いのですが、あつかうプロジェクトが多くなると開発やデプロイなどに使う設定値の管理がだんだん煩雑化していくという課題を感じていました。特に一部のツールは外部公開もしているので、実装と設定をちゃんと分離しようとすると（特にローカルでの開発に関する設定の場合）数ヶ月たった後に作業をしようとすると「どの設定値を使うんだっけ、、」というのがちょいちょいありました。単純にちゃんと管理しておけという話ではあるものの、そういった設定値を統一的に扱えるものがあると便利だなと思って作ったのがこのツールです。端的に言うと、オプションや設定ファイルに記載された内容に応じて環境変数を読み込み、その環境変数とともに指定されたコマンドを実行するというだけのツールです。イメージとしては以下の通り。$ cat test.envDBNAME=hoge$ altenv -e test.env npm run server# running npm server with environment variable DBNAME=hogeユースケース細かい利用方法はレポジトリの方に書いたつもりなので、ざっくりとユースケースごとの使い方を書いておきたいと思います。コマンドラインのオプションでいろいろ指定することもできますが、デフォルトで $HOME/.altenv という設定ファイルを読み込むので、そちらの設定を交えて紹介したいと思います。プロジェクトのディレクトリごとに環境変数をわけるwordir.xxx というテーブルがあり、これを使って作業ディレクトリごとの環境変数を定義できます。（ xxx はただのラベル）[workdir.proj1]dirpath = \"/Users/mizutani/.ghq/github.com/xxx/project1\"define = [\"DB_NAME=mydb1\"][workdir.proj2]dirpath = \"/Users/mizutani/.ghq/github.com/yyy/project2\"define = [\"DB_NAME=mydb2\"]CWDが dirpath 以下にあるとそのテーブル内に記載された設定が有効化されます。具体的には以下のようになります。（ -r dryrun で読み込まれた環境変数一覧が表示されます）$ cd /Users/mizutani/.ghq/github.com/xxx/project1$ altenv -r dryrunDB_NAME=mydb1$ cd ../../yyy/project2$ altenv -r dryrunDB_NAME=mydb2外部のレポジトリやファイル共有サービスから参照するdefine で環境変数を定義するやり方だと全ての環境変数を $HOME/.altenv に書く必要があり、チーム内で共有するのが難しくなってしまいます。なので、外部ファイルを参照することで、gitレポジトリやファイル共有サービス（Google File StreamやDropboxなど）を使って環境変数を共有できます。（ただし、gitレポジトリは自分で最新ファイルをpullしてくることを想定しています）[workdir.proj1]dirpath = \"/Users/mizutani/.ghq/github.com/xxx/project1\"envfile = [\"/Users/mizutani/Google Drive File Stream/Shared drives/MyTeam/config/project1.env\"][workdir.proj2]dirpath = \"/Users/mizutani/.ghq/github.com/yyy/project2\"envfile = [\"/Users/mizutani/.ghq/github.com/yyy/configs/project2.env\"]このように設定することにより、project1 のディレクトリにいる際にはGoogleドライブのShared Drive内にあるファイルが、project2のディレクトリにいるときはconfig管理用レポジトリ内のファイルが参照されるようになります。Staging / Production などの切り替えをする例えば同じディレクトリでもステージング環境とプロダクション環境の両方にアクセスする場合、利用する環境変数の切り替えが必要になります。 profile.xxx というテーブルを用意することにより、利用したい設定を都度選択できるようになります。profileにおける xxx はそのままプロファイル名になります。[profile.proj1-stg]envfile = [\"/path/to/proj1/stg.env\"][profile.proj1-prd]envfile = [\"/path/to/proj1/prd.env\"]このように設定しておくと、 -p オプションによって読み込まれる環境変数を切り替えることができます。$ altenv -p proj1-stg ./deploy.sh# ステージング用の環境変数が読み込まれた上で deploy.sh が実行される秘匿値を環境変数に使う（macOSのみ）macOSが提供しているKeychainに環境変数を保存しておくことで、ファイルなどに平文保存するより安全にAPIキーなどの認証情報を管理できます。基本的には envchain の機能をベースに実装しています。-r update-keychain -w \u003cnamespace\u003e というオプションをつけることで、読み込んだ環境変数をKeychainに書き出します。\u003cnamespace\u003e は任意の名前空間を指定できます。例えばすでに平文でファイル保存していた場合は以下のようにしてKeychainへの書き出しができます。$ altenv -e credential.env -r update-keychain -w mycredあるいはすでに環境変数に読み込まれている場合は以下のようにしてKeychainへ書き出すこともできます。例としてAWSで利用する環境変数 を保存してみます。$ env | grep -e \"^AWS_ \" | altenv -i env -r update-keychain -w aws-cliまた、コピー＆ペーストにより1つずつ書き出すこともできます。$ altenv --prompt AWS_SECRET_ACCESS_KEY -r update-keychain -w aws-cliEnter AWS_SECRET_ACCESS_KEY Value:# 秘匿値を想定しているため入力した値は表示されない呼び出すときは -k \u003cnamespace\u003e オプションで保存した環境変数を呼び出せます。$ altenv -k aws-cli -r dryrunAWS_SECRET_ACCESS_KEY=xxxxxxxAWS_ACCESS_KEY_ID=xxxx$ altenv -k aws-cli aws s3 ls2019-11-21 19:02:20 mybucket-12019-11-21 19:02:22 mybucket-2...","link":"https://mztn.hatenablog.com/entry/2020/05/04/190028","isoDate":"2020-05-04T10:00:28.000Z","dateMiliSeconds":1588586428000,"authorName":"mizutani","authorId":"mizutani"},{"title":"IPアドレスやドメイン名のブラックリストを取得・管理するGo言語のライブラリを作った","contentSnippet":"だいたいタイトルの通りなのですが、色々なサイトで公開されているブラックリストを取得して、トラフィックログなどとの照合に使うことを目的とした badman というライブラリを作成しました。Blacklisted Address and Dmain name Manager です。github.com少し前だとネットワークのセキュリティ監視をするといったら、だいたいsnortのようなネットワーク型IDSを使うことが多かったと思います。しかし近年だと殆どの通信がHTTPS化されているということもあり、現状だとネットワーク型IDSはあまり有効な手法と言えなくなってしましました。代わりにできることの一つとしては、ネットワークのフロー情報（IPアドレス、ポート番号、プロトコルややりとりされたデータサイズなど）やDNSの問合せ＋応答のログを蓄積しておいて、マルウェアのCommand \u0026 Controlサーバや詐欺サイトとの通信が発生していなかったのかを検証することです。この方法だとWebなどの通信が暗号化されていたとしても、不審な通信があったかを発見できます。ただ、継続的に発生する通信ログの検証をするたびにブラックリスト提供サイトからリストをダウンロードしてくると、提供サイトや自分のネットワークにも負荷をかけてしまいます。そこで一度ダウンロードしたものを中長期的に使い回せるようにと考えて、このライブラリを作成しました。なお、ライブラリになっているのはログの入力方法やログの内容が環境によって大きく異ると考えられたからです。具体的なアーキテクチャ例は後で説明します。どう使うものかGo言語に親しい方だとだいたい以下のコードを見てもらえるとイメージがつくのではと思います。package mainimport (    \"bufio\"    \"log\"    \"os\"    \"github.com/m-mizutani/badman\"    \"github.com/m-mizutani/badman/source\")func main() {    man := badman.New()    if err := man.Download(source.DefaultSet); err != nil {        log.Fatal(\"Fail to download:\", err)    }    // ipaddrs_in_traffic_logs.txt contains IP address line by line    fd, err := os.Open(\"ipaddrs_in_traffic_logs.txt\")    if err != nil {        log.Fatal(\"Fail to open a file:\", err)    }    defer fd.Close()    scanner := bufio.NewScanner(fd)    for scanner.Scan() {        entities, err := man.Lookup(scanner.Text())        if err != nil {            log.Fatal(\"Fail to lookup:\", err)        }        if len(entities) \u003e 0 {            log.Printf(\"Matched %s in %s list (reason: %s)\\n\",                entities[0].Name, entities[0].Src, entities[0].Reason)        }    }}このコードでやっていることは以下のとおりです。ブラックリストを提供しているサイトから複数のリストをダウンロードして自分用のレポジトリを作るIPアドレスのリストが含まれている ipaddrs_in_traffic_logs.txt を開いて1行（1 IPアドレス）ずつとりだすとりだしたIPアドレスがレポジトリに含まれていたか検証するこのサンプルだと1.のブラックリストをダウンロードしてくるところは毎回実行されてしまいますが、本来はダウンロードしたものをローカルに一度保存し、それを使い回すということを想定しています。保存する方法は A) シリアライズされたデータをファイルに書き込んで、次回以降はそのファイルを読み込む、 B) 永続性のあるデータストア（現在パッケージに取り込んでいるのはAWSのDynamoDBのみ）をバックエンドに使う、の2通りがあります。詳しい使い方についてはレポジトリの README を御覧ください。アーキテクチャ例AWSで使うことを前提に、2つのアーキテクチャ例を紹介します。それぞれ badman をライブラリとして使って独自にプログラムを作り、動作させることを想定しています。サーバレスで使う場合このケースでは、2つのLambda関数を利用しています。 1番目（左側）の関数はブラックリストを定期的に取得し、シリアライズされたブラックリストデータをS3に保存します。 2番目（右側）のLambda関数は、トラフィックログファイルがS3にアップロードされた際のObjectCreatedイベントによって呼び出されます。 そしてLambda関数はシリアライズされたブラックリストデータとログファイルの両方をダウンロードし、トラフィックログのIPアドレスがブラックリスト内に存在するかどうかを確認します。 存在する場合、ラムダはSlackなどの通信ツールを介して管理者に通知します。このアーキテクチャの利点はスケーラビリティと価格の柔軟性です。Lambdaは（上限はあるものの）トラフィックログの到着件数の増減に応じてスケールアウト・スケールインするのでログ量に応じてリソースが足りなくなったり、逆に過剰にリソースを割り当てたり、というのを心配する必要がありません。さらに、ログ量が少なければ料金も自動的に少なくなるので、あまりコストをかけたくない小さい規模のネットワークの監視をするなどのケースでおすすめです。一方で、不利な点は遅延です。ログの流量によりますが、S3にアップロードする前にログをある程度まとめることになるのでそのバッファリングをしている時間は遅延が発生します。経験則だと概ね数分〜十数分になります。もしリアルタイム性が必要なら以下のサーバ型モデルを採用したほうが良いかもしれません。サーバ上で使う場合このアーキテクチャでは常時稼働しているプログラムをホスト上（この例ではAWS EC2）で動かします。主な利点は、リアルタイム性のためのストリーム処理です。 先述したとおり、サーバレスモデルではある程度ログをまとめてからS3にアップロードする必要があるため、ログの発生から処理完了までに数分の遅延が発生します。常時稼働させるサーバプログラムを使ってデータを絶えず流し込むことで、遅延を最小化します。このプログラムはfluentdのforward用のサービス*1 を動かしている事を想定しており、fluentd経由でトラフィックログを受信します。 その後、badmanを使用して、ブラックリストに含まれているIPアドレスのトラフィックログを確認します。 ブラックリストは定期的に更新されることを想定しています。プログラムを実行しているホスト（この場合はEC2）がクラッシュしても回復できるように、DynamoDBをデータ保存用のレポジトリとして使用します。このアーキテクチャの欠点はリソースの割当が難しいことです。おそらくログの流量がボトルネックになるので、その最大値に合わせてホストのリソースを設定する必要があります。さらにトラブルやいつもと違うイベントでログの流量が大幅に増える可能性がある場合は、それについても気をつける必要があります。これを解決するためには自動的なスケーリングなどの仕組みと組み合わせて使う必要があります。利用してもらうにあたっての注意ブラックリストを提供しているサイトはそれぞれ異なるポリシーを持っています。そのため、環境や組織によっては利用条件を満たさない可能性があるため注意してください。使えるブラックリスト提供サイトを限定するために、利用者が自分で使うサイトを選択することもできるようになっています。また、自分で badman が提供しているInterfaceを満たす構造体を実装すれば、独自のサイトや非公開のデータストアからデータを取り込むことも可能です。簡単にですが各サイトのポリシーについてもREADMEにまとめてありますので、そちらもご参照下さい。ちなみに昔、似たような mdstore というツールを実は作っていたんですが、今回はGoでえいやと作り直しました。理由としてはLambdaで動かしたかったので、1) Lambda+マネージドサービスだけでよりステートレスに動かす仕組みを作りたかった、 2) 概ねnodejsより速く動くGoにすることで、実行時間を短くして安く済ませたかった、などです。*1:プロトコルは https://github.com/fluent/fluentd/wiki/Forward-Protocol-Specification-v1 になります","link":"https://mztn.hatenablog.com/entry/badman","isoDate":"2020-01-03T06:54:02.000Z","dateMiliSeconds":1578034442000,"authorName":"mizutani","authorId":"mizutani"},{"title":"AWSにおけるお手軽セキュリティ監視運用のはじめかた 2019（Cookpad Tech Bookより）","contentSnippet":"はじめにこの文章は技術書典7で頒布されたCookpad Tech Bookに寄稿させてもらったものの転載になります。基本的に加筆などはしていませんが、一点だけSecurityHubに関する記述に間違いがあった（自動通知の機能がない、という誤った情報を記載していた）のでその点だけ修正しています。御存知の通り、2019年12月初旬に開催されたAWS re:Invent 2019において色々な新しいサービスが発表されました。なかでもAmazon DetectiveやAmazon Fraud Detectionはセキュリティ関連サービスの中で注目すべき存在になっており、今後のAWSセキュリティ監視の中で重要なポジションになる可能性があります。この文書は2019年9月ごろ書かれたものなので当然それらの内容には触れていませんが、それについてはまたいずれ別の形でアウトプットしたいと考えています。クラウドの時代になってもセキュリティのやっていきは必要です。クラウド上だと多くのマネージドサービスが提供されているためオンプレミスの環境よりもセキュリティの機能を実現しやすい側面はありますが、それでもまだすべてを頼り切ってよいほど進化しているとはいえないのが現状です。やらないといけないセキュリティの機能はさまざまですが、ここではAWS、およびセキュリティ監視（セキュリティ被害の発生の兆候を検知し分析すること）に焦点を当てて、マネージドサービスを活用したセキュリティ監視の小さなはじめかたについて解説したいと思います。また、マネージドサービスの初期設定方法についての解説は世の中に多くありますが、継続的に使っていくためにはどうすればいいか？ということを説明したものはあまりないため、ここではそういった運用に焦点をあてて説明します。セキュリティ監視この文章における「セキュリティ監視」とは「自分達が運用しているシステムやサービスに発生しうるインシデントの兆候を検知し、それを分析して監視対象の環境に影響があるかを判断すること」とします。インシデントとはある人物による作為的な攻撃によって、システムやサービスに何かしら変化が発生し、それによってビジネスや仕事に悪い影響が発生することとします。わかりやすい例として、業務用PCがマルウェアに感染してしまったり、サービスに侵入されてしまう、という状況を想像してもらえるとよいかと思います。侵入口を潰したり攻撃そのものを遮断したりする「防御」とは異なり、何かが起きた際にそれを迅速に発見し対応できるようにすることを目的としています。なぜセキュリティ監視するのかはじめにそもそもなぜセキュリティ監視が必要なのか？という理由について簡単に説明したいと思います。すべての攻撃を完璧に防ぐのは不可能である: 「監視などするまえにそもそも防いでしまえばいいのでは」という説はありますが、システムに侵入しようとする攻撃の手法やそれをとりまく環境は日々変化し続けており、それに完璧に追従するのは困難です。特に攻撃に利用される脆弱性は次々と新しいものが発見されており、長年使われていたオープンソースのソフトウェアでも例外ではありません。攻撃を防ぐためにはどのような攻撃がくるかということをあらかじめ知っている必要があり、日々状況が更新されていくような環境では防御だけにすべてを頼るのは厳しいといえます。防御の対策は利便性を阻害しがちである: それでも防御を重要視していこうとすると、今度はユーザーの利便性が阻害されてしまいます。防御とは攻撃と疑われる行為を発見したらそれを止める対策です。防御でなるべく多くの攻撃を止めようとすると、ちょっとでも不審な動きがあればその動きを遮断するような方向に調整しなければなりません。それによって正規のユーザーによる正常な動作も不審とみなされてしまい（これを False Positive と呼びます）システムやサービスへのアクセスを止められてしまいます。極端な例として、パスワードを一度間違えたら1日はアクセスできなくなってしまうサービスを想像してみてください。うかつなパスワードを設定していても突破される可能性は低くなりますが、本来のユーザーによる正規のアクセスも妨げてしまいます。もちろんこのような措置が必要な場合もありますが、多くの場合は利便性とのバランスを考えなければなりません。以上の理由により、防御となる対策を入れることはもちろん重要なのですが、防御だけですべての攻撃から守ろうとするのはあまり現実的ではありません。監視と併用することによって利便性、安全性、コストのバランスのとれたセキュリティを実現していくことができるようになります。セキュリティ監視を構成する「検知」と「分析」（と「対応」）セキュリティ監視というプロセスは主に「検知」と「分析」、そして「対応」という3つのフェイズからなっています。これらはそれぞれがキッチリと分離しているわけではなく、検知と分析が被る部分、分析と対応が被る部分がそれぞれあり、互いに影響しあっていると考えてもらえればと思います。aaセキュリティの製品やサービスでは検知に特化したもの、分析に特化したもの、両方の性質を兼ね備えたものなど、いろいろな種類のものがあります。ただ、今回は特に検知と分析がそれぞれわかれたサービスについて説明します。用語の定義インシデント : ある人物による作為的な攻撃によって、システムやサービスに何かしら変化が発生し、それによってビジネスや仕事に悪い影響が発生することイベント : サービスやシステム内で発生する事象を一括にした呼び方。Webサービスへのアクセスからプロセスの起動など、粒度はさまざまアラート : セキュリティ監視のためのプロダクトやサービスが、インシデントの可能性があるイベントを発見し、それについて発報したものログ : イベントとして発生した事象の詳細を記録として残したものセキュリティ監視の説明に出てくる要素の関係性。抽象化しているためこのモデルに当てはまらないものもあるが、おおよその関係性ということでご容赦願いたい検知監視している対象のサービスやシステム内で発生したイベントの情報から、セキュリティ上問題がある事象をみつけだすことを「検知」とします。たとえばアンチウィルスソフトウェアはディスクに保存されたファイルの内容からマルウェアを検知するというのが分かりやすい事例かと思います。他にもイベントが記録として残ったログを集めて分析し、不審な行動を探し出すSIEM（Security Information and Event Manager）も検知の機能があるといえます。また、機械ではなく人間がログや現在進行中のイベントなどをみて根性で怪しい現象に気づく、というのも検知にあたります（定常的にこれをやるのはあまりお勧めできません）。しかし、これらはあくまで「可能性」であり実際にサービスやシステムに影響を及ぼしていると断定した形で報告されることは稀です。そこで、発見された事象が本当にインシデントなのかを判断する作業が必要になります。分析検知された事象が実際にサービスやシステムに影響を及ぼしたのかを調べるのが「分析」です。検知のためのサービスやプロダクトはインシデントの可能性が高い事象を発見してくれますが、これはあくまで可能性にすぎません。本来は検知の段階でインシデントであることを確定させてから通知してくれればいいのですが、残念ながら現代のセキュリティ監視のサービスやプロダクトをそのまま使うだけでインシデントを正確に発見するのは困難です。これはなぜかというと、組織ごとにルールやサービス・システムの運用方法の違い、業務内容の違いがあるからです。たとえば、AWSのコンソールに普段は見られない国に所属しているIPアドレスからのアクセスがあり、ログインに成功したとします。後述する Amazon GuardDuty はこういった通常見られない不審なアクセスをアラートとして発報してくれます。このアラートではIDとパスワードなどの認証情報が盗まれ、第三者が不正にAWSのコンソールにログインした可能性を示唆しています。では、このアラートがあがった時点でそれをインシデントと断じることができるでしょうか。ある組織のルールとして「業務は必ずオフィス内で実施すること」と決まっていたとしたら、自国外からのログインはかなりの確度でインシデントとみていいでしょう。しかし、リモートワークが前提の組織であったとしたらどうでしょうか。スタッフは場合によっては他の国にふらっと旅行にいって、旅先で仕事をしているかもしれません。そうした場合、通常と違う国からのアクセスが一概に危険とは言い難いです。また、ルールが厳しい前者の組織であってもたまたま出張にでていて例外としてアクセスしていた可能性もあります。このように組織のルールや内部事情などによって発見された「インシデントの可能性があるもの」が本当にインシデントなのかを、他のデータと突き合わせながら判断するフェーズを「分析」と呼んでいます。分析では業務内容などに照らし合わせてアラートの判定をする他に、サービスやシステムのログをみてアラートの内容を精査するというアプローチがあります。さきほどの例から考えると、直接本人に「今、旅行中ですか」と尋ねる方法もありますが、一方で他の社内システムのログを検索することで「しばらく前からいつもと違う国で仕事していたのだな」ということを確認できます。（もちろん、AWSへのアクセスとその社内システムの認証系が別になっていることが前提ですが）他にも「ある人物による不審な動きが観測された」というようなアラートがあったときに、具体的にどういった動きがあったのかを確認できれば、それが通常の業務の範囲内なのか、それとも逸脱した行為をしているのかということを判断できます。こういった判断を重ね、発報されたアラートから本当に自組織に対して被害を及ぼすインシデントを発見する、というステップが必要です。実際にインシデントと判断できるものを発見した場合、「対応」のフェーズに移っていきます。対応（余談）「対応」は実際に何かしらの被害が発生した際、被害状況をまとめる、被害を軽減する、被害から回復させるといった行動です。もちろんこれはサービスやシステムを運用する上で重要な対策ではあります。ただ、やり方がサービスやシステムの構成に大きく依存しており、さらに直接的にこれを支援するAWSのサービスは（今の所）あまりないようなので、今回の解説からは省きます。ただ今回ひとつ触れておきたいのは、冒頭で述べたとおり分析と対応はきれいに分離されている訳ではない、ということです。実際の現場では、インシデントと確証はないがかなり怪しいとなったら影響の少ない範囲ですばやく対応を開始する場合も多いです。これについては筆者もそこまで経験が豊富ではないためあまり多くは語れませんが、発生している事象のリスクと周りに対する影響などを判断しつつ、バランスをとりながら対応することは必ずしも容易ではありません。セキュリティ監視に使えるAWSサービスとその役割前置きが長くなりましたが、今回のテーマである「セキュリティ監視を既存（2019年9月現在）のAWSでどうミニマムに実現できるか？」に話を移していきたいと思います。「AWS セキュリティ」でググってみていただくと分かると思いますが、当然ながらセキュリティは監視だけにあらずで、さまざまなサービスがでてくると思います。今回はここまで説明した監視だけに絞り、サービスそのものと構成の例について説明したいと思います。まず次の4つのサービスについて簡単に説明します。各サービスの詳細についてはそれぞれ公式ドキュメントをご覧ください。Amazon GuardDutyAWS Security HubCloudTrailVPC Flow Logs検知に役立つAWSサービスAmazon GuardDutyAmazon GuardDuty はAWS上で起こる不審な挙動を検出してくれるサービスです。詳細な動作について細かなアルゴリズムなどは公開されていませんが、一部設定のセキュリティ上の問題をみつけてくれる他、機械学習を利用して通常と異なる動作（EC2インスタンスによる普段と異なる通信、AWSコンソールへの不審なアクセス）を検知してくれます。具体的な検知内容については https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_finding-types-active.html をご覧ください。GuardDutyは基本的にはCloudTrailのログ、VPC Flow Logs、そして内部DNSの問い合わせデータを利用して検知をしており、それらのデータから見えないイベントは見ることができないようです。たとえば、インスタンス内部に悪性プログラムが静かに潜んでいるのを検出するといったようなことはできないはずです。（通信が発生すれば別ですが）そのためAWS内で発生するすべてのインシデントを網羅できるわけではないのですが、それでもCloudTrailから見えるAWSリソースの操作、およびVPC内部での通信状況に関しては監視できるため、AWS利用の中でそれなりに大きな部分をカバーできるといえます。また、利用料金も全体のAWS利用料のおおよそ1%程度になるといわれており、一般的な商用セキュリティサービス・プロダクトに比べてかなりリーズナブルになっています。AWS Security HubAWS Security Hub はGuardDutyをはじめとするAWS、あるいはサードパーティのセキュリティ監視検知結果を統合する機能を持っています。また、AWSのベストプラクティスを元にしたCIS（Center for Internet Security）ベンチマークという機能もあり、AWS上のセキュリティ関連設定の不備について通知してくれます。AWS Security Hub はそれ自身が検知をする機能を提供しているわけではないのですが、サードパーティのセキュリティ監視サービスやプロダクトからのアラートを統合してくれる点に強みがあります。セキュリティ監視をするうえで手間がかかることのひとつは複数のサービスやプロダクトを利用する際に、ちゃんと統合して使えるようにすることです。これはSIEM（Security Information \u0026 Event Manager）という製品がより上位の機能を提供しているので、状況によってはSIEMを使ったほうがよいかもしれませんが、Security Hubの方が機能が限定的な代わりに多くの場合SIEMより安価なので、今回は Security Hubを軸として説明します。仮にGuardDutyしか使っていない状況だったとしても、今後セキュリティ監視に利用するサービス・プロダクトを容易に追加するために最初から導入しておくのがお勧めです。分析に役立つ（データを蓄積してくれる）AWSサービスAWS上で分析をするにあたり、なるべく多くのログを保存できたほうがいいのはいうまでもありません。しかしサービスなどから出力されるログは環境によってまちまちで、一概に説明するのは難しいものです。そのため、ここでは共通して利用したほうがよいサービスについてのみ解説します。CloudTrailCloudTrailはAWS上での操作をAPI単位で記録するサービスです。AWSではコンソールを含むすべての操作がAPI経由で実行されており、そのログを追うことでどのリソースがいつ作成、変更、削除されたのかを追いかけることができます。CloudTrailはAWS上でのユーザーの挙動を追跡したり、リソースに関する履歴を調べるのに役立ちます。アラートの分析をしていると「このユーザーは何をしようとしていたのか」「このリソースはいつ誰が作ったのか」などを確認する必要がたびたびあります。そのユーザーやリソースについて自分達が記憶していたり、すぐに聞いて分かる状態であればいいのですが、ちょっと前のことになると人は記憶を失ってしまうため、ちゃんとログに頼って検証できる状態にしておくのが望ましいです。CloudTrailは利用しているアカウントの全リージョンに対し一括有効化できる機能があるため、ひとまず有効化しておいてよいサービスかと思います。VPC Flow LogsVPC Flow LogsはVPC内の通信を記録してくれるサービスです。記録と言ってもその名のとおりフローの情報のみ、つまり送信元IPアドレス、宛先IPアドレス、ポート番号、転送データ量、パケット数、といったような通信の一部の情報のみで、通信の内容については取得されません。もし通信の内容を取得したい場合は、VPC Traffic Mirroringを利用できます（詳しくは @{Webサービスへのログを取得する} で解説します）VPC Flow Logsは現状だと一括で有効化する方法は提供されておらず、VPCごとに個別に設定をしていく必要があります。全VPCで設定を有効化したい場合は、AWS Configを使ってFlow Logsが有効になっていないか探すか、（手前味噌ですが）次のようなツールを使って一気に有効化するというのがよさそうです。https://github.com/m-mizutani/flowlogconfAWSにおけるセキュリティ監視の構成例では、実際にこれらのサービスをどのように使うかを、検知と分析それぞれの観点から説明したいと思います。それぞれのサービスを有効化する方法などは公式ドキュメントやWeb上の記事に多く解説がありますので、ここでは触れません。代わりにどのような構成で使うのがよさそうかという、筆者の視点からみたベストプラクティスについて説明します。検知のための構成検知のための構成検知をするためのお勧めの最小構成が上記の図です。Security Hubを中心として、GuardDutyを有効にし、さらに他のセキュリティ監視サービスやプロダクトを使っており、Security Hubとの統合機能が提供されているのであれば、それも統合していきます。GuardDutyは有効化されていれば自動的に統合されるはずですが、念のためSecurity HubのSummaryページから統合されているか確認してみてください。これによって検知に関する情報がSecurity Hubに集約され、Security Hubのダッシュボードを見るだけで、対応すべきアラートの一覧を確認できます。セキュリティ監視サービス・プロダクトが2、3程度だと実感しにくいかもしれませんが、コンソールが別々に分離しているとサービスやプロダクトの数が増えることで作業の手間が指数関数的に煩雑化していきます。セキュリティ監視の対応（特にアラートの分析まで）は日常のルーチンワークになりがちなので、こういったコストを低減できるうちに取り組んでおくことに価値があります。Security HubのFinding（本文書でいうところの「アラート」）はCloudWatch Eventsからイベントを発行できるため、Lambdaでそれを受信し各所に通知するなどの自動対応に繋げることができます。分析のための構成分析のための構成分析のための構成はよりシンプルです。ここまでで説明したCloudTrail、およびVPC Flow LogsをそれぞれS3 Bucketに保存します。図中では同じS3 Bucketに保存していますが、監視対象の規模が大きい場合はオブジェクト数が多くなるため別Bucketにするのがよいでしょう。それぞれ、標準でS3 Bucketに直接ログを出力する機能があるので、それを利用してください。そして保存したログを検索する方法についてですが、まずはAmazon Athenaを利用することをお勧めします。詳しい説明は公式ドキュメントなどに譲りますが、簡潔に説明するとS3 Bucket上にあるログデータなどを並列で一気に読み込み、記述したSQLのような命令にしたがって検索、集計、表示をするサービスです。このサービスが今回のセキュリティ監視に適している理由として、サービスの料金が読み込んだデータ量の従量課金である、ということが挙げられます。セキュリティ監視における分析は重要なタスクですが、業務時間において四六時中発生している状態は望ましくありません。（もしアラートがひっきりなしに発生している、という状況であれば @{対応するアラートを選別する} をご参照ください）そのため事業内容のデータ分析などと違い、特定の瞬間のみログを検索できるような仕組みのほうがリーズナブルです。Athenaはこういった要件によくマッチしていることもあり、まずセキュリティ監視の仕組みを作る初期段階にお勧めできます。具体的な検索の手順などについては次のドキュメントをそれぞれご参照ください。特に「S3パスの日付を指定して、ある特定の日付からのみ検索する」というテクニックを使うことで、検索範囲を狭め（＝読み込むデータ量を減らし＝安い料金で）検索結果もより高速に取得することができるようになります。https://docs.aws.amazon.com/ja_jp/athena/latest/ug/vpc-flow-logs.htmlhttps://docs.aws.amazon.com/ja_jp/athena/latest/ug/cloudtrail-logs.htmlさらに一歩進んだ監視をしたい場合今回紹介したのはあくまで最初に取り組む、いわば初期装備とでもいうべき構成となっています。いずれ何らかの形で改めて紹介したいと考えていますが、セキュリティ監視をより充実させるためにできそうな取り組みのポイントだけ取り上げたいと思います。また、解説という体になってはいますが、筆者もまだ試行錯誤を続けている段階のものが多くあるため、よい解決方法などをお持ちの方がいたらぜひご教示ください。Webサービスへのログを取得するAWSを利用する目的として、かなり多くの方々が「Webサービスの提供」を挙げられるのではないかなと想像しています。Webサービスを提供している場合「攻撃のための侵入口」としてWebサービスそのものが利用されるのは現代においては自明といってもいいでしょう。そのため、自分達が提供しているWebサービスまわりのリソースについてのアラートが発報された場合、Webサービスでどのようなことが起こったのか調査できるように、ログを取得・保管しておくことが望ましいです。通常、セキュリティ監視が目的でなかったとしてもWebサービスに関連するログの一部は取得している場合が多いのではないかと想像しています。特に次の3点については監査やトラブルシューティングのために何らかの形で保管していることが多いと思われるため、それらをセキュリティ監視の分析でも使えるようにするというのが最初のステップかと考えられます。Reverse Proxy、Load BalancerなどWebアプリの手前の中継機能のログHTTPサーバなどのミドルウェアのログ（あれば）Webアプリ本体のログ多くの場合、これらのログは送信元のIPアドレスやリクエストが送信された対象のホスト、URI、一部のクエリなどが含まれており、分析に最低限必要な情報は取得できます。しかし一方でPOSTリクエストなどに含まれるBodyのデータは見えなかったり、リクエストのヘッダ部分の情報が一部欠落しているケースが多く、そういった部分に攻撃コードが含まれるような場合は追跡が難しくなってしまいます。（これらの欠落してるデータはデータ量が多い、センシティブなデータが含まれる、というケースがあるので当然といえば当然なのですが）これについては筆者も最適解はまだわかっていませんが、現状AWSサービスで解決するとしたら次の2つを検討します。AWS WAFを使う: AWS WAF（Web Application Firewall）は防御の機能だけでなく、どのようなリクエストが発生してどのルールにマッチしたか・しなかったのか、をログとして残すことができます。ログを残す目的だけ（＝トラフィックを止めないの）であればAWS WAFはCloudFront、あるいはALBに関連付けするとすぐ使えるようになるので、既存Webサービスがこれらを使っていた場合は非常に容易に展開ができます。ただし現状（2019年9月現在）はリクエストのBodyの内容は取得できないため、POSTなどによる攻撃の追跡は難しいという欠点があります。VPC Traffic Mirroringを使う: VPC Traffic Mirroring機能はWebサービスに限らずEC2インスタンスなどENI（Elastic Network Interfaces）の通信をパケットレベルですべてコピーし、別のインスタンスなどに送信できるサービスです。完全な通信のコピーを取得できますが、パケット単位で通信が送られてくるため、HTTPリクエストの形に直すためにはツールなどでうまくTCPセッションを復元してあげる必要があります。また通信量も莫大になるため、よりシビアにコスト計算をしたり、運用時のパフォーマンスを考えねばならず、全体的に負荷は高めといえます。どちらの方法もかなりの量のデータを取り扱うことになるため、どの程度の料金が発生するかなどを事前によく試算してから利用することを強くお勧めします。その他使えそうなAWSサービス今回は紹介しませんでしたが、その他セキュリティ監視に利用できそうなサービスをご紹介します。Amazon Macie: S3上に個人情報などセンシティブなデータが保存されていないかをチェックしてくれるサービスです。セキュリティ監視の文脈では有効なサービスではあったのですが、残念ながら2019年9月現在では us-east-1 （バージニア）と us-west-2 （オレゴン）のみでしか利用できないので今回は対象外にしました。Amazon Inspector: EC2インスタンスにインストールされている脆弱なパッケージなどを報告してくれるサービスです。どちらかというと予防の側面が強かったため今回は取り上げませんでしたが、これも利用できると分析時に「この攻撃に対して対象のEC2インスタンスは脆弱だったか？」という検証がしやすくなるため、セキュリティ監視に取り込む検討をしてもよさそうです。インスタンス内部の情報を取得するWebサービスに対するリクエスト同様に、今回のセキュリティ監視の構成で取得できていないものとしてインスタンス内部のイベントに関するログがあります。GuardDutyは「あるインスタンスで不審な活動があった」ということまでは教えてくれますが、インスタンスの中のどのプロセスがその不審な活動をしたか、までは教えてくれません。（このあたりについて詳しく知りたい場合はAWSの責任共有モデルを調べてみることをお勧めします）そのため、インスタンスの中のイベントのログは自分で取得しないと、どのプロセスが不審な活動をしたのかがわからず、それがインシデントなのか判断できずじまい、ということになりがちです。これを解決するような製品やOSSは近年増えてきています。osquery、sysdig、auditbeatなどのOSSも、本格的な運用の話は国内であまり聞こえていませんが、開発も盛んになってきている印象です。この領域については筆者もいまだ試行錯誤しているため、明確な構成や運用のベストプラクティスなどを語れる立場にありません。ただ、実際にこのようなログを取り込んだいた場合のアラート分析は著しく捗ることはわかっているため、今後も取り組みを続けたいと考えています。対応するアラートを選別する検知の仕組みを入れた後に起こりがちなのが、アラートが大量すぎて対応しきれなくなるというものです。冒頭でも述べたようにセキュリティ監視は監視する対象のサービス、システム、業務によってやり方が大きく変わってくるため多くの監視サービスやプロダクトは多様なアラートを発報します。「セキュリティ」というものに取り組んでいると、どうしてもセキュリティ監視サービスやプロダクトが発報したアラートについてひととおり目を通して安全であることを確認しないと気がすまない、という状況に陥りがちです。確かに些細に見えるアラートが大きなインシデントの兆候を示していた、というケースもありえなくはありません。しかしそれを理由にすべてのアラートをこと細かに分析してチェックしようとしはじめると現場が疲弊してしまい、本来見るべきだったものを見逃してしまうリスクの方が大きくなります。これを回避するためには必ずアラートのチューニングをしていく必要があります。アラートのチューニングにおいて重要になることを2つほど説明させてください。アラートの内容を機械的に判断して要・不要を判断する: アラートのリスクを判断するときは基本的に人間の直感などに頼らず、判断するための根拠があるはずです。その根拠は同種類の別のアラートにも適用できるはずであり、それをちゃんと言語化しルールとして次のアラートに活かしていかなければなりません。たとえばいつもと違う国からアクセスがあった、というアラートがあってもそれが本人が持っているデバイスからであるという確認がとれれば、それがアメリカからでもイギリスからでも大差はないはずです。（緊張関係にある国だった場合はまた別かもしれませんが、それも言語化すべきルールといえます）このルールをできれば監視のシステム自体に組み込めれば担当者の負荷も劇的に下がると思われますが、それができないシステムも多いので、その場合は基準を作って担当者間で共有するだけでも機械的に対処できることになり、負荷は下げられると考えられます。機械的な判断に必要な情報を（なるべく自動的に）揃える: アラートの内容を機械的に判断するためには、ログをはじめとしてアラート外の情報との組み合わせが必要になるケースが多くあります。これらの外部情報の取得作業をいかに簡易化できるかというのも、ある意味チューニングの一部といえます。アラートが発生した際、何を基準に判断するかが明確になっていれば、その判断に必要な情報は何か？という問いの答えも明確になるはずです。何が必要かわかっているなら、あとは機械的（自動的ならなおよし）に取得できるはずで、これによって自動的にアラートの判断ができないまでも、担当者の負荷を下げることにはつながるはずです。まとめAWSをはじめとするクラウドサービスではセキュリティのマネージドサービスが多く提供されており、セキュリティを向上させるための土台はオンプレミス環境より豊富になっていると思います。しかし一方で、マネージドサービスの個別の使い方についての説明は多く世の中に出回っているものの、運用まで含めた統合的な使い方の説明はあまりないなと常々思っていたため、今回文章にしてみた次第です。まだ拙い内容なのでわかりにくい部分なども多いと思うのですが、今後もこうした情報発信をしていきたいなと思いますので、ぜひお気持ちのある方々と一緒にやっていければなと思う今日この頃です。","link":"https://mztn.hatenablog.com/entry/2019/12/24/073000","isoDate":"2019-12-23T22:30:00.000Z","dateMiliSeconds":1577140200000,"authorName":"mizutani","authorId":"mizutani"},{"title":"セキュリティアラートの自動対応の種類についてまとめた","contentSnippet":"最近、セキュリティアラートの自動対応に対する機運が高まっているので、どういった種類のものがあるかについて整理のため自分なりにまとめてみました。なおここでの「アラート」は「セキュリティシステムや人間がある程度の確度をもってセキュリティ侵害が発生した、あるいは発生し続けていると判断したもの」を指しています。disclaimer基本的に筆者の知識・経験に基づいて書いてます。もっとこういうのあるよ、というのがあれば教えて下さいアラートの検知などの話はしません各対応の細かい実装方法についても話しません（環境・製品・サービスなどに大きく依存するため）アラートの対象となるホスト（被害を受ける側）については、特に断りがない限りサーバ環境とクライアントPC環境の両方を想定して書いていますお題は以下の通りです。Notification (通知)Investigation (調査)Preservation (保全)Block (遮断)Remediation (修復)Quarantine (隔離)これらから1つだけ選ぶ、というよりは状況などに応じて複数を併用することを想定しています。Notification (通知)概要: アラートが検知されたことを関係者に通知する。EメールやSlackなどチャットに流すこともあるし、PagerDutyのように通知先や対応状況の共有などをサポートするツールを利用することもできる利点対象ホストに対して（基本的に）全く干渉しないため誤検知だとしてもホスト・サービスなどに対して影響しない課題（当然だが）人間が対応を開始するまではホストはアラートで示された状況から何も変化しないので、もし本当に危険に晒されている状況で人間が対応を開始できなければ危険度は高くなっていく検討事項基本的には人間が対応をすることが前提であるため、誰がいつどのように対応するか？ということまで含めてちゃんと設計する。例えば「通常業務時間内で対応する」というのであれば原則として深夜や土日に検知されたアラートについては通知がきても翌営業日ないし週明けにしか対応できない、というようなことを組織内で握っておく必要があるホストに影響がないからといってどんなアラートでも通知しようとすると流量が増えていき人間が疲弊する。また、意図的に増やそうとしなくてもセキュリティシステムなどの更新により新しいアラートが検知されて流量が増える可能性もある。そのためアラート数を少なくするような仕組みとセットで考えるとよいInvestigation (調査)概要: アラートに出現した識別情報（IPアドレス、ドメイン名、ユーザ名、ファイルのハッシュ値などなど）に対して関連情報を収集する。例えば不審な通信のアラートが検知された場合、外部の脅威情報DB（VirusTotalやabuse.chなど）を参照することで、その通信先がC\u0026C（Command \u0026 Control）サーバとして利用されていたのかどうかを知ることができる。他にもあるユーザが不審な行動をしたというアラートが検知された場合、組織内で利用しているサービスやシステムのログを参照することで、当該ユーザがアラートの前後に何を、どこから実施していたのかがわかる。これによって、アラートのリスク評価などの時間を短縮できる。なお、調査のみを単独で実施するというよりは通知などと組み合わせることでより効果を発揮する利点調査をする過程において判断が必要となる手順はあまりないため、誰がやっても同じ結果になる。そのため自動化の恩恵（時間の短縮、ミスの防止）を十全に受けることができる。課題特になし検討事項外部の情報を参照する場合はAPIなどを使って検索をすることになるが、そのような脅威情報を提供してくれるサービスは無料版だとかなり厳しくAPIの利用制限が定められている場合が多い。したがって、アラートが大量に発生している状況ですべてのアラートについて調査しようとするとあっという間に利用制限に引っかかる。特に自動化していると気づかずにDoSのようになってしまって、あげくBANされる可能性もあるため流量の制限などは事前によく検討しておく必要がある。なお有料版にすることで制限緩和してくれるサービスもあるが、だいたいはそこそこいいお値段である上述のポイントにも絡むが、1つのアラートに対してどこまで深堀りするかも考える必要がある。例えば、あるIPアドレスが過去にマルウェアを配布していたという情報を得た際、どのような種類のマルウェアなのかを知ることでよりリスク評価が容易になる。ただ、そのような紐付けされた情報をたぐり始めると際限がなくなってしまい、APIの制限にひっかかったりシステムの負荷が上がってしまうという問題がある。そのため、無闇に関連する情報を探すのではなく、アラートに含まれる識別情報の意味と文脈を考えて、ちゃんと調査する対象を選んだりどこまで調べるかを考えなければならないPreservation (保全)概要: アラートの対象となっているシステムから調査に必要そうな情報を探して別の場所に保全する。集める情報としてはシステムログ、ミドルウェアやシステムの設定情報、動いているプロセスやネットワークの状況といったものが挙げられる。フォレンジックアーティファクト収集ツールを自動で実行しデータを別の場所へ転送するイメージ利点通知、調査に次いでホストに影響を及びさない（ただし情報取得時に負荷のかかる手段を使うと、可用性の面で影響があるかもしれない）収集したい情報が大量であったとしてもアラートが検知された近辺でのみ収集することで、データ転送やストレージなどのコストを下げられる課題通知などと同様にホストに干渉しないため進行中の脅威があった場合に阻止してくれるものではない侵害を受けたホストの場合、保全の対応をする前にrootkitなどを仕込まれている可能性があるため、ファイル情報やプロセス情報などが改ざんされたものになっている恐れがある検討事項セキュリティ侵害を受けた対象ホストから保全した情報の削除・変更ができるとまずいので、権限の設定やアーキテクチャをちゃんと考える必要がある課題の部分でも述べたとおりアラート発生後だと正しい情報を取得できない可能性がある。自動化によって対応開始の時間を短縮でき人間が手動で対応するよりは良いが、アラートもセキュリティ侵害発生直後に発見されているとは限らず、後手に回っているのは間違いない。そのため多少データ転送やストレージのコストがかかったとしても、常時必要な情報を収集する仕組みを検討する価値はある厳密な証拠保全の観点から言うと、自動保全の工程で微細な証拠を消してしまう（例えば証拠が残っているディスクの一部の領域を上書きしてしまうなど）可能性もあるので、そういった工程のなかで影響がないように留意するBlock (遮断)概要: 現在進行系で攻撃を受けている際に、攻撃元になっている相手を遮断して攻撃による影響を排除すること。つまりBAN。主に外部にサービスを提供するサーバ環境で必要な場合が多い。狙ってやってくるDoS攻撃だけでなく、悪意のあるなしに関わらずシステムに想定外の負荷をかけるような通信や、不正な行動（リスト型攻撃など）を弾くといった場面でも有効な場合がある利点可用性の点でいうと、サービス側の性能向上や負荷がかかる部分の修正といった作業無しですぐ効果がでる課題サービスの場合、すべての通信を遮断するとただのサービスダウンになってしまうので攻撃者の識別子（IPアドレスやユーザ名）を指定した上で遮断することになる。しかし、どちらも攻撃者からすると比較的簡単に用意できるため、ボットネットなどを使って数の暴力で押されると弱いという問題がある概要にも書いたとおり、あくまで可用性への影響低減や不正な行動の抑制に対して効果があるものであり、任意コード実行などの攻撃が成功したあとに遮断しても無意味である（遮断しても別の場所から打ち込まれて死亡するだけなので）検討事項BANした対象をどの程度の期間BANし続けるかも考えておく必要がある。IPアドレスのような識別子はNATによって複数人が同時に使っていたり、アドレスのつけ変わりによって別の人が利用したりすることはよくある。永久にBANし続けると無関係の人まで巻き込んでしまうため、攻撃による影響低減とのバランスをとって検討しなければならないサービス内でBANする場合は比較的柔軟に遮断ルールを持てる（はずだ）が、マネージドサービスやセキュリティ製品をつかってネットワークのレイヤでBANする場合は保持できるルール数に上限があったりするので注意が必要であるあくまで筆者の経験則や聞いた話だが、いきなりボットネットで大規模攻勢に晒されるということはあまり多くはない気がするため、短期的には遮断しつつ、その間に別の対応を進めるというような併用が効果的かもしれないRemediation (修復)概要: 攻撃、あるいは悪意のないミスなどによって変更されてしまったファイルや設定などを含むシステムをあるべき状態に戻すこと。サーバ上のコンテンツ復旧や、マルウェアに汚染されたホストからマルウェアを取り除いて正常な状態に戻すといったようなことも含める。また、ホストだけではなくクラウドを含むマネージドサービスについても、管理者が禁止している設定内容になっていた場合に自動的に修復させる、といった用法もある。概念としてまとめてしまったが、具体的な方法については修復対象によって大きく異る。利点攻撃によるコンテンツや設定などの改変に対しては、（場当たり的にではあるが）可用性を高めることができる。機密性や完全性が損なわれている状態だとしても、とにかく可用性を維持したいというようなものに有効（主に悪意のない）意図しない設定変更などに対しては、認可の粒度の粗さを補うことができる。つまり「Aという項目に対して変更する権限をあたえる」までしか認可の設定ができないシステムにおいて「Aという項目はXかYという内容になっていなければならない」というルールを強制したい場合に、「Aという項目がZになっていた場合に自動的にXに戻す」というような対応をすることで、擬似的にルールを実現できる。課題攻撃による改変に対しては、根本原因を取り除くわけではない。改変が発生しているということはホスト上の様々な箇所が改変されている可能性があり、それらを全て適切に修復するのはかなり困難である。例えばサーバの場合だとコンテンツや設定だけでなく、同時にバックドアが仕込まれている可能性が高い。またPC環境でマルウェアに感染していた場合、昨今のマルウェアは感染とほぼ同時に複数の悪意あるコードをホスト上のあちこちに仕込み、1つや2つ駆除されたとしても別のマルウェアが再度汚染を再開させてもとの状態に戻ってしまう。したがって攻撃に対しては場当たり的であると言わざるを得ない。主に悪意のない、意図しない変更に対する修復についても便利ではあるものの、一度は意図しない状態になってしまう（完全に変更を防げるわけではない）という点に留意する必要がある。そのため、根本的には認可の粒度をより細かくできるようにする、というアプローチの方が重要である。クラウドのような環境であれば問題が起こったホストをまるごと潰して、全く同じものを再度作り直すという自動化をすることで、ホスト上にどのような改変がされていたとしても完全にその影響は除去できる。ただし、同じものが再度作られるということは当然攻撃を成功させた脆弱性もそのまま再現されるので、やはり根本解決には至らない検討事項課題で述べたとおりあくまで場当たり的な対応であり、修復単体で対策しても可用性を少し高める程度である。並行して根本的な（おそらくは人間による）対応を実施するということを念頭に置いて自動化を設計する必要がある。フォレンジックの観点で考えるといろいろな痕跡を破壊する可能性があるため、それを踏まえた上で実施するかどうかを検討する必要もある。Quarantine (隔離)概要: 攻撃を受けたとされるホストをネットワークから切り離し、攻撃による内外への影響を閉じ込める。攻撃を受けただけという状況よりは、攻撃が成功してすでに侵入されている、といった状況で被害の拡大を防ぐのに有効な一手になる。利点ほとんどの攻撃がネットワーク越しに発生する＆社内向けシステムもほとんどがネットワークによってアクセスされることを考えると、攻撃元からの指示を止めつつ内部システムや外部サイトへの影響を完封できる。攻撃の進行を食い止めるための強力な方法である課題ネットワークから切り離されるため、可用性に対しての影響が大きい。サーバの場合はサービスの提供が全くできなくなるし、PC環境の場合は操作している人の作業が強制的に中断される可能性がある。サーバの場合はサービスが冗長化してあって対象のホストを急に隔離しても大丈夫＆すぐに代替のサーバが用意できる、というようなアーキテクチャになっている必要がある。PC環境の場合は事前にそのような対応をすることについての合意形成が必要になる課題と言うほどではないかもしれないが、ほとんどの場合があくまでホスト単位での隔離なので、すでに攻撃が横展開されていた場合は影響を完封できないことには留意したい検討事項課題で述べたとおり、他の対策に比べて非常に影響が大きく安易に実施できない。そのため自動的に実施する場合は、対象ホストの重要度（機密性の高い情報がある、強い権限を持っている、など）を考慮したり、攻撃が進行中であることを示す複数の証拠をもとに発動させるなど、慎重に条件を検討する必要があるネットワーク通信を遮断するため、C\u0026Cサーバとの通信も遮断される。これは影響を極小化するという意味ではいいが、フォレンジックの観点からは追跡が難しくなるとも言える。これについてはどちらが良いかという諸説がありつつ、ビジネス的な判断要素も多分に絡まってくる。そういった高度な判断が必要と考えると、やはりあまり自動化に向かないかもしれない","link":"https://mztn.hatenablog.com/entry/2019/12/23/070358","isoDate":"2019-12-22T22:03:58.000Z","dateMiliSeconds":1577052238000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Amazon S3上のログのスキーマを管理していい感じに使うGo言語用ツールを作った","contentSnippet":"あまりにニッチすぎるから全く需要ないかなと思ったんですが、世の中に3人くらいは同じ悩みを抱えた人がいるかなー？と思ったので一応ブログをしたためておきます。github.comこれはなにタイトルでちょっと雑に書きましたが、もう少し正確言いうとAmazon S3上に保存したログのフォーマットやスキーマの一部をコード上で定義し、管理するためのフレームワーク in Go言語です。以下のように定義を書いた後、S3のバケット名、キーを指定するとパース済みの構造体を返してくれます。ここでは1行ずつのJSON形式で保存されたログが your-bucket バケットの http_log/ 以下に入っており、さらに ts というフィールドに時刻情報が入っていることを定義しています。   pipeline := rlogs.Pipeline{        Ldr: \u0026rlogs.S3LineLoader{},        Psr: \u0026parser.JSON{            Tag:             \"ts\",            TimestampField:  rlogs.String(\"ts\"),            TimestampFormat: rlogs.String(\"2006-01-02T15:04:05\"),        },    }    reader := rlogs.NewReader([]*rlogs.LogEntry{        {            Pipe: pipeline,            Src: \u0026rlogs.AwsS3LogSource{                Region: \"ap-northeast-1\",                Bucket: \"your-bucket\",                Key:    \"http_log/\",            },        },    })実際の読み取りはこんな感じ。   ch := reader.Read(\u0026rlogs.AwsS3LogSource{        Region: \"ap-northeast-1\",        Bucket: \"your-bucket\",        Key:    \"http_log/log.json\",    })    for q := range ch {        if q.Error != nil {            log.Fatal(q.Error)        }        values := q.Log.Values.(map[string]interface{})        fmt.Printf(\"[log] tag=%s time=%s src=%v\\n\", q.Log.Tag, q.Log.Timestamp, values[\"src\"])    }rlogsの中には自分自身の需要によりJSON、VPC FlowLogs、CloudTrailのそれぞれのログに対応するパーサーを用意していますが、自分で実装することもできます。なんで必要なのかS3はオブジェクトストレージという性質上、当然ながら保存するときのログの中身・構造は一切問われません。そのためフォーマットやスキーマという概念を（ほぼ）無視してログの保存ができますが、一方でログを利用する際には別途中身をパースする必要があります。保存しているログが2、3種類だけしかない、あるいは保存する際にちゃんと共通のスキーマに落とし込んでいる、というような場合はこれ以上お話することはないのですが、だいたいの場合現実はそうはいかないかなと思っています。特にS3にログを保存するときのメリットは「高可用でログの一次保存ができる」という点が大きいです。そのため、ログを保存する前にあれこれやってエラーなどがおきて可用性が下がってしまうというのは、アーキテクチャの旨味が少なくなってしまうかなと思います。ということからログを利用する際にはどのバケット、どのプレフィクスにどんなログが入っているかを知っている必要があります。ログを利用するツール・システムが1つだけならそこに定義などを書いておけばいいのですが、実際には様々なことにログを利用したくなるため、自分は共通化したいと考えました。そこで共通利用できるようにして、ついでにログの取得＋パースの機能もつけようと思ったのがこのフレームワークです。どう使うのか組織内などで1つレポジトリを作り、そこにフォーマットやスキーマの定義を書いて、それをGoのパッケージとして呼び出す、というような使い方を想定しています。例えば your-git-server.example.com のようなサーバがあって your-git-server.example.com/someone/logparser のようなレポジトリを用意した場合、以下のような感じで定義を書いておきます。package logparserfunc NewReader() *rlogs.Reader {        logEntries := []*rlogs.LogEntry{                // ログの取り込み方＋パースの仕方＋場所の定義を                {                        Pipe: rlogs.Pipeline{                                Ldr: \u0026rlogs.S3LineLoader{},                                Psr: \u0026parser.JSON{                                        Tag:             \"your.log\",                                        TimestampField:  rlogs.String(\"time\"),                                        TimestampFormat: rlogs.String(\"2006-01-02T15:04:05Z\"),                                },                        },                        Src: \u0026rlogs.AwsS3LogSource{                                Region: \"ap-northeast-1\",                                Bucket: \"your-backet\",                                Key:    \"logs/\",                        },                },               // いろいろ書く        }        return rlogs.NewReader(logEntries)}そのあと、実際にログを利用するコード内で以下のように呼び出します。package mainimport (        \"your-git-server.example.com/someone/logparser\")func main() {    reader := logparser.NewReader()    ch := reader.Read(\u0026rlogs.AwsS3LogSource{        Region: \"some-region\",        Bucket: \"your-bucket\",        Key:    \"http/log.json\",    })    for q := range ch {        if q.Error != nil {            log.Fatal(q.Error)        }        values := q.Log.Values.(map[string]interface{})        fmt.Printf(\"[log] tag=%s time=%s src=%v\\n\", q.Log.Tag, q.Log.Timestamp, values[\"src\"])    }}どう使っているか以前、会社のブログにも書いたですが、今の仕事ではおよそ20種類ぐらいのログをこのフレームワークを利用して取り込み、いろいろなことに利用しています。このあたりの話はまたいずれ改めて会社のブログなどに書くかもしれません。","link":"https://mztn.hatenablog.com/entry/2019/11/04/150414","isoDate":"2019-11-04T06:04:14.000Z","dateMiliSeconds":1572847454000,"authorName":"mizutani","authorId":"mizutani"},{"title":"クラウドネイティブなハニーポットをAWS上に作ってみた話","contentSnippet":"TL;DRAWSのマネージドサービスを活用して低インタラクション型のハニーポット環境を作ったコストも月々約$15で運用可能コマンド3回ぐらいで誰でもデプロイできるようになっているので興味があれば使ってみてくれよな背景AWSに置く低インタラクション型ハニーポット（synに対してsynackだけ返して後は送られてくる通信を監視するやつ）、今ならシャキッとスパッと実装できるんだろうなあああと過去のクソ実装を思い出して悶絶してる— Masayoshi MIZUTANI (@m_mizutani) 2019年2月1日という感じで昔クラウド上で運用していたハニーポットのことをふと思い出したのですが、仕事で多少AWSのサービスを理解した今だったらもうちょっとまともに実装できそうだよなぁ、実装するならインスタンスで完結するんじゃなくてクラウドのマネージドサービスちゃんと使って消耗しない作りにしたいよなぁ、と考えているうちに気持ちが高まってきたのでやりました。また真面目な話としては、自分も情報セキュリティを生業としているので自分自身で脅威情報を収集する手段を持っていたかった、というのがあります。警視庁による定点観測やNICTによる監視報告などから、どのようなポートにどういう攻撃が来ているか、ということを知ることができますが、どのような環境で観測されているかという情報は非公開です。肌感覚ですが、こういったアクセスは対象となるネットワークによって異なる傾向があるように思えるため、自分で把握できる環境の情報をえる手段があると良いなと思っていました。ちなみに「クラウドネイティブ」という言葉の意味は誰が言っていることが正しいのかはよくわかりませんが、「極力マネージドサービスを使って構築する」ぐらいの気持ちで使っています。あしからず。今回扱うハニーポットの仕組みハニーポットと一口に言っても、特定のWebサービスの振りをしたりするものや、仮想環境をまるっと用意して侵入した攻撃者がどういう行動をするか観測するものなど様々なのですが、今回は低インタラクション型なハニーポットを実装しました。やっていることは至極単純で、TCPのsynパケットが来た場合に偽装syn+ackパケットのみを打ち返し、攻撃者側のプログラムにTCPがEstablishしたと誤認させます。そして、その後に続くパケットを収集することで攻撃者がどんな通信を投げてくるのか観測します。以前はC++でこれを実装していたのですが、近代的な機能を使おうとするといろいろ面倒というのもあったのでこれを機にGoで書き直しました。lurkerという名前で実装しており、gopacket というライブラリでパケットキャプチャ、および偽装パケットの生成と送信をしています。前述したとおり低インタラクション型なので、攻撃者の挙動を深追いすることはできないのですが、以下のようなメリットがあります。スケーラビリティが高い: 主な動作が 1) SYNパケットの応答を打ち返す、 2) パケットをキャプチャして保存する、という2つのみなので非常に軽快に動作します。今回はAWSの構成の制約上やっていませんが、大昔に大学の研究室で数百単位のIPアドレスを監視していた際も同じようなアーキテクチャで問題なく可動していました。侵入後の攻撃者の活動を心配する必要がない: 心配する必要がないというより、心配すらできない、が正しいかもしれません。実際に侵入させる系の高インタラクション型のハニーポットだと、侵入された後に外部に対して攻撃などの影響を及ぼさないようにするにはどうしたらいいか、ということを真剣に考える必要があります。場合によっては不正アクセスの片棒をかつぐ事になり厳しい怒られが発生する場合もありつつ、さりとてあまり行動（特に外部との通信）を制限しすぎると何も情報がえられない、という難しい問題があります。ですが、この仕組ではsyn+ackを打ち返すだけしかできないので、そのあたりの心配をする必要はありません。全ポートを監視できる: 通常ハニーポットを運用する場合、Webサービスを偽装する場合はport 80や443、sshを偽装する場合はport 22など、対象となるサービスによって監視するポートが自ずと狭まるものです。しかしこの仕組ではとりあえずどのTCPポートでも受信したパケットに対してはすべからく打ち返すので、全ポートに対するデータが収集できます。これの利点は、攻撃者がそもそもどこのポートに対してスキャンしようとしているかが分かることです。例えばsshはTCPセッション確立後にProtocol version exchangeのパケット（SSH-2.0-OpenSSH_5.3 みたいなやつ）が送信されます。これを見ることでsshは標準ポートの22だけでなく、1022、2222、8022といったポートもスキャンされているという情報を知ることができます。設計方針なるべくマネージドサービスを使う近年においては常識ですよ、と言われてしまうかもしれませんが、すぐに対象のサービスが使えるという以外にも一応以下の効果を期待したということを記しておきます。持続的な運用を丸投げできる: 完全なメンテナンスフリーというわけにはいきませんが、やはり日々の運用の部分を肩代わりしてもらえるというのは大きいです。特に今回作るものは毎日ガッツリ使うというよりは、日々データをためておいて必要なときに確認する、というユースケースを想定しています。そうなると自分で動かしていたサービスがいつの間にか落ちていて、気づいたら全くデータ取れていなかった…という悲しいことも起きがちです。もちろんちゃんと監視の仕組みを入れてアラート飛ばすなどすればいいのでしょうが、その対応の手間も安くはありません。あと、雑に自前でサービスを立ち上げるためにインスタンスを上げっぱなしにしていると中のパッケージが古くなって脆弱性を放置して…などということも起こりがちです。雑多な用途で作るサービスだからこそ、そのあたりの負荷をなるべく減らしたいという気持ちです。監視の仕組みが最初から組み込まれている: こちらも同様に自前で頑張れなくないですが、既存のマネージドサービスだと最初から豊富な監視の機能が提供されています。メッセージ配信サービス（例 Amazon Simple Notification Service）であれば流量など、サーバレス実行環境（例 AWS Lambda）であれば実行回数や実行にかかった時間などをCloudWatch metricsで確認したり、CloudWatch alarmを設定し特定の条件で通知を飛ばしたり、といったことが容易に実現できます（今回そこまでやってないけど）こういったものがデフォルトで提供されているのであまり自分で頑張らなくて良い、というのもマネージドサービスの利点です。データ取得と分析の処理を分離する以前に似たようなアーキテクチャを考えていたときは、基本的にデータの収集と分析を密結合させて、最終的な結果だけをfluentdに流す、という方法をとっていました。言わずもがなですが、その構成だと分析方法の追加や変更、削除をするたびにデータ収集の部分をいじる必要がでてきてしまい、うかつに触れなくなってしまいます。また、データ収集と分析の処理を同じ環境で実施しようとすることで、負荷の重い方がリソース（CPUやメモリ）の制約を受けやすくなってしまう、ということもあります。具体的には後述しますが、そういった理由からマネージドサービスなストレージであるSimple Storage Service (S3) にまずデータ（今回は通信を記録したpcapファイル）を投げ込み、その通信に何が含まれていたか？という処理は後ろ側に任せる、というような構成をとりました。実装というわけで実際の実装に関する解説をしたいと思います。実装は3パートに分かれていて、それぞれ sensor、backend、output と呼んでいます。それぞれCloudFormationをベースとして実装しており、実際のデプロイ方法についてはデプロイの節をご覧ください。sensorパートハニーポット本体が設置してあるパートです。さすがに「TCPのSYNパケットを受けて偽装したSYN+ACKを返す」という処理をマネージドサービスで実現するのは困難だったので、そこはEC2インスタンスを使いました。ハニーポットには管理用と監視用、2つのネットワークインターフェースを接続しています。EC2は自前で2つ以上のネットワークインターフェースを接続すると標準で割り当てられるパブリックIPアドレスが使えなくなってしまうため、Elastic IP Address を2つ確保し、それぞれのネットワークインターフェースに割り当てて*1います。これらは全てCloudFormationを使ってデプロイ可能なようにしています。（ CloudFormationのテンプレート）テンプレートを見るとわかるかと思いますが、（かなり雑なのでちょっと恥ずかしいですが）ハニーポットのソフトウェア本体であるlurkerのバイナリをダウンロードして /etc/rc.local に起動スクリプトを仕込み、実行するところまでを記述してあります。なのでこのテンプレートをデプロイするだけで、AWSに対し外部からどのような攻撃やスキャンがされているのか、というデータを収集し始めることができます。このホスト上で動作するlurkerの仕事は非常に単純です。TCPのSYNパケットを観測したらSYN+ACKパケットを打ち返すTCPやUDPのフロー（IPアドレス＋ポート番号の組み合わせ）ごとに観測したパケットを保持しておくあるフローに対して1分以上通信が発生しなかったらそのフローのパケットデータをS3バケットにpcap形式で保存する先述したとおり、gopacket というライブラリがかなりいろいろやってくれて、偽装パケットを作ったり、パケットをキャプチャしたり、pcapファイル形式にデータを変換してくれたりと、だいたいこれに乗っかってやりたいことができました。データ出力先は思い切って（というか面倒だったので）S3バケットに出力するようにしか作っていません。出力されたpcapファイルは以下のような感じで蓄積されています。現在運用している感触だと、だいたい1日あたり10000個弱、合計10MB弱のpcapファイルが生成されています。backendパートここは単純に2つのマネージドサービスを展開しているのみで、あまり説明することはありません。sensorがデータをアップロードする先のS3、およびイベントを通知するための Simple Notification Service (SNS) が、このbackendパートになります。S3にファイルがアップロード（生成）されると、そのイベント通知がSNSに飛び、さらにそこからoutputパートにあるLambdaが呼び出されます。強いていうとS3にはイベントが発生した際に直接Lambdaを起動する機能もあるので、SNSを使わないでもこの構成は実現可能です。それでもSNSを利用している理由としては、S3からのLambdaの直接呼び出しは1つの宛先しか設定できないために分析したい処理が増えたときに困る、そしてbackendパートとoutputパートをより疎結合にできる、などが挙げられます。outputパート最後が収集したデータをもとに、なんらかの出力をするoutputパートになります。backendパートにおいてS3に生成されたファイルがSNSに通知され、それをトリガーにしてLambdaが起動します。Lambdaには生成されたファイルそのもののデータではなく、どのバケット、どのキーに対してファイルが生成されたかという情報が伝わるだけなので、LambdaがS3バケットにアクセスして対象ファイルをダウンロードしてpcapファイルの中身を分析する、という一般的なS3 + Lambdaの構成になっています。SNSで複数のLambdaに通知を飛ばせるため複数の分析用Lambdaを配置することもできますが、今回はサンプルとして1つだけ「pcapファイルの中身を荒くまとめてCloudWatch Logsに投げ込む」という例をご紹介します。今回、分析用に使うLambdaは python + dpkt で実装しました。ハニーポットのソフトウェアであるlurkerと同じくGoで実装しても良かったのですが、gopacketがlibpcapに依存しておりLambda上でC libraryを使うのは骨が折れそうだったので、今回はネイティブにpcap読み取り機能をもつ（libpcapに依存しない）dpktを利用しました。Lambdaでやっている処理は以下のとおりです。S3からpcapファイルをダウンロードして読み取る送信元IPアドレスや宛先ポート番号を取得しTCPのデータセグメントを再構築するCloudWatch Logsにデータを送信するTCPはデータを再送などできる都合上、重複したデータをキャプチャしている可能性があるためそれを排除する必要があります。今回は特にsyn+ackだけ返してその後の通信を全くしない、というツールの特性上、通常のTCP/IPスタックであれば必ずデータの再送が発生します。今回は各pcapファイルに1つのフローしか入っていない、という条件なのでわりと雑多にストリームの再構成のコードを書いてみました（何か間違っていたらこっそり教えてください）これらの情報を取得した後、以下のようなJSONを生成してCloudWatch Logsに投げ込みます。{  \"init_ts\": 1549870119.960277,  \"last_ts\": 1549870151.089438,  \"src_addr\": \"193.201.224.***\",  \"dst_port\": 22,  \"payload\": \"U1NILTIuMC1XaW5TQ1BfcmVsZWFzZV81LjcuNQ0K\",  \"readable\": \"SSH-2.0-WinSCP_release_5.7.5\\r\",  \"s3path\": \"s3://***/pcap/2019/02/11/07/1549870119_193.201.224.***_172.30.2.***_23300_22.pcap\"}CloudWatch Logsに投入したJSON形式のログは自動的にパースされ、CloudWatch insightを使って実用的な検索などができるようになっています。デプロイ先述したとおり、ご紹介した sensor、backend、outputのパートは全てCloudFormationで記述されていますので、awsコマンドだけでバーンと展開できるようになっています。Prerequisite以下のツールが必要になります。pythonは3系、awscliはここ最近のものなら動くんじゃないかなと思いますが、検証済みなのは以下の条件です。また、言わずもがなですがawscliはAPIキーなどのcredentialをセットアップする必要があります（詳しくはこちら）python \u003e= 3.7awscli \u003e= 1.14.400) テンプレート等の取得普通にgitでtemplateなどのセットを取ってきます。$ git clone https://github.com/m-mizutani/aws-honeypot-templates.git$ cd aws-honeypot-templates1) backendパートのデプロイまず最初にbackendパートを設定します。これはsensorパートが送り先のS3バケットの名前を知っておく必要があること、そしてoutputパートがsubscribeするSNSのtopic名を知らないといけない、という依存関係によります。必要なパラメータを用意しコマンドを実行することで、S3バケットやSNSのリソースが生成され必要な設定が変更されます。必要なパラメータbackend_stack_name: backendパートのスタック名です。任意の名前で問題ありません。$ aws cloudformation deploy \\    --template-file backend.yml \\    --stack-name \u003cbackend_stack_name\u003e \\    --capabilities CAPABILITY_IAMデプロイが完了したら、以下のコマンドでS3バケットの名前を知ることができます。AWSのWebコンソールなどから参照しても問題ありません。$ aws cloudformation describe-stack-resources --stack-name \u003cbackend_stack_name\u003e | jq '.StackResources[] | select(.LogicalResourceId == \"DataStore\") | .PhysicalResourceId ' -r2) sensorパートのデプロイ次にsensorパートを同様にCloudFormationのテンプレートを使ってデプロイします。こちらは必要なパラメータが少々多くなります。必要なパラメータsensor_stack_name: sensorパートのスタック名です。任意の名前で問題ありません（ただし他のスタック名とかぶらないように）VpcId: センサーがデプロイされるVPCのIDです。 (例 vpc-1234xxxx) VPCおよびsubnetは事前に準備しておく必要がありますSubnetId: センサーが接続するsubnetのIDです (例 subnet-1234xxxx)KeyName: センサーにセットするSSHキーの名前です。基本的にトラブルシュート用です (例 default)S3Bucket: backendパートで作成したS3のバケット名を指定してください$ aws cloudformation deploy \\    --template-file sensor.yml \\    --stack-name \u003csensor_stack_name\u003e \\    --capabilities CAPABILITY_IAM \\    --parameter-overrides \\    VpcId=\u003cVpcId\u003e \\    SubnetId=\u003cSubnetId\u003e \\    KeyName=\u003cKeyName\u003e \\    S3Bucket=\u003cS3Bucket\u003e3) outputパートのデプロイoutputパートのテンプレート、およびLambdaで使うコードは output/cwlogs 以下に入っています。（他にも何種類か用意したかった気持ちのあるディレクトリ構成だ、というところだけお察しください）こちらはいくつかの処理が必要なので deploy.sh というスクリプトを実行しています。やっていることは中身を見ればわかりますが、1) pythonのパッケージインストール、2) pythonのコードをzipで固める、3) backendパートのリソース名を取得する、4) 実際にデプロイ、という流れになっています。必要なパラメータregion: AWS のリージョンを指定してください（backend、sensorと同じリージョンにしてください）もしbackend、sensorデプロイ時に特にリージョン指定していなければ aws configure get region で確認できます (例 ap-northeast-1)backend_stack_name: backend パートをデプロイしたスタック名を指定してくださいoutput_stack_name: outputパートのスタック名です。任意の名前で問題ありません（ただし他のスタック名とかぶらないように）code_s3_bucket: Lambdaのコードを置くためのS3バケット名になります。backendパートで用意したS3バケットとは別のものが良いと思います（同じでだめなことはないけど）code_s3_prefix: Lambdaのコードを置くためのS3キーのprefixになります。自動的に \"/\" が末尾に追加されるので、例えば functions とだけ指定してください。（自分で末尾に / をつけると空のディレクトリ名が作成さてしまいます）$ cd output/cwlogs/$ ./deploy.sh \u003cregion\u003e \u003cbackend_stack_name\u003e \u003coutput_stack_name\u003e \u003ccode_s3_bucket\u003e \u003ccode_s3_prefix\u003eCloudWatch Insightでキャプチャしたログを見てみるここまできたらデータ収集、データの蓄積、そして分析結果が一気通貫で動いている状態になっているはずです。CloudWatch insightで結果を確認してみましょう。東京リージョン（ap-northeast-1）を利用しているなら以下のリンクでコンソールが開くと思います。https://ap-northeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-1#logs-insights:コンソールを開くと以下のような画面になっているかと思います。 /honeypot/lurker-cwlogs-output となっているところがLogGroupの選択になります。/honeypot/\u003coutputパートstack名\u003e というLogGroupが作成されているはずなので、自分の環境にあった名前を選んでください。とりあえず「クエリの実行」をクリックしてもなんらかの出力は出てくると思いますが、例えば以下のようなクエリがわかりやすいかと思います。fields @timestamp, src_addr, dst_port, readable, strlen(readable) as len| filter len \u003e 0| sort @timestamp desc| limit 20クエリの意味としては、fields で項目を選択しつつ readable フィールドの文字列を取得して、 filter で文字列が0より大きいものを抽出しています。観測してみると、synパケットだけ飛んできていてペイロードデータが送られてきていないトラフィック（いわゆる普通のSYNポートスキャン）もそれなりにあるので、それを避けるためのクエリです。例として私の環境では以下のような出力がでてきました。どういうものが見えるのか？この仕組を動かし始めてまだ2〜3日といったところですが、いくつか面白い物が見えていたので軽くご紹介します。画像は左から送信元IPアドレス、宛先ポート番号、そして送信されたペイロードとなります。Hadoop YARN ResourceManager への攻撃現在観測している範囲だと、データが送信されている通信の半分以上がこの通信です。S-Owlさんのブログ記事によるとHadoop YARN ResourceManagerに任意のコードを実行できる脆弱性があり、これを探し回っている通信と見られます。SSHへのアクセスこれ上側は全部同じIPアドレスからきているのですが、protocol version exchangeで全部違ったクライアントを騙ってアクセスしてきていました。クライアントの種類によってアクセスを許可・遮断するようなツールやサーバがあったりすんですかね…。バックドアらしきものへのアクセスちょっと見づらいのですが、 /xw1.php というパスに対して h=die(@md5(F3bru4ry)); というデータをPOSTで送信してきています。他にも /xw.php や /xx.php といったパスに対して同様の形式っぽいデータが送られているのを確認しました。具体的になんのツールなのかなどはわかっていませんが、パス名のパターンから考えるに攻撃者が設置したバックドアなどではないかと推察されます。コストさて、冒頭にも書いていますが実際にこれを運用するとどのくらいのコストがかかるか、というのを計算してみました。前提条件は以下の通りで実測値をもとにしています。環境ごとに変化する可能性はありますが、大幅にずれることはないんじゃないかなと思います。（2019年2月現在の東京リージョンの価格情報をもとに計算しています）1日あたりに生成されるpcapファイルの数：10000個1日あたりの生成されるpcapファイルのサイズ合計：10MB1時間あたりのSNSに流れるデータサイズ：300KBLambda の1時間あたりの実行時間合計：350秒S3のデータ保持期間：1年なにか抜けてる要素があるかもしれませんが、支配的なのはEC2インスタンスの使用料＋EIPの使用料なのでまあそんなにズレはないかなと思います。ということで、月額約$15ほどでこの仕組を運用できることがわかりました。これは無料枠を使っていない前提なので、普段AWS上のリソースを使っていないアカウントならさらにお安くなります。価格帯的に高いか安いかは人によるでしょうが、趣味で動かすのであれば高すぎるということはないんじゃないかな、と思う次第です。今後の課題Elastic IP addressを自動更新するようにする : このような定点観測型のハニーポットの弱点はIPアドレスが固定だと攻撃者に気づかれて、そもそもアクセスを敬遠される、という恐れがあります。ただ、これはAWSを利用することで解決可能で、定期的にEIPをつけかえれば（同じ観測点ではないものの）攻撃者に観測点を常に特定されている、という状況を回避できます。一方でこの仕組を作ろうとするとCloudFormationと相性があまり良くない、という問題があります。スタックを削除する際に付け替えるために新たに取得したアドレスをちゃんと片付けられるようにしないとならず、それについてはちょっと頭を悩ませるところです使用するElastic IP addressの数を減らす：AWS ではデフォルトでEIPの利用がアカウントごとに5個までと制限されています。この仕組は1つのセンサーをデプロイするだけで2つも消費してしまうため、最大で2つまでしか利用することができなくなっています。このことからEIPを1つだけで運用する、もしくはEC2 インスタンスに標準で付与されるIPアドレスを利用してうまくできないか、というのは検討の余地があるかなという状況です。自分のパケットがデータに含まれない問題をどうにかする : gopacket非常に便利ではあるのですが、どうも自分自身が射出したパケットはキャプチャできない、という構造になっているようです。なので現在収集されているpcapにはsyn+ackパケットが含まれておらず、pcapを読み込むツールによっては期待された動作をしない懸念があります。これはTCPの応答プロセスとキャプチャのプロセスを分けるなどしてうまくできないかなとは考えています。*1:本当は1つのElastic IP Addressのみで運用したいのですが、詳しくは今後の課題に後述","link":"https://mztn.hatenablog.com/entry/2019/02/11/182903","isoDate":"2019-02-11T09:29:03.000Z","dateMiliSeconds":1549877343000,"authorName":"mizutani","authorId":"mizutani"},{"title":"テキスト出力されたログファイルから元のログフォーマットを分析するツールを作った","contentSnippet":"タイトルの通りなのですが、昔ちょっとやっていたテーマに関連したツールをGo言語の練習がてら作ってみました*1。ログファイルから元のログフォーマットを分析するとはここで言うログのフォーマットというのは所謂フォーマット文のことを指します。log.Printf(\"Requested from %s\", ipAddr)このコードから以下のようなログが出力されます。2018/05/23 23:25:00 Requested from 10.0.2.12018/05/23 23:25:10 Requested from 192.168.1.52018/05/23 23:25:24 Requested from 10.0.1.5元になったフォーマットは %s の部分にIPアドレスらしきものが埋め込まれて下図のようなテキストとして出力されます。この例は非常に簡単なので下から上を推測するのは容易ですが、内容が複雑になってくると「これ値なのか固定文なのかどっちだ？」ということがまれによくあります。この下の出力から上のフォーマット文（に近いもの）を推測するのが今回作成したツールになります。このツールは 1) すでに出力されたログファイルからフォーマットを推定する、そして 2) 推定したフォーマットを利用し、そのフォーマットに該当するログがログファイルのどのあたりに出現したのかを示す という2つの機能を実装しています。なんでこんなツールが必要なのか実際には、正規化・構造化されたログデータのみを扱う環境であればこのツールは不要ですが、以下のような状況で役立ちます。ログの全体像を把握したい場合 : セキュリティ分析の文脈で特に多いと思いますが、今まで見たことのない大量のログをみてそこから知見を導き出さないと行けない場合があります。そういったときにひたすら less コマンドで眺めようとしても人間には厳しいので、全体としてどういうログがあるのか？ そしてどういう分布をしているのか？ ということがわかると分析のとっかかりが非常に楽になります。特にセキュリティ分析で必要なのは多くの場合全体の99%を占める通常のサービスに関するログではなく、何か異常が起こったポイントになります。異常が起こった際のログというのは通常見られないエラーや処理が発生しやすいため、異常なログ＝珍しいフォーマットのログがどこに出現するのかを把握できると、そこにまず注目して分析するという足がかりを作ることができます。テキスト形式で出力されるログを再利用しないとならない場合 : すでにサービスなどが稼働しておりテキストではログを出力するという場合、そのログを正規表現にかけるなどして中に含まれている値を抽出する必要があります。仕様書がある場合はいいですが、そうでない場合はソースコードを見るか、もしくは正規表現を書く→網羅でいているか確認する→正規表現を直す、みたいなことを繰り返さないとならずかなり面倒です*2。このツールだと抜くべき値の正規表現の推定まではしてくれませんが、既存のログから分かる範囲ではどこまでやればいいかを網羅できるので作業的に楽になります。使い方Go言語を使う環境が整っていれば go get github.com/m-mizutani/logptn でインストールされます。GitHub - m-mizutani/logptn: Generate Log Format from real log data例として（短いものですが）以下のようなログをツールに入力してみます。$ cat test.logFeb  1 07:56:49 pylon sshd[5153]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=192.168.0.3  user=rootFeb  1 07:56:51 pylon sshd[5153]: Failed password for root from 192.168.0.3 port 7176 ssh2Feb  1 07:56:51 pylon sshd[5153]: Connection closed by 192.168.0.3 [preauth]Feb  1 08:01:26 pylon sshd[5156]: Invalid user upload from 192.168.0.3Feb  1 08:01:26 pylon sshd[5156]: input_userauth_request: invalid user upload [preauth]Feb  1 08:01:26 pylon sshd[5156]: pam_unix(sshd:auth): check pass; user unknownFeb  1 08:01:26 pylon sshd[5156]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=192.168.0.3Feb  1 08:01:28 pylon sshd[5156]: Failed password for invalid user upload from 192.168.0.3 port 51058 ssh2Feb  1 08:01:28 pylon sshd[5156]: Connection closed by 192.168.0.3 [preauth]Feb  1 08:05:01 pylon CRON[5159]: pam_unix(cron:session): session opened for user root by (uid=0)Feb  1 08:05:01 pylon CRON[5159]: pam_unix(cron:session): session closed for user rootFeb  1 08:05:54 pylon sshd[5162]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=192.168.0.3  user=rootFeb  1 08:05:56 pylon sshd[5162]: Failed password for root from 192.168.0.3 port 33005 ssh2Feb  1 08:05:56 pylon sshd[5162]: Connection closed by 192.168.0.3 [preauth]Feb  1 08:10:28 pylon sshd[5165]: Invalid user mythtv from 192.168.0.3Feb  1 08:10:28 pylon sshd[5165]: input_userauth_request: invalid user mythtv [preauth]Feb  1 08:10:28 pylon sshd[5165]: pam_unix(sshd:auth): check pass; user unknownFeb  1 08:10:28 pylon sshd[5165]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=192.168.0.3Feb  1 08:10:30 pylon sshd[5165]: Failed password for invalid user mythtv from 192.168.0.3 port 59978 ssh2Feb  1 08:10:30 pylon sshd[5165]: Connection closed by 192.168.0.3 [preauth]Feb  1 08:15:01 pylon CRON[5168]: pam_unix(cron:session): session opened for user root by (uid=0)Feb  1 08:15:01 pylon CRON[5168]: pam_unix(cron:session): session closed for user rootFeb  1 08:15:26 pylon sshd[5171]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=10.2.3.4  user=rootFeb  1 08:15:28 pylon sshd[5171]: Failed password for root from 10.2.3.4 port 60733 ssh2Feb  1 08:15:28 pylon sshd[5171]: Connection closed by 10.2.3.4 [preauth]Feb  1 08:17:01 pylon CRON[5173]: pam_unix(cron:session): session opened for user root by (uid=0)Feb  1 08:17:01 pylon CRON[5173]: pam_unix(cron:session): session closed for user rootFeb  1 08:20:35 pylon sshd[5177]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=10.2.3.4  user=rootFeb  1 08:20:37 pylon sshd[5177]: Failed password for root from 10.2.3.4 port 44877 ssh2Feb  1 08:20:37 pylon sshd[5177]: Connection closed by 10.2.3.4 [preauth]Feb  1 08:25:01 pylon CRON[5180]: pam_unix(cron:session): session opened for user root by (uid=0)Feb  1 08:25:01 pylon CRON[5180]: pam_unix(cron:session): session closed for user rootFeb  1 08:25:16 pylon sshd[5183]: Invalid user user from 10.2.3.4このデータを入力させると以下のような出力をします。./logptn test.log2018/05/20 13:30:55 arg:test.log     4 [4ffb267b] Feb  1 *:*:* pylon sshd[*]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=*  user=root     4 [845f4659] Feb  1 *:*:* pylon sshd[*]: Failed password for root from * port * ssh2     6 [847ccf35] Feb  1 *:*:* pylon sshd[*]: Connection closed by * [preauth]     3 [de051cd9] Feb  1 08:*:* pylon sshd[*]: Invalid user * from *     2 [8e9e2a13] Feb  1 08:*:* pylon sshd[*]: input_userauth_request: invalid user * [preauth]     2 [22190c74] Feb  1 08:*:* pylon sshd[*]: pam_unix(sshd:auth): check pass; user unknown     2 [83fba2bf] Feb  1 08:*:* pylon sshd[*]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=192.168.0.3     2 [f1ba83ea] Feb  1 08:*:* pylon sshd[*]: Failed password for invalid user * from 192.168.0.3 port * ssh2     4 [e4a6f815] Feb  1 08:*:01 pylon CRON[*]: pam_unix(cron:session): session opened for user root by (uid=0)     4 [5256845b] Feb  1 08:*:01 pylon CRON[*]: pam_unix(cron:session): session closed for user rootこの出力では、左から「そのフォーマットが出現した回数」「フォーマットID」「推定されたフォーマット」になっています。また、推定されたフォーマットにおいて、値として埋め込まれると思われる部分を * という記号に置き換えています。この例ではサンプルが少ないため、IPアドレスの部分が * になっていないものもありますが、サンプル数が増えるとこれも * に置き換わります。上記は人間が読みやすいテキスト形式での出力になっていますが、別のプログラムで扱えるようにjson形式でも出力できます。./logptn test.log -d sjson | jq . {  \"formats\": [    {      \"segments\": [        \"Feb  1 \",        null,        \":\",        null,        \":\",        null,        \" pylon sshd[\",        null,        \"]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=\",        null,        \"  user=root\"      ],      \"count\": 4    },(snip)さらに、そのフォーマットがログ全体のどの行数あたりに現れたのかをHTML形式で一覧にして表示することもできます。$ ./logptn  ./var/log/secure -d heatmap -o secure.html上記のコマンドでログのフォーマット、およびそれが何行目あたりに出現したのかを示すヒートマップを作成できます。ヒートマップは左が推定されたフォーマット、上のヘッダが行数（何行目〜何行目）、右が合計ログ数になっています。下の画像がちょっと小さくて見づらいですが、HTMLファイル自体はここからもダウンロード可能です。大きい画像性能計算量としては O(NM) になり、N がログファイルに含まれるログの総数、 M が推定されたフォーマットの数になります。いろいろなログファイルで試してみましたが M は10〜100ぐらいに収束するのでだいたいは N 、つまりログの総数が影響します。雑にしか計測していませんが、M=40 ほどになるデータに対して MacBookPro Early 2015 (2.7 GHz Intel Core i5) で動かして、おおよそ30,000 logs/sec 程度で動作しました。多分コード的にはもっと最適化できるんですが、まだそこまでは手を付けてません。動作の仕組みこのあとはどうやってフォーマットを作成しているかという話なので、興味のある方だけどうぞ。すでに出力されているテキストログから元になったログフォーマットを推定する話は昔から研究としてありますが*3、今回 logptn で実装したのは非常に簡易なアルゴリズムになっています。昔は自分もいろいろとこねくり回した方法を考えたのですが、どれだけ複雑なアルゴリズムを使ったところで「まあ所詮は推測にすぎないよね」という割り切りを得たので、極力シンプルに実装しました。手順このフォーマット推定のアルゴリズムは4段階に別れており、それぞれ順番に解説します。Phase1) Import logsこのアルゴリズムはバッチ型（ある程度の固まった量のログデータをまとめてから処理するタイプ）になります。一方で次々到着するログを逐次的に処理するオンライン型やストリーム型と呼ばれる手法もありますが、今回はもとになるデータセットは事前に決まっている（あとから増えない）ものとします。取り込みに関しては全く難しいことはしておらず、現在は完全に1行1ログとして分割して切り分けています。全体の流れとしては複数行のログでも対応できないことはないアルゴリズムになっていますが、複数行で切り分ける基準がログごとに様々すぎるので、現状では対応していません。Phase2) Chunkingデータを1つずつのログ（現在は1行のテキスト、と同じ）に分割したあとは、そのログに含まれる単語などに分解する Chunking を実施します。これはログ内に埋め込まれる値は単語などの短い単位として出力される、という前提をおくことで、値として出力される単語の長さが違うことでフォーマットがばらつくのを防ぐのが目的です。例えば 0.0.0.0 と 255.255.255.255 という2つが別のログに現れたとしても同じ「IPアドレス」として認識してほしいですが、これを一文字ずつ比較しようとすると2つはかなり異なる文字列長になります（0.0.0.0 が7文字、255.255.255.255 が15文字）もちろんこういう文字列長の違いをうまく吸収してくれるアルゴリズムなら気にしなくていいのですが、だいたいは問題を単純化するために事前にログを単語（ここではchunkとよんでいます）に分割しています。分割については、これが自然言語的な英語であれば単純に空白で区切ればいいのですが、ログファイルというのは様々な記号が含まれてそれによって区切られている場合もあるので、なかなか空白だけというわけにはいきません。実際にはある特定の記号が出てきた場合に区切るという実装にしており、現状 logptn だと \\t!,:;[]{}()\u003c\u003e=|\\\\*\\\"' がデフォルトの区切り文字となっています。これらのうちどれかがでてきたらchunkとして切り分けてきます。（詳しくはこちら を参照）この記号の選び方は完全に自分の経験に基づくヒューリスティックなものなので明確な根拠はないですが、まあだいたいうまくいっている感じです。一方、これらの記号にもとづいてこのフェーズである程度正しく文を分割できることが前提となっているため、日本語のようなマルチバイト文字のログについてはおそらくうまくいきません。また、ヒューリスティックを入れていいと考えるなら正規表現などによって日付やURL、Eメールアドレスなど値として埋め込まれると考えられるような形式の値をを特定して切り出してしまえばより精度があげられます。実際、それを見越して正規表現でそういった機能も実装したのですが、Goの正規表現モジュールが想像以上に遅くて厳しかったので、現状デフォルトの機能としては外しています。（一応、 --enable-regex オプションを使うと有効化はされます）実際にこの方法で文を分割すると、以下のようになります。Before: pam_unix(cron:session): session closed for user rootAfter: pam_unix, (, cron, :, session, ), :, , session, , closed, , for, , user, ,  rootPhase3) ClusteringChukingされたログが出揃ったら次は類似しているログをクラスタリングします。クラスタリングも非常にシンプルなアルゴリズムを使っています（名前知らないだけで既存のクラスタリング手法かもですが）。以下の手順をログ1つずつ順番に試します。Chunk長（1つのログから生成されたChunkの数）が同じクラスタがなかったら手順終了同じChunk長のクラスタ全部に対して距離を計算する クラスタとログの距離は、クラスタの中心になっているログとどれくらい近いかで計算する。ログ間の距離は全体でChunkが一致する割合を見て、割合が高いほど近いと判断する。クラスとの距離がthreshold（デフォルトでは0.7）を超えていたら、もっとも近いクラスタに組み込まれて手順終了もしthresholdを下回るクラスタのみだったらそのまま終了クラスタに組み込まれずに終了した場合は、そのログを元に新しいクラスタを生成します。これをすべてのログに対して実施します。Phase4) Estimate Formatクラスタが生成されたらあとはフォーマットを推定するのみです。これも非常にシンプルなアプローチで、クラスタ内のすべてのログに対して積をとっているイメージです。クラスタ内のログを L1, L2, ... , Ln としたとき、まず L1 と L2 で積をとって、L' を生成し、そのあとは Li と L' で積をとる、という処理を繰り返します。L1: Requested  from  10.0.2.3L2:  Requested  from  192.168.0.1L': Requested  from  null同じクラスタだとChunkの長さがすべて同じになるので、互いのログのChunkを先頭から比較します。同じ内容であればそのまま、もし異なる内容であれば null とします。この null がフォーマットの中で値が入ると考えられる部分となります。このあと L3 と比較する際は null の部分はどのChunkと比較しても必ず null になります。この操作をクラスタ内のすべてのログに対して実施すると、最終的にそのクラスタのすべてのログに適合できるフォーマットが生成（推定）できるということになります。この手法の弱点前述したとおり、このアルゴリズムはChunkingがある程度正しくできていて、かつ1 Chunk＝埋め込まれる値になることが強い前提となっています。そのため、たとえばChunkに分割されやすい任意長の文字列が登場するようなログ（極端に言えば、例えばユーザによる入力をそのままログに書き出すようなログ）に対しては非常に低い精度になると見込まれます。また任意長でないとしても同様にChunk分割によって1つの値が複数に分割されてしまうようなログには耐性がないと言えます。また、現状のアルゴリズムだと複数のクラスタから同じフォーマットが生成される可能性があります。クラスタを生成する時のアルゴリズムがわりと雑なのでたまたま距離の計算でしきい値を超えてしまったなどの場合に、本来同じクラスタであるべきログが2つ以上のクラスタに分離してしまいます。これについてはまだすっきりした方法を思いついてないですが、生成後のフォーマット同士を比較してマージするというような処理が必要かなと考えています。参考文献LogCluster — A data clustering and pattern mining algorithm for event logs, R. Vaarandi and M. Pihelgas , https://pdfs.semanticscholar.org/3a3a/c31e9f8e4dc3c464825ca192fddf0e18b2ba.pdfClustering Event Logs Using Iterative Partitioning , Makanju, Adetokunbo A.O. and Zincir-Heywood, A. Nur and Milios, Evangelos E. , https://web.cs.dal.ca/~zincir/bildiri/kdd09-ane.pdfLength Matters: Clustering System Log Messages using Length of Words, Keiichi Shima, https://arxiv.org/pdf/1611.03213.pdfDrain: An Online Log Parsing Approach with Fixed Depth Tree, Pinjia He, Jieming Zhu, Zibin Zheng, ,http://www.ieeeconfpublishing.org/cpir/UploadedFiles/ICWS17_11570_camera.pdf*1:言い訳がましいのですがまだGo言語まともに書き始めて1ヶ月ぐらいという有様なので実装物について、流儀的にこういうの違うよ、とかGoならこういうふうにも書けるよ、みたいなコメントは大歓迎です*2:そんな環境のほうがおかしいだろというツッコミはあると思いますが、稀によくあるシチュエーションでした。特に前職*3:参考文献として幾つか論文へのリンクを貼っておきました","link":"https://mztn.hatenablog.com/entry/2018/05/24/081517","isoDate":"2018-05-23T23:15:17.000Z","dateMiliSeconds":1527117317000,"authorName":"mizutani","authorId":"mizutani"},{"title":"2018年春アニメはネット配信だけで視聴できるのか","contentSnippet":"背景先日、会社でアニメの雑談していたときに「そういえば今時のネット配信はテレビ放映中のアニメのカバレッジってどれくらいなんだろう？」と気になりました。だいぶ配信が整備されてきたようなそうでもないような…。個人的には四半期に一度せっせと録画の準備をしたり、HDDの残り容量を気にしていろいろケアしたり、録画に失敗したりというので消耗するのはそろそろやめたかったのでなるべくならネット配信で見てしまいたい派です。ということで、現実的にどれくらいの視聴ができるのかというのを知るべく、2018年春アニメのネット配信状況をまとめて見ました。結果2018年春アニメ ネット配信一覧 - Google スプレッドシート※ 雑に作った＆後から情報が更新されることもあるようなので、間違いなどあればtwitterなどで指摘してもらえればと思います結論から言うと「完全にネット配信だけで生きていくことはできないが、頑張ればわりといける」です。まとめはある程度配信数を揃えていそうなサイトで、かつ月額定額制で（少なくともその期にやってるアニメは）定額のうちに入っているものを対象にしたつもりです。（ニコニコ、DMMなどは1週間で無料期間が終わってPay per viewになるので除外しました）バンダイチャンネルdアニメストアAamzonビデオ・プライムビデオGYAO!AbemaTV楽天TVHuluビデオマーケットNetflix以下、まとめていた時の気づき。配信数はバンダイチャンネルとdアニメストアの二大勢力。しかしそれでも30本ちょいで今季から新しく始まった72作品の半分に届いていない日中や夕方にやるような本来子供向けのアニメはあまり配信されていない傾向にある。そのためみたいコンテンツが深夜アニメ枠ならかなりがカバーされているAmazonビデオやNetflixは二大勢力には数で劣るものの、独占配信のコンテンツがいくつかある","link":"https://mztn.hatenablog.com/entry/2018/04/07/171537","isoDate":"2018-04-07T08:15:37.000Z","dateMiliSeconds":1523088937000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Web系企業に転職して最高だったという話をしたい","contentSnippet":"11月にSI企業からCookpadにセキュリティエンジニアとして転職して1ヶ月たったのですが、いろいろ感銘をうけたのでその気持を忘れぬうちに文章に残しておきたいと思います。disclaimer個人の主観であり、客観的にSI企業が悪いとかWeb系が良いとか言っているわけではありません。かなり前職disな話っぽくなってしまっていますが、そこは企業としての性質の違いだとご理解いただければ幸いです。当該企業からはお金を頂いています。予めあしからずご了承ください。しがらみが少ないCookpadはWeb系の中でもかなり規模が大きい方だとは思うのですが、それでも前職のグローバル含めた規模のおそらく1/1000ぐらいであり、自分にとってはとても風通しの良い体質に思えます。新しく何かを始めようとするときも、関係する人と立ち話で「こんな感じにしようと思うんだけどどうですかね」みたいなところをざっと決めて作りながら物事を進めていく…というやり方だと感じています。Rough Consensus and Running Codeという世界ですね。もちろんこの1ヶ月の間に細かい手戻りも何度かあったりしたのですが、ちゃんと合意を取りながらすすめると言ったやりかたを超えるスピード感で仕事をするのが重要と感じています。（もちろんこれは対象の規模などにもよりますが）また、サービスなどに直結するような内容でも素早く動いていくことを重視しているように感じています。前職では何かしようとするとだいたい2〜3つ以上の力学というか外圧のようなものがあり、それをまずどうにかしないといけませんでした。グループ内部ではわりと好きにやらせてもらっていたのですが、その外に出ようとした瞬間に壁を突破したり調整したりが必要でそこで疲弊してしまうことが少なくありませんでした。現職では担当者同士ですぐ話をして次のステップへ進めるというサイクルが短く回っているため、むしろ振り落とされないよう頑張ってついていかねばと思う場面も少なくありません。強いエンジニアが多いとりあえず、右を見ても左を見ても豪傑ばかりという印象です。前職でも研究所に学術的研究に秀でた方は多くいらっしゃいましたが、正直なところエンジニアリングが得意という人は全体でもかなり少なかったです。本当はエンジニアリングも得意だけど、そういうのが仕事の内容的に見えてこないというだけだったかもしれませんが、全体としてエンジニアリングにあまり積極的でない空気感を感じていました。当然ながら現職ではエンジニアリングは非常に重要な位置づけとなっており、これを蔑ろにすると（多分）人権を失います。象徴的なイベントとして、入社後にちょうど社内ISUCONが開催され私も参加させてもらったのですが、出張や休暇などでいない人を除いて全技術職が参加必須というのに驚きました。技術職と言っても様々な分野の方（インフラ、サーバサイド、フロントエンド、モバイルアプリ、研究職）がいらっしゃるわけですが、皆さんほぼ基本的な技術は一通りできるのは当たり前で、その上で自分の得意分野を活かして競技に参加していました。クックパッドの社内ISUCON始まりました pic.twitter.com/gI6ewazyzM— Issei Naruta (@mirakui) 2017年11月22日また、CTOが「今日一日業務が止まるのはとても手痛いが、それでもやる価値がある」と言っていたのがとても印象的で、ちゃんとエンジニアの育成に力を入れているんだなと思いました。セキュリティの分野についても入り組んだ攻撃や防御の話に通じている人はあまりいませんが、実践のサービス開発と運用の部分については長年の蓄積を持つ人が多く、学ばせてもらうところが多くあります。そういった環境に身を置けるというのはエンジニアとしてありがたいことだと思います。当事者意識があり、サービス・環境の改善にとても前向き自分たちが作っている・使っている環境を常に良くしていこうという文化を強く感じます。前職の場合、基本的には本社なり別部署が決めたものを（それがどんなに使いづらいものでも）言われるがままに使うというのが基本でした。規模の大きさを考えると仕組みや使うものを決める人と使う人を分けたほうが仕事が明確になって良いのでしょうが、使いづらさやだめなところがいつまでも改善されないというフラストレーションがありました。現職場では自分達が使うものを自分たちで選び、時には作るといったことをするため、常に「どうすると良くなるか？」といった方向を見ているなと感じています。これは今あるものを良くするためにも重要なことだし、その良くなったものをベースにまた次の新しいことを始めるのにも活きてきます。また、そうするべきかという議論や検討はもちろん必要ですが、ソフトウェアであれば自分で作ってしまっても良いわけで、ものづくりが好きな自分としてはそれも魅力の一つになっています。自由にオープンソースにコミットできる正直、これが一番強烈だったかもしれせん。入社する前から外部に対してアウトプットしていくことは評価にも含まれており望ましいという話は聞いていたのですが、実際にとても自由な状況でした。OSSに関するポリシーを見てみると \"従業員は自分の良識に基づいて、業務時間中に開発したソフトウェアをOSSで公開できる\" という説明を見つけ、あまりの神々しさに見た瞬間目が潰れるかと思いました。目がーっ！前職では知財やそれに準じる成果物が非常に厳しく管理されており、私的時間に書いたコードですらOSSとして公開あるいはcontributeするのに内部レビューと承認が必要でした。おかげでOSS的活動が好きな自分としては少なからずストレスではあったのですが、それが完全に開放され翼を授かった気持ちです。というかむしろ、前職との違いに頭がクラクラしています。おかげで、これまでgithub上でPRを送るというOSS活動に縁がなかったのですが、先日始めてPRを送りmergeされてました。実に大したことじゃないんですが、ささやかながら嬉しい気持ちになっています。今後は自分で書いているOSSだけでなく、他のOSSにも積極的に貢献していきたいと考えてます。その他あまり本質ではないのですが、その他感動したことなどをいくつか。いわゆる今時の仕組みを使った開発・運用社内で動いているシステムやフレームワークを見て「おお、これが噂に聞いたgitでconfigのバージョン管理をして自動デプロイされるというあれか…！」と感動していました。github eterpriseまでは前職でも使っていたのですが、普通にコードのバージョン管理をするだけで（それでも社内ではかなり珍しい感じでしたが）そういった今時っぽい使い方はしていませんでした。まあがっつり運用というほどではなかったので、そこまでする必要がなかったと言えばそうなんですがね…。開発マシンなどマシン自体は前職もそこまで悪くなかったですが、現職ではさらにもう一回り上のスペックになっています（MacBookPro メモリ16GB）。基本、全員が4Kディスプレイを使っています。キーボードやマウスについても、自分は最近 Realforce とLogicool G900 がベストな組み合わせなので「ちょいと値は張るけど新しく職場用に自分で買うかー」と思っていました。が、この話をしたら「いや、普通に発注してくださいよw」と言われするっと申請したらしゅっと支給されてとても感動しました。無限のコーヒーやスナックがあるまったく本質ではないし、前職にいたときもコーヒー買うお金をケチったことなどないのですが、やはり無料で供給されると思うと気分が全く違いますね。ここしばらくカフェインをコードに変換する仕事をしていました。おわりにまだ転職してからたかだか1ヶ月なのでこれから見えてくる大変なことや苦労も色々あるとは思うのですが、今のところ職務内容も含めて、転職してよかったと思える生活をしています。この記事は別にリクルート目的というわけではないので特にリンクなどは貼りませんが、現職ではセキュリティエンジニアだけでなくいろんな職種を募集しているので、興味のある方は気軽に声をかけてもらえればと思います。追記コメントとか見てたら「給与や労働時間の話がないのは闇」って書かれていて、みんなよく訓練されてるなぁと感心してしまいました。気になる方も多いと思うので一応追記しておきます。給与は前職で「独身一人暮らしが雑に出費しても貯金できる程度」もらってると書きましたが、そこからちょい上乗せするくらいもらっています。転職時にあんまり給与交渉しなかったので場合によってはもっとあがっていたかもしれません。勤務時間は基本1日8時間となっていてフレックスタイム制です。残業時間は先月で確か20時間ちょいぐらいだったと記憶していますが、これは働きはじめでいろいろ慣れていなかったこともあり、効率的にやればもっと短縮できそうではあります。","link":"https://mztn.hatenablog.com/entry/2017/12/03/122429","isoDate":"2017-12-03T03:24:29.000Z","dateMiliSeconds":1512271469000,"authorName":"mizutani","authorId":"mizutani"},{"title":"情報セキュリティ関連の求人","contentSnippet":"先日転職したわけですが、転職活動序盤に「そもそも情報セキュリティ関連の求人ってどういうのがあるんだろう？」と思ってばーっといろいろな職種を見渡していました。その結果、概ねこういうカテゴリの募集があるのか、という知見を得たのでまとめてみます。これから情報セキュリティ関連の職種への就職・転職を考えている人の参考になれば幸いです。なお、筆者の個人的嗜好によってバイアスがかかっている可能性は多分にあり、まったくもって網羅性を保証するものではありません。脆弱性診断自社で開発するプロダクトやサービスを検査し、脆弱性を発見する仕事。また開発物のチェックだけでなく、セキュアな開発のガイドラインを作成するというような仕事が付け加えられている場合もある。プロダクトやサービスに直接関連する開発の知識・経験が求められる。SOCオペレータサーバやネットワークを監視してセキュリティインシデントを発見・対応する仕事。非常に規模が大きい自社サービスを抱えているところでは自社内だけを対応するケース（プライベートSOC）もあるが、おおむね契約したお客さんの環境を監視するManaged Security Serivceの要員を募集している場合が多い。監視機器の環境構築・導入・保守も担当する。インシデントを発見した場合に報告するだけなのか、インシデント対応をサポートするのかなどは会社によって異なる。社内全体のリスク管理個別のプロダクトやサービスの脆弱性を検査するだけでなく、社内全体のリスク評価の実施して改善案をだしたり、インシデント発生時の演習のとりまとめをやったりする。CSIRT (Computer Security Incident Response Team) に近い業務を求められるものもある模様。かなり上級職で給与レンジも高いが、幅広く深い知識と経験が要求される感じがした。ITシステム部門（セキュリティ担当）大手日系企業などに多い。社内のIT利用を統括するIT部門においてセキュリティ関連の業務を担う。社内でIT機器を使う際のセキュリティ関連ガイドラインを作成したり、ISMSなどのレギュレーション対応、セキュリティベンダへの発注、監査対応など諸々を対応する模様。自分で手を動かしてテクニカルなことをやる場面は少なそう。インフラエンジニアIT部門とやや似ているが、どちらかというと自社サービスのアプリケーション、ミドルウェア以外の部分（OS、ネットワーク、サーバ管理など）を担当し、その中でセキュリティ業務も担当すると言った感じ。どちらかというとセキュリティはおまけ要素っぽさがある。セキュリティプロダクトベンダのテクニカルセールスやサポート外資系ベンダに多い。日本でプロダクトを売る時に導入や運用において起こる技術的な課題を解決する。またはプロダクトを導入後の問題に対して対応するようなポジション。外資系だとおそらく上司が海外にいるとか普通にあるっぽいので求人で英語力必須とある。コンサルタントお客さんのセキュリティ上の課題を洗い出し、ソリューションまでの道筋を示したりする。観測した範囲だとセキュリティ専門にやるというよりはITコンサルの中の一部の業務という感じっぽい。ここまでくるとあんまりエンジニアという枠ではないかも。その他リサーチャー：脅威分析などを専門にやるポジション。募集要項を見る限り学会などでの発表を目指すような研究者ではない（トーマツ等）セキュリティプロダクトベンダの開発エンジニア：国内で募集している例はかなり少ない（トレンドマイクロぐらい？）インシデントレスポンスチーム：まれに見かけた。自社内のインシデント対応を担当","link":"https://mztn.hatenablog.com/entry/2017/11/18/123050","isoDate":"2017-11-18T03:30:50.000Z","dateMiliSeconds":1510975850000,"authorName":"mizutani","authorId":"mizutani"},{"title":"退職します","contentSnippet":"2017年10月31日をもって，6年7ヶ月お世話になった日本IBMを退職します．何やってたの？最初に入社したときは研究部門（東京基礎研究所）につとめていてIBMクラウド上のログ管理のシステムやSIEM関連の開発をやっていました．2015年4月から1年半ほどIBM Tokyo SOC (Security Operation Center) で働かせていただいたのですが，いろいろな力学によって2016年9月ごろにはまた研究部門に戻っていました．研究所では，自分はどちらかというと開発よりのプロジェクトをやることが多く，実験したり論文書いたりというようなアカデミックな活動はあまりできていません．ただ，やはりまわりは一流の研究者というか超人のような人たちが多く，色々刺激されたり勉強させてもらいました．特に学生時代の研究は我流で突き進んでいたところが少なからずあったので，改めて研究のやりかたについて学べたのはありがたかったです．もともと学生時代にIDS（侵入検知システム）まわりをやっていたこともあり，SOCではその経験を活かしつつ，実際の現場ではどのようになっているかということを肌感覚として大いに学ばせてもらいました．最初の頃は純粋にアナリスト業務をやっていましたが、途中から業務効率化や分析の方が面白くなってしまい、後半はそういったツールの開発に取り組んでいました。Tokyo SOCレポート*1もほそぼそと執筆を続けさせてもらい楽しかったです．現職どうだった？素直に書いてみたいと思います．研究所は完全裁量労働で働く時間は相当な自由が効きましたが，一方で海外勢と一緒にやるプロジェクトだったりすると夜中の電話会議もそれなりの頻度でありました．個人的には給与に不満はありませんでした．独身一人暮らしが雑に出費しても貯金できる程度にもらっていました．（少なくとも自分の周りは）仕事に対しては真摯で筋の通った方が多く，直接の人間関係で困ったことなどはほぼありませんでした．非常に古く大きい企業（創業から106年，全世界で社員数40万人弱*2 ）であるため，そういった組織特有のしがらみというか壁を感じる場面は少なくなかったです．何で辞めるの？新しい経験を積みたくなった，というのが最も大きな理由です．開発に従事するのもSOCで監視をするのもそれぞれ楽しさはありますが，情報セキュリティという視点でみるとそれぞれ局所的になってしまっているなと感じていました．一口に情報セキュリティといっても，現実にやならければいけないことは多岐にわたりそれぞれが密に連携している...と思っています．今後，何か一つの技術や活動に注力するとしても，一度全体を見渡して情報セキュリティの設計・実装・運用に携わってみたいと思うようになりました．そのためには現在の会社だとどうしても「BtoBのベンダ」という立ち位置になって局所的な話になりがちになってしまうため，もっと自分が全体に責任をもって取り組めるユーザ企業でセキュリティに取り組んでみたいと思って退職を決めました．どこに行くの？11月1日よりCookpad社にてセキュリティエンジニアとしてお世話になる予定です．セキュリティ界隈でまたしばらく活動させて頂くことになるかと思いますし，アカデミック方面にもできれば関わり続けたいと思っております．本職の開発の方々には及ぶべくもありませんが，開発自体は割りと好きな方なのでセキュリティ関連で面白いものを作っていくということもやりたいですね．ということで，今後共何卒よろしくお願いいたします．*1:https://www-935.ibm.com/services/jp/ja/it-services/soc-report/*2:Wikipediaより https://ja.wikipedia.org/wiki/IBM","link":"https://mztn.hatenablog.com/entry/2017/10/28/161725","isoDate":"2017-10-28T07:17:25.000Z","dateMiliSeconds":1509175045000,"authorName":"mizutani","authorId":"mizutani"},{"title":"ZIP SIM使ってみた@ニューヨーク","contentSnippet":"TL;DRとりあえず次回も使ってもいいかな，という印象使ってみたもの・環境など出張で1週間ほどUSに行くことになり，せっかくSIM free版のiPhoneを持っているのでなるべく安く済ませてみようということで日本で買えるprepaid SIMにチャレンジしてみましたwww.amazon.co.jp機種: iPhone SE (SIM free版)使った場所: NewYorkCity および White Plains周辺使ってた期間: 1週間良かった点地下鉄やトンネル内などではさすがに電波がとどかなかったが，それ以外の屋外ではほぼ問題なく使えた通信速度はとても速いとは思わないまでも，過剰なストレスを感じるほどではない．普通ホテルのWiFiと組み合わせて使ったところ，通信量は7日間でおよそ300MB強だったので容量も問題なしただし平日はほとんど仕事でつかっておらず，日中もフルで使ったのは土日だけなので1週間観光であちこち行くとかだと若干心もとないかも追加容量プラン（\"top up\"）もあるので必要に応じて追加金できる良くなかった点このSIMに限った話ではないのかもしれないが，屋内が比較的弱い．例えばJFK空港内とかはかろうじて通信できるが不安定「SIMを指してから5分以内にSMSでUSの郵便番号（ZIP code）を送るとその地域の電話番号が割り振られる」という説明だったのに，指した瞬間にSMSが飛んできて勝手に番号が割り当てられた．まあ通話使わないのでそんなに困らなかったけど・・tipsAPNの設定を変更する必要がある普段IIJ mioを使っているのだがちゃんとプロファイルを削除しないと競合して上手く動かないAPNの設定をしたあと一度iPhoneを再起動したらデータ通信できるようになった","link":"https://mztn.hatenablog.com/entry/2017/06/14/155107","isoDate":"2017-06-14T06:51:07.000Z","dateMiliSeconds":1497423067000,"authorName":"mizutani","authorId":"mizutani"},{"title":"悪意のあるドメイン名のブラックリストをまとめて取得・管理するツール mdstore を公開しました","contentSnippet":"悪意のあるドメイン名のブラックリストを取得・管理する mdstore というツールを作って公開しました。github.com世の中にはフィッシング詐欺やマルウェアによる攻撃に使われるドメイン名のブラックリストを公開しているサービスがいくつかあります（参考）。近年はDGA(Domain Generation Algorithm)を利用したマルウェアもあるためブラックリスト化だけでは追いつかない場合もありますが、それでも既知の攻撃に利用されるドメイン名の名前解決を発見もしくは防止できれば、水際で攻撃による被害を食い止められる可能性があります。ただ、このようなブラックリストは提供しているサイトによってカバーしている領域などが違うため、ブラックリストごとに違うドメインが扱われています。多くのドメインを網羅しようとすると複数のサイトからデータを取得する必要がありますが、フォーマットが異なるなどの理由から一手間必要です。このツールは複数のブラックリストをローカルにダウンロードし、DBに投げ入れて管理・利用することで、この一手間を簡略化しようというものです。2017年1月7日現在、以下の3サイトからデータを取得します。DNS-BH – Malware Domain Blocklist: BH DNS Files, Terms of UseMVPS: Blocking Unwanted Connections with a Hosts FilehpHosts: Download, End User Licence Agreement注意：ブラックリストを提供している各サイトの利用規約では基本的にinternalな利用は認めているようですが、特に商用利用などをする場合には詳細をご自身でよく確認してください。使い方セットアップ本ツールはnodeで動作し、redisにデータを格納します。動作を確認しているバージョンは以下のとおりです。node: v7.2.1, v6.0, v6.1redis: v3.2.6インストールは環境に合わせてよしなにやってください。その後、npmを使ってmdstoreをインストールします。$ npm install -g mdstoreパスを通すのが面倒でなければカレントディレクトリへのインストール（上記コマンドから-g を抜く）でも問題ありません。さらにツール利用前にredis-serverが動作していることを確認してください。install mdstore by npm npm install -g mdstorestart redis server, e.g. redis-server \u0026またデフォルトのredis server接続先 (localhost, port 6379, db 0) 以外を使いたい場合はオプションで指定できます。-s or --host: redis server host-p or --port: redis server port-d or --db: redis server dbブラックリストの更新update コマンドを使うことで各サイトのブラックリストをダウンロードし、DBへの格納までを実施します。すでに対象のドメイン名が存在する場合は、取得したという履歴が追記されます。現在サポートしているサイトは3サイトだけですが、hpHostsが特に件数が多いため完了までに2〜3分かかります。$ mdstore updateupdate: OKドメインを探すget コマンドを使うことであるドメイン名が存在するかどうかを調べることができます。下記では例として 151.ru というドメイン名が存在しているかどうかをクエリしています。% mdstore get 151.ru2017-01-06T14:44:05.347Z { source: 'hphosts', ts: 1483713845.347 }左のカラムが対象となるブラックリストをダウンロードした時刻になります。右側のtsのフィールドがタイムスタンプでこれをDateに変換したものです。ドメイン名がブラックリストに追加された時刻ではない点に注意してもらえればと思います。sourceはブラックリストの取得元を表しており、hphosts、dnsbh、mvpsのように表示されます。その他、データの取得元で掲載されている項目に応じて追加のメタ情報が表示されます。/etc/hosts の生成ローカルのredisに保存してあるデータをもとに、悪意のあるドメイン名を 127.0.0.1 に強制的に変換する /etc/hosts を生成します。これを /etc/hosts と置き換えることで悪意のあるサーバと通信する可能性を低減させることができます。$ mdstore hosts \u003e hosts.txt$ head hosts.txt127.0.0.1       localhost::1     localhost127.0.0.1       www.wwsupport.net127.0.0.1       www.memdesign.co.uk127.0.0.1       www.titanweb.net127.0.0.1       www.livingston.rs127.0.0.1       iphonesupport.co.uk127.0.0.1       up1702.info127.0.0.1       dcstest.wtlive.com127.0.0.1       ad.doubleclick.net.34325.9225.302br.net$ sudo cp hosts.txt /etc/hosts         # Linuxの場合$ sudo cp hosts.txt /private/etc/hosts # macOSの場合データへのアクセスCLIでアクセスする以外には、ローカルのredisに格納したデータはmdstoreのライブラリを使って参照することができます。以下のようなnodeのコードでアクセスできます。DNSの問い合わせログを持っている場合、自分でコードを書くことで不審なサイトへのアクセスがなかったかを確認できます。var mdstore = new (require('mdstore')).Redis();mdstore.update((err) =\u003e {  // synced        mdstore.get('is.the.domain.malicious.com', (err, res) =\u003e {          if (res.length \u003e 0) {                  console.log('yes, the domain name is malicious');          } else {                  console.log('no, this is benign');                }        });});また、当然ですがredis serverに直接クエリすることも可能です。ただし、履歴データはMessagePackでエンコードされているので直接人間が読むのはちょっと難しいです。一応、以下のような1 linerで表示させることはできます。$ redis-cli --raw lindex 151.ru 0 | node -e \"process.stdin.pipe(require('msgpack-lite').createDecodeStream()).on('data', console.log);\"","link":"https://mztn.hatenablog.com/entry/2017/01/07/140443","isoDate":"2017-01-07T05:04:43.000Z","dateMiliSeconds":1483765483000,"authorName":"mizutani","authorId":"mizutani"},{"title":"Oculus Riftはいいぞ。最高だ","contentSnippet":"1月ごろ事前予約開始したのを偶然知り、9万円以上という値段に一瞬たじろぎながらも完全にノリと勢いだけで注文したOculus Riftがついに先週自宅に届いたのですが、この一週間毎日遊んだ感想をまとめておきたいと思います。ひとことで言うと、自分がこの十年の間に触ったガジェットの中では最高に興奮しました。やばい。Oculus Riftやばい。ご存じない方のために念のため説明しておくと、Oculus RiftはHMD（ヘッドマウントディスプレイ）の一種です。これまでのHMDは頭を動かすと自分の頭についているHMD本体も一緒に動くため、映像も一緒に動いてしまうので単純に「頭に普通のディスプレイをくっつけているだけ」に等しい状態でした。しかしOculus Riftは内部・外部にセンサーがあり「頭を動かすと見えている映像も追随して動く」という機能を実現しています。このような製品は総称してVR（バーチャルリアリティ）HMDなどと呼ばれており、HTC ViveやPlayStation VRもその仲間です。どういうことが起きるのかの雰囲気は以下の動画からどうぞ。www.youtube.comまず総評自分の語彙のなさが歯がゆいのですが、とにかくまず言えることは没入感が半端なくすごいです。センサーで頭の動きを追跡して映像を追随させる、と言われると「どうせ微妙に位置がずれたり反応がぶれたりするんでしょう？」と思うかもしれません。というか、自分自身がそう思っていたのですが、使ってみると完璧と言って差し支えないほどの精度で映像が動くという点に驚愕しました。格ゲーをやりこんでいるような人だとフレームレートの違いが認識できるらしいので、そのレベルになるとひょっとしたら違和感を感じるのかもしれませんが、私のような一般人にしてみると映像の動きはリアルと全く変わらないと感じました。一人称視点の映像だと完全にその世界に入りこんで「どこだここ！？」みたいになります。もう一つすごいと思ったのはコンテンツの可能性の幅の広さです（コンテンツそのものの量はまだそれほど多くない）。今までVRはゲームに使うものだよね的な議論が多かったような気がしていますが、思った以上にいろいろな分野で応用できるのではないかと感じました。ゲームも一人称視点のものに限られるかと考えていたのですが、三人称視点のゲームとかシムシティのようなシミュレーションゲーム、あるいはリアルタイム戦略ゲーム（RTS）にも応用できる可能性があります。詳しくは後述。とにかくこればかりはいくら言葉で語っても伝わらないかもしれないので、ひとりでも多くの人に体験してもらえればと思う次第です。やってみたコンテンツここからは実際に自分がさわってみたゲームと感想をつらつらと載せていきます。EVE: Valkyriewww.youtube.com一人称視点のシューティングゲームです。有名どころで言うとエースコンバットみたいな感じですね。ゲームとしては昔からあるようなものなのですが、Oculus Riftによる没入感で「俺、パイロットになってる！！」感が味わえます。最初に発進で射出される場面などは思わず「うわあああああ」って声がもれてしまうような迫力ですし、右や左、さらには後ろをみても宇宙空間が広がっており、完全に気分はマクロスとか宇宙戦艦ヤマトの戦闘機です。これでロボットだったらガンダムだったんだが、、、と思うところではありますが、間違いなく近々ロボット版をどこかが開発・発売すると確信できるほどロボットものとVRは相性がいいと思わせてくれるゲームでもあります。グラフィックスも綺麗なので、迫力があって楽しいです。ゲームとしては3次元空間を飛び回って敵を撃墜したりしていくのですが、プレイとしての大きな違いは視野の大きさと視点移動の概念が大きく変わった点でしょう。Oculus Riftは視野角が100〜110度あるらしいので、格段に目でとらえることができる範囲が広がっています。さらには視点も現実と同じ感覚で動かせるので、レーダーだけに頼らず360度敵を目で追いながら戦うということができます。レーダー機能ももちろなるのですが、近距離で高速旋回する相手のユニットを目で追いながら戦えるだけで全然違う体験でした。単純にゲーム性としてはだいぶ難しくてまだ撃墜されるばかりなのですが、毎日こつこつやっています。全体的にみるとこれまでプレイした中で一番完成度が高いゲームだと感じています。Lucky's Talewww.youtube.com3D空間でキャラクターを動かしてステージをクリアしていく、いわゆるNINTENDO 64やゲームキューブのマリオに近いゲームです。三人称視点なんだから別にこんなHMDつけてやらなくても、と思うかもしれませんが、自分の目の前にそのフィールドそのものがあるというのは想像以上の新鮮さを与えてくれました。いってみれば、自分の机の上に箱庭があって、そこでキャラクターを動かしているような感じでプレイができます。ゲーム性でみても単純にキャラクターを動かしてステージをクリアしていくだけなんですが、これがVR視点になったとたん思った以上に楽しい。マリオなどの視点移動もかなりよく出来ていたとは思いますが、これをプレイすると今まで3Dの三人称視点のゲームでどれだけ視点移動・調整にストレスを感じていたのか気付かされます。あと、これはゲームやコンテンツによって違うので一概には言えないようですが、このゲームではいわゆる「覗き込み」ができます。つまり体を乗り出すことによって建物の裏側にあるアイテムが見えたり、体を動かして少し先にあるステージの状況が見えたりします。なので自分が動きながら「何かを探す」というアクションができ、ゲームの幅が広がるなと感じました。このあたりは本来は広い空間を動きまわることを想定したHTC Viveの方が強いのかもしれませんが、Oculus Riftでも十分に仮想空間を感じ取れました。また、このような「箱庭のようなものを三人称視点で見ながらゲーム」というコンテンツがVRで成り立つとすると、かなりいろいろなジャンルに応用ができるのではと思います。例えばシムシティのようなシミュレーションであっても、自分が作った街を上空から覗き込みながらプレイするというやりかただと違った楽しみ方が生まれると思います。さらにVR HMDと組み合わせて使うVR用グローブも開発中のようなので、シムシティでも模型を置いたり取り除いたりするような感覚で街を作る、というようなインターフェースも実現できると考えられます。他にもリアルタイム戦略シミュレーション（RTS、エイジ・オブ・エンパイア シリーズ、StarCraftシリーズなど）も、これまではマウスを使ってユニットや建造物の操作をしていましたが、例えばイメージとしては動くミニチュアを手で操作しながら戦わせる、というようなインターフェースも考えられると思います。さらにはオンラインのカードゲーム（HearthStoneなど）であっても、本当に対戦相手と対峙しているかのような空間でプレイでき、FaceRigのような技術と組み合わせれば「対面にいるのはゲームキャラクターなんだけどちゃんと対戦相手の表情が伝わってくる」というようなゲーム空間が作り出せます。（それでプレイヤーが楽しくなるかキレやすくなるかは難しいところですが 苦笑）www.youtube.comなにはともあれ、そういった観点から新鮮な驚きを与えてくれるゲームでした。Windlandswww.youtube.comこちらは一人称視点で飛んだり跳ねたりしてステージを進んでいくタイプのアクションゲームです。ワイヤーのようなものを木に引っ掛けながら飛び回るのが特徴です。古い人間なんでゼルダの伝説のフックショットみたいなもの、というのをまず連想したのですが、スパイダーマンの蜘蛛の糸や進撃の巨人にでてくる立体機動装置をつかって飛び回る…といったほうがイメージとして近いかもしれません。このゲームはHTC Viveだと両手でそれぞれ持つ専用インターフェースを使ってプレイするようなのですが、Oculus RiftでもXbox用のコントローラで普通にプレイできます。一人称視点のアクションゲームであり、（ちょいグラフックは雑な感じがするものの）世界を冒険するみたいな感じのプレイ内容になっており、まさにVRの本懐！といったようなゲームなのですが、実際のところ個人的にはこれが一番激しく酔って辛かったです。VRに限らずこの手のアクションゲームではよくあることですが、プレーヤーに人間離れした跳躍力があるため激しく飛んで激しく落ちていきます。ゲーム性の点からは別に不自然でもなんでもないのですが、リアルな映像として脳に入ってくると「視覚は動いていると言っているのに、体は動いてない（加速度を感じない）よ？」ということになり、お脳が混乱します。万人が同じ感想を持つかわかりませんが、夢のなかで落下しているという状況に近い気持ち悪さがあります。また、EVE: Valkyrieのような広い空間を高速に移動するのではなく、床や壁などがかなり近くにあり、「視覚が移動している」ということを強烈に認識しやすいことも原因だと思います。ひっとしたらジェットコースターとかが好きな人だとわりと大丈夫なのかもしれません（自分はジェットコースター駄目派です）。あと、飛ぶだけではなく落下を繰り返すということもあって緊張しているのか、このゲームだけめちゃくちゃ手汗をかきました。ということで、体験としてはなかなかおもしろいのですが圧倒的に消耗が激しく、自分は1日あたり20分くらいのプレイが限界でした。でも刺激的です。動画再生・デスクトップ表示アプリこのあたりを試してみました。BigScreen (Beta)CINEVEOVideo (Oculus)Whirligigwww.youtube.comWindowsのデスクトップそのものやただの動画をVR上の空間に投影するだけのアプリケーションなのですが、これもまたいろいろと可能性を感じます。これまで、VRではないHMDを使った動画再生は映画館のような迫力があると言われつつも、頭を動かすと画像も動いてしまう違和感があり微妙と言われてきた気がします。これらのアプリケーションはデスクトップや動画を仮想空間にうかぶ空中ディスプレイのように表示したり、仮想空間上の壁面に投影したりします。例えばCINEVEOは映画館での上映を模したVR空間に動画をスクリーン投影しますが、Oculus Riftの没入感に加えてわざわざ映像の光が壁に反射するのを再現していたり、当然ながら頭を動かせば他のお客さんが見える、といった演出から本当に映画館にいるような錯覚を覚えます。http://www.mindprobelabs.com/cineveo_themes.htmlよりCINEVEOはmp4などの動画ファイルを用意する必要がありますが、BigScreenはデスクトップの映像をそのまま表示するので、直接VRに対応していないWeb系のストリーミングサービス（ニコ動、バンダイチャンネル、AbemaTVなど）でも映画館のような環境で再生可能です。また、Whirligigは魚眼レンズ x 2で撮影したような動画を擬似的な3DとしてOculus RIftで見ることができます（この場合、映像の範囲は前方180度に限られていました）空中ディスプレイにデスクトップが移るので、攻殻機動隊の電脳世界のようにこれで作業できたらカッコいいのに…！と思ったのですが、解像度があまりよくないという問題（後述します）があるため、例えば空中ディスプレイ上でコードを書くというのは現状かなり厳しいのではという状況です。ただ、先述したVRグローブ等と組み合わせることで新しいユーザインターフェースが期待できるため、あるいは現在マウスでやっているようなアプリケーションの作業をVRに置き換えるという時代は来るかもしれません。その他その他に以下のようなゲームを試してみました。InCell VRInMind VRwww.youtube.comそれぞれVRのサンプルのような位置づけのコンテンツです。ゲーム性は大してないのですが「VRで仮想空間を高速移動する」という体験ができます。MIND Pathwww.youtube.comあまりのホラー感に開始3分で音を上げました（お化け屋敷ダメです）これは別にホラーというわけではないのですが、あまりに没入感すごいので、暗い屋敷みたいな空間でいきなりゾンビとかが脅かしにでてきたら心臓が止まる自信があります。今後も自分はホラー系をプレイしないですが、逆に好きな人には最高だと思います。www.youtube.comMocuMocuDanceMMDのモデルを表示するソフト。まじかで見る等身大ミクさんかわいいです。Leap motionと組み合わせてボーンの操作ができるようで、はやくも手の動きをセンスするインターフェースとの組み合わせの良さを見せてくれています。Oculus Riftの課題さて、散々持ち上げた後でなんですが…ぶっちゃけ結構いろいろな課題があると思います。お値段非常に高価だと思います。まず本体が送料込みで94,600円、さらに接続先のPCの最低推奨スペックとしてCPU i5-4590＋Graphci Card: NVIDIA GTX970以上を要求してくるので、コアPCゲーマでもないかぎりは少なく見積もっても10万強のPCに買い換える必要があります。よって現状では合計20万円以上の初期投資が必要であり、なかなかハードルが高いというのは否めません。画質がいまいち没入感すごい！という話をさせてもらったのですが、よくよく画面をじーっと見つめると結構粗が目立つ解像度として見えます。screen-door effect（網戸効果）というらしいのですが、そもそもディスプレイ部分に眼球が近すぎるため本来の解像度より粗く見えてしまうようです。そういう意味ではふと画像の粗さに気づいて「あ、仮想空間なんだな」と時々思い出すレベルになっています。逆に高い解像度で見えるようになったら現実より現実っぽい仮想空間ができあがるのではと思うので、今後の技術の向上に期待です。メガネ当方完全にメガネ野郎なので結構深刻な問題です。構造的には顔に密着するようになっているため、持っているメガネを無理やり装着しようとするとすべからくフレームがへしゃげそうになり、そのまま使うのを断念しました。結局どうしたかというと、ひとまずは昔のメガネを分解してレンズの前におき、無理くり対応しています。いろいろな対応策が考えられてはいるようですが、個人的には生まれて初めてコンタクトレンズの購入を検討しているところです。こんな感じ。意外と置いただけでもまあまあなんとかなる。酔う正直なところ、これが最大の問題だと思います。Windlandsの解説でも書いた通り、そもそも移動がともなうコンテンツだと「視覚情報では加速度がかかっているはずの状態なのに体は加速度を感じていない」というミスマッチが必ずおきるので、体に負担？がかかっているような気がしてきます。ここ数年乗り物酔いや普通のディスプレイでFPSとかのゲームをやって一切酔ったことがない自分でも、ものによっては1時間ぐらいでちょっとキツくなってきます。これはもう人類が進化して三半規管とかがそういう視覚情報と体感加速度のギャップとかに対応するとかしないといけないのかもしれませんが、どうにか解消してくれないかなぁと思う点ではあります。まとめ買いか買いじゃないか、と聞かれたらまだ普及期には至っていない、というのが正直な感想です。お値段＋諸問題と得られる効果を考えるとちょっと面白そう、というノリで買えるおもちゃではないと思います。しかし、個人的には十分なインパクトがありVRの可能性を大いに実感できる製品だったことは間違いありません。例えるなら、1980年代に給料一月分ぐらいするようなコンピュータを一部のマニア層だけが買って、可能性を感じながらもほそぼそといじっていた黎明期に近いと思います。このOculus Riftが現行の値段・性能でそのまま普及するとは自分も思いませんが、5年後、あるいは10年後にVRというものがなんらかの形で社会の一部で使われているだろう、ということは確信できます。ということで、Oculus RiftにかぎらずHTC ViveでもPlayStation VRでもいいのですが、ぜひこれらの製品に触れられる機会があれば一度体験することをお勧めします！","link":"https://mztn.hatenablog.com/entry/2016/05/03/134603","isoDate":"2016-05-03T04:46:03.000Z","dateMiliSeconds":1462250763000,"authorName":"mizutani","authorId":"mizutani"},{"title":"『見て覚えろ』の後ろには屍の山がある","contentSnippet":"www.recomtank.comちょうど職場でも新しいメンバーの教育問題がいろいろ議論されているところで、この記事を見て思ったこともいくらかあったのでつらつら書きなぐってみます。上の人がみんな「俺は見て覚えた」というのは生存者バイアス（の可能性が高い）どことは言いませんが、マニュアル化された教育法がない世界では確かに「自分は先輩を見て覚えた。だからお前もそうしろ」という言説をよく見かけます。できる上の人達はみんな口をそろえて言うため、それに従えば自分もできる人になれるのか、と思ったり思い込んだりしてします。しかしそれは「上を目指していた人たちが全員そのように上へあがっていた」のではなく「そのような教育方法でも生き残った人たち」なのであり、ただの生存者バイアスに過ぎません。そのやり方についていけなかった人たちがその組織・業界を去っていった結果、残った人たちなのであって、その後ろには屍の山が築かれています。個人的な経験の中でもそういった人たちをいろいろな場面で見てきました。育てたい人物像をイメージ出来ているか『最初から教えてばかりだと、考える能力が身につかない』という論もあり、この言葉が完全に間違いではないと思います。ただ、まずこれは程度問題であり、育てたい人物像と設定するハードルの高さのバランスを考える必要があると思います。例えば本当の超少数精鋭を育てたいのであれば、ほぼ突き放してついてこれた人だけがその組織・業界に残る、ということもあり得ると思います。ただし先程も書いた通り、その後ろには山のような屍が築かれ、その道を志した100人に1人とか、もっとひどければ10000人に1人しか残らない、みたいな話もありえると思います。HxHのハンター試験みたいなものです。貪欲に自分で学習し、人のスキルなどを盗んでいく超逸材だけが残っていくことでしょう。ただし、このモデルは本当に人数を増やす必要が無い場合か、それだけ厳しい道でも志願する人が後を絶たない、といったような状況でなければ成立しないでしょう。一方で超逸材がいなくてもいいが（いてもいいけど）仕事として100点満点中80点をちゃんととれる人が増えてほしい、という場合だと、全て「自分で勝手に学べ」モデルは非常に相性が悪いと思われます。一般的な企業や組織はほとんどがこちらに該当すると思われます。特に事業などの規模を拡大させたい場合は100人雇って1人しかものになりませんでした、では話になりません。こういった場合は先のブログで書かれていた通り、マニュアル化された作業手順や教育方法があってしかるべきだと考えます。そもそも「マニュアル化できない」とはどういうことなのかちょっと自分のいる業界に偏ってしまいますが、基本的にマニュアル化できない仕事というのは、人によって過程や結果が異なることを許容する 仕事だと考えられます。以下、その例をあげてみます。何かを自ら創造するような仕事（システム・ソフトウェア設計、新しい企画の立案）前提条件の想定が難しく条件の組み合わせも複雑であり、条件の網羅が困難なもの（トラブルシューティング、インシデントレスポンス）試行錯誤しながら進めないといけないもの（新しい機器の検証、探索的データ分析）確かに上記のような仕事について全てマニュアル化するのはかなり難しいとは思います。しかし、全てをマニュアル化するのは難しいとしても、部分的にはいろいろマニュアル化（ないしは定型的な教育によって身につけた手順によってできるもの）できそうではないでしょうか？ 例えばソフトウェアの設計などはどのような道筋でやるべきかという教本はいろいろありますし、トラブルシューティングでもまずはこれをチェックしろ、みたいな初動のマニュアルは作成できそうです。最終的に人間が考え、発想し、創造する必要のある仕事は確実にあると思います。しかしそのためには、どこからが機械的に作業して（あるいはもう機械に作業させてもいいわけで）どこからが人間の判断の力を発揮しなければいけないか、という線引をすることが重要なのではと思います。あと、基礎力の必要性などについてもちょっと書きたかったですが、夜更かしが過ぎてきたのでこの辺で。","link":"https://mztn.hatenablog.com/entry/2016/03/10/014446","isoDate":"2016-03-09T16:44:46.000Z","dateMiliSeconds":1457541886000,"authorName":"mizutani","authorId":"mizutani"},{"title":"博士の愛した就活（採用プロセス編） ","contentSnippet":"前回からの続き。ちょうど経団連的新卒採用プロセスがはじまったということで、博士課程をしている後輩によく話していることをまとめました。この話は私が経験した情報科学系のごく狭い範囲の知見を元に書いていますが、現在博士課程の人やこれから博士課程に進もうと考えている人の参考になれば幸いです。また、主に企業への就職を中心に話をします。前回は就職先の選び方について書きましたが、では実際に就職しよう！として動き出した時にどういうアプローチで内定をもらうか、という部分についてです。1) 新卒採用プロセスに乗る、2) 中途枠・オープンポジションを狙う、3) つてを頼る という三本立てでお送りします。1) 新卒向け採用プロセスに乗るいわゆる説明会に参加して、エントリーシートをだし、何度か面接を経て採用、という学部生や修士生と同じパターンです。博士の場合は例外扱いになるケースも有りますが、こういった新卒採用プロセスを持っている会社の場合はだいたいそこに組み込まれることが多いと思います。細かい対策については学部や修士のものとほぼ変わらないのでSPI対策本などを読んでおく感じでしょう。時期的な制約が強いこのアプローチで気をつけなければいけないのは、プロセスに乗れる時期が1年のうちに限られているという点です。2017年卒の場合は2016年6月から採用試験がはじまるので、2017年3月に卒業することを前提に2016年6月から就職活動をはじめなければなりません。学部や修士過程では単位を落とすなどのミスをしないかぎりは決まった時期に卒業できるので「お前は何を言っているんだ」という感じかもしれませんが、ほぼ学内で卒業までが完結する学部や修士と違い、博士課程の卒業審査は学外の要素がからんでくるため、卒業時期が不安定になりやすいというリスクがあります。博士課程の在籍経験がある人はよくご存知かと思いますが、博士過程を卒業するためには研究をして博士論文を書くだけではなく、論文誌への掲載や国際学会での発表という要件が明示的・暗黙的かを問わず存在します。論文誌や国際学会での採択は学内でコントロールできるものではなく、外部の査読者に掲載や発表を了承してもらわなければなりません。これは容易なことではなく、1度の投稿には構想・実験・論文執筆に数ヶ月を要しますし、下手をすると何度投稿しても掲載・発表拒否となることもあります。こういったものが卒業条件（あるいは卒業を決めるためのプロセスの条件）に加わることで希望通りの時期に卒業できないというケースが起こりえます。そのためこの新卒向けプロセスに乗る場合、（例えば2017年卒予定だとすれば）2016年6月には論文誌や国際発表が完了・あるいは見通しが立っている状態にして、6月からは就職活動に時間を割き、その後に研究まとめ、博士論文執筆や発表をこなすということを手際よく進め、2017年3月にちゃんと卒業する、というところまでをやりとげなければなりません。採用プロセスの課程が分かりやすいこのアプローチは時期の制約が厳しい代わりに、採用プロセスが比較的分かりやすいと言えます。中途枠や例外的な扱いになると他に参考事例が無いので、自分が今どういう状況に立っているのか（採用が進んでいるのか停滞しているのか）ということが不明瞭になりがちです。これが（ある程度大きい企業に限るかもですが）新卒採用のプロセスになると同じプロセスをやっている別の学生が一定数以上いることになります。就職希望の他の学生の方と状況をシェアできることもあるかもしれませんし、過去の事例からおおよその状況を把握できます。あくまで自分の立ち位置がわかるという程度のものですが、戦略的に複数の企業の採用面接を受けている時にはメリットになると考えられます。2) 中途枠・オープンポジションを狙う外資やベンチャーだと、そもそもあまり体系だてて新卒採用を実施しておらず、誰でも応募できるオープンポジションという形で募集をしているケースが多く見られます。また日本企業でも中途採用という形で新卒以外の採用希望者を雇用しているため、そこから採用プロセスに乗せてもらうというアプローチがあります。業務内容が明確で採用プロセスも比較的柔軟中途枠・オープンポジションはそれぞれ求められる技能や採用後の業務内容について、ほとんど事前に明示的に説明されています。前回でも少し書きましたが、新卒採用プロセスによる就職は採用後の業務内容が明示されないケースが少なからずあります。また、例えば面接中に口頭で説明されれる場合もありますが、所詮は口約束なので会社の都合によっていつの間にかに変わっている場合もあります。もちろん会社都合による業務の内容は中途枠・オープンポジションでも発生する可能性はありますが、最初から業務内容が曖昧な採用プロセスと明確なプロセスでは対応が違ってくると思われます。また、面接・雇用タイミングの融通がききやすいというアドバンテージもあります。先述の通り、新卒採用のプロセスでは面接などの時期が限られており、内定、ないしは内々定から実際の雇用までにかなり期間があります。経団連の施策によってかなり後ろだおしされたものの、それでも約半年ほどの差があります。それに対して中途やオープンポジションの場合は採用決定後、かなり早い時期で雇用が始まると聞いています。そのため、例えば博士号の審査に関するどたばたも終わり、卒業までのいくらかの期間の間に就職活動をして就職する、というような流れもありえます。タイミングよく求職している業務経験者じゃあ新卒プロセスは忘れて、中途枠・オープンポジションを狙うのがいいのか？という話になりますが、もちろんデメリットもあります。まず、中途枠やオープンポジションでは「業務経験者」を条件にしている場合が多く、そのケースでは博士課程卒はこれに該当するのか？という問題があります。博士課程での専門にマッチしていれば下手な業務経験者よりも技術的な面については優っているケースは多々あると思います。また、博士課程の学生でも研究プロジェクトをまわす経験があるのだからそういった面でも業務と比べて遜色ない、と主張する方もいらっしゃします。ただ、自分も博士課程を卒業して企業に就職して5年ほどたった今考えても、やはり経験の質は若干違うと感じています。特に中途枠という設定の窓口に多いと思いますが、そういったことを採用担当の方が懸念される場合は「新卒採用の窓口があるのでそちらからどうぞ」と突っ返されるリスクがあります。また、受けたいときに受けられる可能性が高い事と、受けたいときに希望する職種を募集しているかというのは全く別問題になります。企業側としていつでも採用希望を受け入れるということは（適切な人材がいれば）早く採用して働き始めてほしいということの裏返しでもあります。追加で募集するということもありますが、多くの場合は人が見つかればその募集は打ち切ることになるので、この辺りの動きはかなり流動的です。また企業側の方針転換などで誰も採用しないままの打ち切りということもありえます。自分の希望する企業の希望する職種が都合の良い時期に募集しているかは完全に運である、というところにリスクがあります。3) つてを頼る前述の中途枠を狙う、に若干近いところがありますが、知り合いの会社の中の人経由で採用面接をうけさせてもらうケースです。博士課程の学生となると企業とのプロジェクトや学会参加などでその人なりの人脈を築いている場合が多いと思います。そういった人たちに紹介してもらい、面接を受けさせてもらいます。多くの場合、紹介してもらう人に人事権がなかったりするので、紹介＝即採用みたいにはならない（というかそのケースはヤバイ）のですが、いくつか中途採用やオープンポジションに比べて有利な点があります。面接にたどり着きやすい、というアドバンテージ外資系に多いパターンだと思いますが、レジュメだけ登録させて「空きができたら会社から連絡を出すね」というのを見かけます。こういうのは大手ほど大量のレジュメが登録されることになるので、特別な業績などあれば別でしょうが、待てども待てども連絡がこないのはざらです。その点、紹介の場合は比較的面接プロセスまではたどり着きやすく、同じような内容が書かれた大量のレジュメの中から選ばれるのを待つよりは、面接官に直接自分をアピールできるチャンスが得やすいと言えます。これは採用する側からも、どこのだれだかわからない応募者より、同じ会社で働く社員の紹介のほうが安心感があります。そのため、大企業でも応募者が面接をパスして入社したら紹介した人に褒賞がでる紹介制度がある、という話をよく聞きます。一朝一夕ではどうにもならないつてを頼る時の難しさは、当然ですが自分の人脈を学生時代どれくらい築けたかによって頼れる範囲が変わってくることです。これは少なくとも大学の研究室などに所属してからどのように活動してきたか、すなわち対外発表や外部講演、勉強会での交流などをどれくらい積極的にこなしてきたかということに依存します。そのためそれなりに長い期間がかかっていることが重要であり、エントリーシートのように今日明日で何十社にアプローチできるというものではありません。自分の状況・ペースにあわせた就活を長々と書きましたが、結局のところ博士課程にいる時点でいわゆる「みんなで足並み揃えて」何かをするという道からは外れていると思います。それぞれ学生さんごとに状況・ペースが違うので、いろいろなやり方のメリット・デメリットを勘案して自分にあった方法を選ぶと良いと思います。","link":"https://mztn.hatenablog.com/entry/2016/03/05/122102","isoDate":"2016-03-05T03:21:02.000Z","dateMiliSeconds":1457148062000,"authorName":"mizutani","authorId":"mizutani"},{"title":"博士の愛した就活（就職先の選び方編）","contentSnippet":"タイトルは思いつきです。博士課程にいる後輩によく話していることをまとめました。この話は私が経験した情報科学系のごく狭い範囲の知見を元に書いていますが、現在博士課程の人やこれから博士課程に進もうと考えている人の参考になれば幸いです。また、企業への就職を中心に話をします。博士課程を修了した後に企業への就職を考えている場合、企業を選択するにあたって以下のことをチェックするとよいのでは、という点をまとめてみました。就職後の業務は明確か？就職したとして自分の専門を活かした仕事ができるかというのは、その会社の採用形態によって異なります。外資系などの場合は新卒採用の場合でもある程度は業務内容を明確にしたうえで募集しているところが多いと思います。さらにオープンポジションのような形式で募集している場合は、より具体的に業務内容が明示されていることが多く、自分の専門が活かせるかどうかということについて判断しやすいでしょう。逆に日本企業の場合は「とりあえずとるだけとって後から事業部や部署に振り分ける」という形式をとっているところが比較的多い印象です。こういう場合、自分が専門でやっていた分野を得意とする企業であっても研究職などにはつけず、営業など研究開発とは遠い部門へ配属されるということも普通にありえます。特に日本企業では定期的に部門を移っていくことでキャリアアップするといった、官僚のシステムに近い会社もあるようです。いろいろなことを広く経験したい、という方にとってはそういうシステムはいいのかもしれませんが、博士に進んだ人で自分の専門をずっとやっていたい、という方にとってはミスマッチになる可能性があります。そういう観点から就職後、どのようなキャリアパスが用意されているかということも確認しておくのがよいでしょう。会社として博士号を評価してくれるか？血の滲むような思いをしてとった博士号を評価してくれるかどうかというのは、博士課程の学生にとって重要な関心事だと思います。残念ながら、企業によっては博士号をプラスに捉えてもらえないどころか、マイナスの評価になる場合すらあります。博士号を持っている人は専門指向の強い人と捉えられがちなので、ポジションとのミスマッチがあるとそれがマイナスイメージに働くことがあります。また、単純に学部生に比べて歳を重ねているという現実もあり、新卒採用主義の企業からすると敬遠されやすい傾向があります。企業によっては正規ルートでは博士の学生は就職できないということすら聞いたことがあるため、もし博士課程後に特定の企業へ就職しようと考えている学生さんがいらっしゃる場合、事前に確認しておくべきです。しかし一方で博士号をプラスに評価してくれる企業もあります。主観的な意見ですが、やはり外資系やベンチャー企業などに多いと思います。博士号取得の過程ではある分野への専門性だけではなく、他分野にも応用が効く問題発見・設定や解決能力などが養われるので、そういった点を見てもらえるようであれば採用に対しても有利に働く面があると思います。給与面での優遇はあるか？また採用過程だけでなく、給与面に反映があるかも重要な点です。学部卒と修士卒で給与がわかれているというケースは多く見かけますが、博士卒に対して給与面での優遇がある企業もまれに見かけます。博士卒の給与が書かれていない企業は、そもそも博士の応募が少ないので例外的な扱いになっており給与面については応相談な場合と、そもそも修士と同じ扱いである場合があるかと思います。博士課程は在籍中に毎年学費を払わなければなりませんし、就職すればそれだけ給与を稼げたであろう3年以上の在籍期間を消費しています。就職に際して給与が全てとは思いませんが、給与は会社に対する貢献へのフィードバックの一つの形ではあるため、給与が修士卒と同じということは、博士号についてはあまり評価してくれていないと考えるのが自然かもしれません。また、働いた経験がないと実感しにくいと思いますが、給与というのは同じ会社で働き続けるにしても後から転職するにしても、最初の年収というのが後々に響いてきます。昇給は元の給与に対してN%加算みたいな形式になるかと思いますし、転職するにしても元の給与に+N百万みたいな形で増えれば上々、普通はほぼ同額、みたいになると噂に聞きます（これは業界によって大きく違うかもしれませんが）。あまり給与だけみて就職先を決めても不幸になることが多々ありそうですが、その一方で給与を甘く見ない、ということも非常に重要です。全く違う分野を考える場合上記3点は自分の専門をある程度意識した就職の話になりますが、全く違う分野を考える場合は年齢がやはり重要なポイントになってきます。学部卒と比べると通常で約5年、在籍期間が長ければそれ以上の差がついています。年齢が上になった人が全て新しいことを学ぶのに不向きだということはありませんが、経験則的には年齢が若い方が学習にも意欲的で飲み込みも早いという側面はあります。そういったことから採用に不利になったり、新卒採用に対してそもそも年齢制限が加えられるというケースもあります。博士課程はこじらせると6年、あるいはそれ以上かかるケースがあり、その場合は学部・修士で浪人・留年がなかったとしても卒業時点で30歳を超えてしまいます。これは違う分野に行く場合だと大きなハンデキャップになってしまう可能性が高く、個人的には途中で見切りをつけるという選択肢も検討するべきではと思います。","link":"https://mztn.hatenablog.com/entry/2015/12/23/122201","isoDate":"2015-12-23T03:22:01.000Z","dateMiliSeconds":1450840921000,"authorName":"mizutani","authorId":"mizutani"},{"title":"インターネット通信データ量をd3jsのツリーマップで可視化してみた","contentSnippet":"練習などを兼ねてちょいと書いてみました。自分のMacBookProで作業をしていた時に取得した通信データから、通信相手をドメイン名で判定し、送受信量をもとにツリーマップにしてみました。通信からのデータ取得は自作ツールを使い、出力結果をPythonでごにょっといじった後にd3jsで描画しました。通信データは約5時間ほど。HTML版はここに公開しています。細かい通信量とか見えます。送信データ量のツリーマップ送信データ量と受信データ量は一度に表現するのが難しいので、今回は分けてみました。まずは送信データ量から。解説を入れるとこんな感じです。送信データ量そのものは多くないのですが、作業していたソースコードがDropbox配下にあったので頻繁にDropboxにデータを送信していたため、Dropboxがとても大きく出ています。といっても、送信データ量はDropboxの島を全部あわせて70MB程度ですね。どうということはありません。さらに、作業時にずっとみていたニコ動の通信が目立って見えるのがわかります。これも送信データ量としては少なく、トータルで20MB強というところでしょうか。これはこちらから生中継をするようなデータを流していたわけではないため、ほぼTCPのack（受信確認）のパケットだけでこれぐらいの容量になっていることが伺えます。受信データ量のツリーマップ一方、受信側はこんな感じです。解説付きだとこんな感じになります。さっきより顕著にニコ動の通信がデータ量を占めているのがわかります。マイリスト登録していた動画をBGM代わりに受信しつづけていたので、その配信される動画のデータががつんと乗ってきている状態ですね。全体で約2.5GBほどあり、携帯キャリアの回線（テザリング）などを使っていたらあっというまに帯域制限にひっかかったでしょう。（この時はカフェに設置されてるWiFiを使っていました）次に大きなポーションになっているのが左下のBlizzard社からの通信です。これはBlizzard社が制作、発売しているHeathstoneのパッチが落ちてきたためだと考えられます。Hearthstoneはゲームとしてとてもシンプルなのですが、演出などが豊富なためアプリ・パッチのサイズがとても大きいというのが若干ネックになっている気がします。でもゲーム内容はとても面白いのでおすすめですよ（脈絡のない宣伝）他に注目すべき点としては右下にあるtwimgからのトラフィックでしょうか。そこまでtwitterの画像をずっと見続けた記憶はないので、Twitterクライアント（Tweetbot）がサムネイル（および画像本体？）を取得する通信だけで約100MBほどを受信しているのがわかります。ちなみにツイートの受信であるuserstream.twitter.comからの受信は右上にある青の細長い部分で、受信は20MB程度です。写真投稿などが多い昨今だと通信データ量だけでみればかなりtwimgに負荷がかかっているようです。ということで、通信を無制限に使える環境であれば特に気にすることのないものですが、データ量制限のある環境ではどの通信がどれくらいの割合をしめているかということがわかると通信データ量の節約がはかどるのではと思います。（一部当然のことですが）今回の知見としては以下のとおりです。動画垂れ流して見ているのは非常にインパクトがでかいアプリケーションのパッチも種類によってはそれなりに重いツイート取得はそうでもないが、画像閲覧はそれなりに重いようなのでクライアントの設定しだいではデータ量を節約できるかも？こちらからは以上です。","link":"https://mztn.hatenablog.com/entry/2015/11/14/172231","isoDate":"2015-11-14T08:22:31.000Z","dateMiliSeconds":1447489351000,"authorName":"mizutani","authorId":"mizutani"},{"title":"自動化するときに考えるべきこと3つ","contentSnippet":"自分の経験を元にメモ書き。1. 自動化の目的は「属人性排除」「ヒューマンエラーの除去」「高速化」のいずれか、もしくは全てである属人性排除「この作業は○○さんしかできないから」みたいなものをなくすのが属人性排除。これは自動化することによって作業の一部、あるいは全てをほかの人でもできるようにすることで達成される。職場における人の入れ替わりで秘伝の技が途絶えてしまったり、引き継ぎの労力を少なくすることによって組織としての靭性を高めることができる。また自動化する過程で、ある人物しか理解していなかったロジックや、そもそも作業をしている本人ですら説明できないような手順や理論を解き明かし、再現性のある形へ落とし込めるという副次的な成果がある。これが手順書という形だと解釈の違いによる間違いなどが発生する可能性があるが、コードによって自動化されていることで誤解を生む可能性を極小化する。（ただし0になるわけではない）ヒューマンエラーの除去プログラムによって自動化された作業でも当然例外やバグによって思わぬ挙動をすることがあるが、人間も言うに及ばずしょっちゅう間違いをおこす。しばしば「集中力が足りない」「もっと注意する」「気合」などの精神論で解決できると信じている人がいるが、個人的な経験則でいうと、どれだけ注意深く作業したとしてもだいたい最低0.01〜0.1%程度の確率でミスをする。プログラムのバグの発生も同程度、あるいはもっと高い確率かもしれないが、最大の違いは（バグ修正すれば）プログラムは同じ間違いを二度起こさないことである。人間の場合、同じ人物が同じミスをしてしまうこともあるし、作業者が入れ替わると同じミスを起こすかもしれない。高速化単純作業やロジックが決まっているものについては、それを得意とする機械にやらせるべきである。2. 自動化の目的は「コスト削減」であってはならないよく「自動化によってコストが削減されます」という言い方がされているが、だいたいの場合こういうプロジェクトは失敗する傾向が強い。これは、この文脈ででてくる「コスト」とはすなわち「人件費」のことであり、「コスト削減」といは「人員整理・リストラ」につながるからである。多くの場合、自動化するためには今その仕事をしている人物から作業のロジックやノウハウを教えてもらわなければならないが、プロジェクトの最終目的がリストラだとすると、教えてもらう人たちがまさのその対象になるわけである。これでは協力してノウハウを教えてもらうどころか、その人達が抵抗勢力になってしまうため、プロジェクトが進まなくなってしまう。結局のところ自動化とは人間の作業を機械にやらせることになるので、コスト削減が最終目的ではないとしても少なからず上記のような問題を引き起こしやすい。ただし、以下のようなケースでは比較的スムーズにすむ。他にやるべき作業があるにも関わらず、現在は自動化対象の作業に業務時間が圧迫されている場合全てを完全に自動化できず、最終的に人間の判断などが必要な作業の場合(1) は例えば、目先の作業に振り回されてしまって先行投資的な作業に取り掛かれていないような状況である。(2) は例えば現実世界や人物間の文脈をもとに最終的な判断しなければいけない作業だったり、一定確率でしか正解が導かれるが外した時の影響が大きいので人間が責任を負う必要があるようなケースである。こういう類のものは結果が導かれるまでの過程を正しく理解している人物が必要になるので、単純に機械を人に置き換えられるものではない。3. 自動化は「熟練の作業者」ではなく「未熟な作業者」に対して効果が高いなぜか自動化の話がでると「専門家（熟練の作業者）」「それ以外」という登場人物しかでてこなかったりすることが多いのだが、現実にはその中間たる「未熟な作業者」がいる。最初の目的に挙げた「属人性排除」「ヒューマンエラーの除去」「高速化」は、もちろん熟練の作業者に対しても有効だが、それ以上に「未熟な作業者」に対してはより大きい効果を生みやすい。これは作業を完全自動化するわけではなく、未熟な作業者がとりかかる一部だけでもその効果がでやすいという観点もある。（熟練の作業者の一部の作業を置き換えると、逆に効率が下がってしまうことがしばしばある）ただし、先述した判断が必要な作業などもあるため、自動化された作業について無知でよいというわけではない、ということについては注意が必要である。","link":"https://mztn.hatenablog.com/entry/2015/11/01/110645","isoDate":"2015-11-01T02:06:45.000Z","dateMiliSeconds":1446343605000,"authorName":"mizutani","authorId":"mizutani"},{"title":"コンピューターセキュリティシンポジウム2015に参加してきました","contentSnippet":"情報処理学会 コンピューターセキュリティシンポジウム(CSS)2015＠長崎に参加してきました。ちゃんぽん美味しかったです。より実践的になっている学会実学的な発表が多くなってきている印象でした。CSSにはマルウェア対策研究人材育成ワークショップという発表枠が含まれているのですが、ここで発表されているネットワーク侵入検知や防御、マルウェア分析などは他のコンピュータ科学の研究とくらべてもとくに実践的な内容になっていると思います。マルウェア対策技術というのは、攻撃者側のマルウェアや攻撃手法の変化が非常に早く、自分も昔指導教員に「マルウェア関連の研究で5年前というのは石器時代」と言われたことがあります。そのため研究でも数年後に芽がでるようなものではなく「今」「役立つ技術」というものが求められていると思います。今回もそうですが、このマルウェア対策研究人材育成ワークショップ(MWS)というのは大学や企業の研究所だけでなく、セキュリティをサービスとして売っているような会社やそれこそアンチウィルスベンダの方も参加されており、こうやってデータ収集してみた、みたいな内容も多く発表されています。これはこのワークショップが始まってから徐々に広まってきた流れであり、それ以前のCSSにはなかった流れだったと記憶しています。ワークショップの委員の方もこういった実践に沿った研究活動を広めてほしいという願いがあったようで、それが形になってきているということを強く感じました。研究は良くも悪くも機械学習的な話が多かった自分が参加したセッションの偏りがあったからという気もしますが、とりあえずデータを機械学習に食わせて何か結果をだす、というような発表が多かったのが印象に残っています。データをいろいろな視点から扱ってみるという点では貢献があるかなと思う反面、機械学習系の研究の悪いところとしてでやすい「なぜこの手法を選んだのか」ということを論じきれていなかったり、「この結果は他の環境や実環境でも有用なのか」というようなことに対しての突っ込みが甘いものも少なくなかったように思います。研究所から離れた自分が参加してみて私自身が今年の4月から研究所を離れて現場（SOC）に入っているのですが、やはり現場的視点を持ってからこういう研究発表を聞くと面白いと思いました。特にMWSというのは事前に配布されるマルウェア関連のデータがあるのですが、この共通のデータをいろいろな視点で料理している研究を見ると、実際の現場でも「ああ、こういう見方や分析をして見ると何か見えてくるかもしれない」というような着想を得ることができました。すでに多くのセキュリティ対策ベンダだけでなく大手Webサービスの方などもちらほら参加されるなど、多様な方々が集まるよい場だったと思います。研究というキーワードがあるとちょっと疎遠になってしまいますが、普段セキュリティに関わっている方ならいろいろと有益だと思いますので、参加を検討してみるとよいと思いますよ。","link":"https://mztn.hatenablog.com/entry/2015/10/27/233323","isoDate":"2015-10-27T14:33:23.000Z","dateMiliSeconds":1445956403000,"authorName":"mizutani","authorId":"mizutani"},{"title":"AWS EC2へのSSHに対する攻撃をハニーポットで分析してみた (2015年4月〜6月)","contentSnippet":"数ヶ月間、私のお小遣いを貪り続けてきたAWS EC2上のハニーポットですが、さすがに財布へのダメージが蓄積してきたのでいったん停止させました。停止させたもののそれなりにデータを蓄積していたので、さてどうしようかなと思っていたのですが、先日、長崎で開催された情報処理学会のコンピュータセキュリティシンポジウム2015で聞いた講演の一つにSSHの新しい攻撃方法について触れられていてちょっと気になったので、収集したデータのうちSSHに関しての通信のみちょっと分析してみました。ハニーポットの構成やデータの収集方法については過去のエントリを参照していただきたいのですが、今回はAWS Asia Pacific (Tokyo)上でEC2のインスタンス4つを4月頭から6月末まで動かしてデータを取得しました。財布へのダメージも4倍！しかしおかげで複数のIPアドレスで観測した時に生じる差分について知ることができました。アクセス件数の推移2015年4月から6月までEC2の4インスタンスで観測したSSHサーバへのアクセス件数まずはベタに各インスタンスに対するアクセス件数を時間軸で見たものです。A, B, C, Dがそれぞれのインスタンスになりますが、4つともアクセス件数の傾向にそれほど大きなブレ方はしていないことがわかります。これらのインスタンスが使っているIPアドレスはどこにも広告していないので基本的には全て無差別に打ち込まれている攻撃であると言えます。そのため特定の組織などに対する攻撃とは異なるかもしれませんが、このようなアクセスは使用しているIPアドレスに関わらず、安定（？）して日々起きていることがわかります。アクセス先ポート番号の件数2015年4月から6月までEC2の4インスタンスで観測したSSHサーバに対するアクセス先ポート番号の件数つづいてアクセス先ポート番号の分布です。4インスタンスの合計値から上位20件をグラフにしてみました。当然ながらデフォルトポートである22番へのアクセスがダントツですが、それ以外にも様々なポート番号に対してアクセスが来ていることがわかります。ちなみに観測されたポート番号は合計56種類となっており、5050、18080 などといったSSHとは全く関係なさそうなポート番号もターゲットとなっていました。今回利用したハニーポットは特にSSHサーバを偽装するわけではなく、アクセスしてきた接続元のホストに対してSYN-ACKを返すだけで、あとは勝手に相手が送ってくれたデータをせっせと回収します。ではなぜ22番ポート以外もSSHだとわかったのか？というとSSHの接続確立時に相手が勝手にバナーとしてSSH-2.0-PUTTY のような文字列を送ってきてくれるので、そこからSSHをターゲットにしているということがわかります。なかにはSSH-2.0-paramiko_1.15.2やSSH-2.0-libssh2_1.4.2のように、あからさまにツール使ってますぜと宣伝してくれているやつもいたりします。しかし先に述べたとおりこちらからは何も情報を渡していないため、相手は攻撃先がSSHサーバであるかどうかを確認などせずに22番以外のポートに接続をしにきているということがわかります。「ポート番号を変えているからパスワード認証でも大丈夫だよね」とか「ポートスキャンを止めているからどこがSSHのポート番号かわからないよね」と考えている管理者の方はぜひ設定の見直しをお勧めいたします。アクセス先IPアドレスと攻撃元IPアドレスの関係2015年4月から6月までEC2の4インスタンスで観測した攻撃元IPアドレスの件数（アクセス先IPアドレス毎）それではようやく複数のインスタンスを使ってデータ収集した強みをみたいと思います。気になることの一つとして「攻撃者はIPアドレスのレンジを舐めるように攻撃しているのでは？」ということだと思います。実際にSSHにかぎらずport sweep（アドレスレンジに対して特定のポートが空いていないか順番に確認するタイプのスキャン）などではそういった挙動も見られます。上の表は各インスタンス（A, B, C, D）で観測されたかどうかと、それぞれで観測されたIPアドレスのユニークな数になります。観測されたIPアドレスは全部で6,669件ですが、そのうちの約80%にあたる5344件の攻撃元IPアドレスがどれか一つのインスタンスでのみ観測されているということになります。それぞれのインスタンスはある程度同じレンジにおさまっていたため、このことから 攻撃者は近接するアドレスに対して何度も出現する可能性が高いとは言えない ということがわかります。先ほどのポート番号に比べると直接的な対策ができるような類のものではありませんが、例えば自組織で管理されているサーバでSSHの不審なアクセス（Brute forceなど）が発生したさいに他のサーバも利用するブラックリストに追加する、というような対策はそれほど効果的ではないかもしれません。（もちろん、残り20%は複数インスタンスで観測されているので無意味ということはありませんが、それでも全インスタンスで観測されたアドレスは約6.5%ほどになっています）攻撃元IPアドレス毎の接続試行回数2015年4月から6月までEC2の4インスタンスで観測した攻撃元IPアドレス毎の接続試行回数の分布（n\u003c10)最後にご紹介するのが1つの攻撃元IPアドレスからやってくるSSHアクセスは何回まで試行されるか？ということをグラフにしたものです。先述したとおり、このデータ収集はあくまでTCPセッションが確立したとみせかけてデータを送信させるだけという仕様になっているため、本当にBrute force attackのようなパスワード試行された回数をカウントしているわけではありません。しかし、通信状態の問題などでうまく接続できないなどのケースが考えられるため、相手がどれくらいしつこかったのかということを知る指標にできるかと思います。このグラフでは1つのインスタンスでのみ観測された5344件のIPアドレスに対してそれぞれのアドレスは何度接続試行したのかをヒストグラムで表したものとなります。一番左のバーが1回だけの試行だった攻撃元IPアドレスのかたまりになるのですが、これを見るとほとんどの攻撃元IPアドレスが試行1回目でダメそうだったらその時点で諦めているということがわかります。このグラフは試行10回までの分布しか表示していませんが、10回以上試行してきたIPアドレスは16件だけでした。全体的に非常に諦めがよい、ということを読み取ることができます。しかし、ここで最初にふれた情報処理学会のコンピュータセキュリティシンポジウム2015の話に戻ってくるのですが、富士通研究所の齊藤さんが発表された「SSHログインセンサによるSTBF(Brute Force attacks with Single Trials)の観測」において一つのIPアドレスからパスワード試行が1回だけ実施されて、次は別のIPアドレスから試行されて、というのを繰り返すBrute force攻撃が確認されたという事例が報告されていました。これは、一つのホストからパスワード試行を繰り返すと防御側に目立って接続拒否されたり、共有されているブラックリストに掲載されてしまい他の環境に対しても攻撃ができなるなることを攻撃者が警戒した結果、ボットネットのように悪性ホストを大量に所有（またはレンタル）している攻撃者が目立たないように1回だけパスワード試行をして去る、という一撃離脱型の攻撃が連続して発生しているということだと考えられます。この攻撃に対してはIPアドレスを基準としたパスワード試行回数制限による対策がほぼ無効化されてしまうということが言えます。実際にこの攻撃がどのくらい世の中に蔓延しているかについては発表者の方も今後調査を継続していくとおっしゃられていましたが、ここで紹介した分析からもそのような種類の攻撃が発生している可能性を示唆する結果となりました。AWSでのインスタンスに限りませんが、SSHでリモートアクセスをしているホストについては今一度設定の見直しなどをしたほうがよいかもしれません。","link":"https://mztn.hatenablog.com/entry/2015/10/26/010627","isoDate":"2015-10-25T16:06:27.000Z","dateMiliSeconds":1445789187000,"authorName":"mizutani","authorId":"mizutani"}]},"__N_SSG":true},"page":"/members/[id]","query":{"id":"mizutani"},"buildId":"ES-1SnkhtthyVvnq96ujm","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["link",{"rel":"icon shortcut","type":"image/png","href":"https://blog.ubie.tech/logo.png"}],["link",{"rel":"stylesheet","href":"https://fonts.googleapis.com/css2?family=Inter:wght@400;700\u0026display=swap"}],["title",{"children":"mizutani | Ubie Engineers' Blogs"}],["meta",{"property":"og:title","content":"mizutani"}],["meta",{"property":"og:url","content":"https://blog.ubie.tech/members/mizutani"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"property":"og:site","content":"Ubie Engineers' Blogs"}],["meta",{"property":"og:image","content":"https://blog.ubie.tech/og.png"}],["link",{"rel":"canonical","href":"https://blog.ubie.tech/members/mizutani"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/_next/static/chunks/main-8a83f0fd99327c4684a8.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.1daf1ec1ecf144ee9147.js" async=""></script><script src="/_next/static/chunks/commons.8d61253ae98ee51657b8.js" async=""></script><script src="/_next/static/chunks/pages/_app-e552cec615d644762a9b.js" async=""></script><script src="/_next/static/chunks/81b50c7ab23905e464b4340eb234bd6ea389d26b.6f016a54640da22ace83.js" async=""></script><script src="/_next/static/chunks/pages/members/%5Bid%5D-0a2d3cf0d329b39cefc0.js" async=""></script><script src="/_next/static/ES-1SnkhtthyVvnq96ujm/_buildManifest.js" async=""></script><script src="/_next/static/ES-1SnkhtthyVvnq96ujm/_ssgManifest.js" async=""></script></body></html>